{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0345371c-056b-463f-8029-73beeeddedc8",
   "metadata": {},
   "source": [
    "# Understanding the .env file and getting your LLM API key\n",
    "\n",
    "## What is a .env File?\n",
    "\n",
    "A .env file is a simple text file that stores **environment variables** for your project. Think of it as a secure storage place for sensitive information like API keys, passwords, and configuration settings that you don't want to hardcode directly into your Python scripts or accidentally share with others.\n",
    "\n",
    "The \".env\" name literally means \"dot env\" (the dot makes it a hidden file on Unix systems), and it follows a simple format: each line contains a variable name, an equals sign, and its value.\n",
    "\n",
    "## Why Use a .env File?\n",
    "\n",
    "Imagine you're writing LangChain code that uses OpenAI's API. You could write your API key directly in your code like this:\n",
    "\n",
    "```python\n",
    "openai_api_key = \"sk-1234567890abcdef\"  # DON'T DO THIS!\n",
    "```\n",
    "\n",
    "But this is problematic because if you share your code on GitHub or with classmates, you're sharing your private API key, and anyone could use it (and potentially run up charges on your account). A .env file solves this by keeping secrets separate from your code.\n",
    "\n",
    "## How to Create a .env File\n",
    "\n",
    "Creating a .env file is straightforward:\n",
    "\n",
    "1. **Open a text editor** (like Notepad, VS Code, or any code editor)\n",
    "2. **Create a new file** and save it as `.env` (literally just those four characters - a dot followed by \"env\", with no file extension like .txt)\n",
    "3. **Add your variables** in the KEY=VALUE format\n",
    "4. **Save the file** in your project's root directory\n",
    "\n",
    "**Important:** Make sure your .env file is listed in your `.gitignore` file so it doesn't get uploaded to GitHub. Most Python projects already include `.env` in the gitignore by default.\n",
    "\n",
    "## Why the Root Directory?\n",
    "\n",
    "The root directory is the main folder of your project (the top-level folder containing all your exercise files and subfolders). When you run `load_dotenv()`, the library searches for the .env file starting from the directory where your Python script is located, then moves up through parent directories until it finds one.\n",
    "\n",
    "By placing the .env file in the root directory, all your exercise scripts (whether in subfolders or at the top level) can access the same environment variables. This means you only need **one** .env file for your entire course, not a separate one for each exercise.\n",
    "\n",
    "## How load_dotenv() Works\n",
    "\n",
    "When you write these two lines at the beginning of your LangChain exercise:\n",
    "\n",
    "```python\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "```\n",
    "\n",
    "Here's what happens step by step:\n",
    "\n",
    "1. **Import the function:** The first line imports the `load_dotenv` function from the `python-dotenv` package (you need to install this package first with `pip install python-dotenv`)\n",
    "\n",
    "2. **Load the variables:** The second line `load_dotenv()` searches for your .env file, reads it, and loads all the variables into your program's environment\n",
    "\n",
    "3. **Access the variables:** After loading, you can access these variables in your code using `os.getenv()` or they're automatically available to libraries like LangChain that look for them\n",
    "\n",
    "For example, after running `load_dotenv()`, when you initialize a LangChain model, it automatically finds your API key:\n",
    "\n",
    "```python\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LangChain automatically looks for OPENAI_API_KEY in environment\n",
    "llm = ChatOpenAI()  # No need to manually pass the API key!\n",
    "```\n",
    "\n",
    "## Understanding Your Example .env File\n",
    "\n",
    "Let's break down each section of the .env.example we include in the root directory of the project:\n",
    "\n",
    "**LLM Model API Keys:**\n",
    "```\n",
    "OPENAI_API_KEY='your_openai_api_key_here'\n",
    "ANTHROPIC_API_KEY='your_anthropic_api_key_here'\n",
    "GOOGLE_API_KEY='your_google_api_key_here'\n",
    "```\n",
    "\n",
    "These store the authentication keys for different AI language models. You'd get these keys by signing up on each provider's website (OpenAI, Anthropic, Google). Replace the placeholder text with your actual keys, which typically look like long random strings of letters and numbers.\n",
    "\n",
    "**Third-Party Tools:**\n",
    "```\n",
    "TAVILY_API_KEY='your_tavily_api_key_here'\n",
    "```\n",
    "\n",
    "This is for Tavily, a search API that LangChain can use for web searching. You'd only need this if your exercises involve giving your AI agent the ability to search the internet.\n",
    "\n",
    "**LangSmith Configuration:**\n",
    "```\n",
    "LANGSMITH_API_KEY='your_langsmith_api_key_here'\n",
    "LANGSMITH_TRACING=true\n",
    "LANGSMITH_PROJECT='your_project_name_here'\n",
    "```\n",
    "\n",
    "LangSmith is LangChain's monitoring and debugging platform. These variables set up tracking for your LangChain applications. The `TRACING=true` setting enables monitoring, and `PROJECT` names your project so you can organize your traces. This is optional but helpful for learning because you can see exactly what your LangChain application is doing behind the scenes.\n",
    "\n",
    "**Comments and Optional Settings:**\n",
    "Lines starting with `#` are comments - they're ignored by the program and are just there to help you understand what each section is for. The commented-out `LANGSMITH_ENDPOINT` line would only be uncommented if you're using LangChain's European servers instead of the default US ones.\n",
    "\n",
    "## Quick Setup Checklist\n",
    "\n",
    "To get started with your LangChain course: create your .env file in the project root folder, add the API keys you need (starting with at least OpenAI or Anthropic), make sure your .env file is in .gitignore, and always include those two dotenv lines at the start of each exercise script. Then you're ready to go!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5834dd-02f2-44af-9021-8f5811652eaf",
   "metadata": {},
   "source": [
    "## Make sure you create the .env file with at least the API key of the LLM\n",
    "* Make sure you create the .env file with your OpenAI API key. If you need it, you will see you to get your OpenAI API key in a section below.\n",
    "* If you want, you can copy or rename the .env.example file as .env and enter there your confidential API keys.\n",
    "* Remember, you have the .env.example in the project folder with this incomplete content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545624e2-683c-4c38-8337-1c624410b245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Models API keys  \n",
    "OPENAI_API_KEY='your_openai_api_key_here'\n",
    "ANTHROPIC_API_KEY='your_anthropic_api_key_here'\n",
    "GOOGLE_API_KEY='your_google_api_key_here'\n",
    "\n",
    "# API keys of third-party tools\n",
    "TAVILY_API_KEY='your_tavily_api_key_here'\n",
    "\n",
    "# Optional: for evaluation and tracing using LangSmith\n",
    "LANGSMITH_API_KEY='your_langsmith_api_key_here'\n",
    "LANGSMITH_TRACING=true\n",
    "LANGSMITH_PROJECT='your_project_name_here'\n",
    "\n",
    "# Uncomment the following if you are on the EU instance:\n",
    "#LANGSMITH_ENDPOINT=https://eu.api.smith.langchain.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06984722-ffb4-4b62-a30f-df99cd0a05e3",
   "metadata": {},
   "source": [
    "## How to get your OpenAI API Key\n",
    "\n",
    "Since **OpenAI LLMs are currently the most used in the business world**, we will use OpenAI LLMs in most of the exercises and projects of this bootcamp. \n",
    "\n",
    "**We will show you how to use alternative LLMs**, so you will be able to experiment with them by yourself.\n",
    "\n",
    "Here's a simple guide to getting your OpenAI API key:\n",
    "\n",
    "**Step 1: Create an OpenAI account**\n",
    "Go to https://platform.openai.com and click \"Sign up\". You can use your email address or sign up with Google/Microsoft.\n",
    "\n",
    "**Step 2: Add a payment method**\n",
    "Once you're logged in, you'll need to add a payment method (credit/debit card). OpenAI charges based on usage, but don't worry - for learning exercises, the costs are typically very small (often just a few cents per session).\n",
    "\n",
    "**Step 3: Get your API key**\n",
    "- Click on your profile icon in the top-right corner\n",
    "- Select \"API keys\" from the dropdown menu\n",
    "- Click the \"+ Create new secret key\" button\n",
    "- Give it a name (like \"LangChain Course\")\n",
    "- Copy the key immediately and save it somewhere safe (like a password manager or secure note)\n",
    "\n",
    "**Important tips:**\n",
    "- **Never share your API key** - treat it like a password\n",
    "- **Save it immediately** - OpenAI only shows it once. If you lose it, you'll need to create a new one\n",
    "- **Set spending limits** - In your account settings, you can set a monthly spending limit to avoid unexpected charges\n",
    "\n",
    "**How you will use your API key during the course:**\n",
    "You will store your API key in an `.env` file in the same root directory of the exercise you are working on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffea14d-268e-4527-9ee2-c602bbbc0719",
   "metadata": {},
   "source": [
    "## How to get your Anthropic API Key\n",
    "Here's a simple guide to getting your Anthropic API key:\n",
    "\n",
    "**Step 1: Create an Anthropic account**\n",
    "Go to https://console.anthropic.com and click \"Sign up\". You can create an account using your email address.\n",
    "\n",
    "**Step 2: Add a payment method**\n",
    "After logging in, you'll need to add a payment method (credit/debit card). Like OpenAI, Anthropic charges based on usage, and for learning exercises, the costs are typically very low.\n",
    "\n",
    "**Step 3: Get your API key**\n",
    "- Once logged in to the Console, look for \"API Keys\" in the left sidebar menu\n",
    "- Click \"+ Create Key\"\n",
    "- Give it a descriptive name (like \"LangChain Course\")\n",
    "- Copy the key immediately and save it somewhere secure (password manager or secure note)\n",
    "\n",
    "**Important tips:**\n",
    "- **Never share your API key** - it's like a password that gives access to your account\n",
    "- **Save it right away** - You can only view the full key once. If you lose it, you'll need to create a new one\n",
    "- **Monitor usage** - Check your usage dashboard to keep track of spending\n",
    "- **Set budget limits** - You can configure spending limits in your account settings to control costs\n",
    "\n",
    "**How you will use your API key during the course:**\n",
    "You will store your API key in an `.env` file in the same root directory of the exercise you are working on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e823b1e-e992-4c8f-a5af-8d3bfe72cc3d",
   "metadata": {},
   "source": [
    "## How to get your Google API Key to use Google LLMs (Gemini, etc)\n",
    "Here's a simple guide to getting your Google API key for Gemini:\n",
    "\n",
    "**Step 1: Go to Google AI Studio**\n",
    "Visit https://aistudio.google.com and sign in with your Google account (Gmail).\n",
    "\n",
    "**Step 2: Accept terms and conditions**\n",
    "You'll need to accept Google's terms of service for using their AI services.\n",
    "\n",
    "**Step 3: Get your API key**\n",
    "- Click on \"Get API key\" in the left sidebar (or you might see it prominently on the main page)\n",
    "- Click \"Create API key\"\n",
    "- Choose to create a new project or select an existing Google Cloud project\n",
    "- Your API key will be generated - copy it immediately and save it securely\n",
    "\n",
    "**Important tips:**\n",
    "- **Keep it private** - Never share your API key or commit it to public code repositories\n",
    "- **Save it immediately** - Store it in a password manager or secure note\n",
    "- **Free tier available** - Gemini offers a generous free tier for learning and experimentation, which is great for course exercises\n",
    "- **Rate limits** - The free tier has rate limits, but they're usually more than enough for learning purposes\n",
    "- **Monitor usage** - You can track your API usage in Google AI Studio\n",
    "\n",
    "**For your course:**\n",
    "When your LangChain exercises need to use Gemini models, you'll typically store the API key as an environment variable called `GOOGLE_API_KEY` in your `.env` file, alongside your other API keys.\n",
    "\n",
    "**How you will use your API key during the course:**\n",
    "You will store your API key in an `.env` file in the same root directory of the exercise you are working on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c52ad1-1f2f-4493-9da4-b807f9e7dc7e",
   "metadata": {},
   "source": [
    "## How to experiment with other popular LLMs (Closed and Open Source)\n",
    "\n",
    "As you learn LangChain and other Gen AI frameworks, it will be valuable to experiment with different Large Language Models (LLMs) beyond just OpenAI, Anthropic, and Google. Each model has unique strengths, pricing, and capabilities that can enhance your learning experience. Let's explore some popular options.\n",
    "\n",
    "#### Understanding Open vs. Closed Source\n",
    "\n",
    "**Closed Source LLMs**: These are proprietary models where you access them through APIs. You pay per use, but the company maintains and improves the model for you.\n",
    "\n",
    "**Open Source LLMs**: The model weights are publicly available. You can run them locally (if you have powerful hardware) or use them through API services. They're often more affordable and customizable.\n",
    "\n",
    "#### Popular Closed Source LLMs to Explore\n",
    "\n",
    "1. **DeepSeek** (China)\n",
    "**What makes it special**: Excellent at coding tasks and mathematics, often at a fraction of the cost of other premium models.\n",
    "\n",
    "**Where to get started**:\n",
    "- Website: https://platform.deepseek.com\n",
    "- Sign up with email\n",
    "- Navigate to API Keys section\n",
    "- Very affordable pricing, great for students on a budget\n",
    "\n",
    "**Best for**: Coding exercises, technical problem-solving\n",
    "\n",
    "---\n",
    "\n",
    "2. **Grok** (xAI - Elon Musk's company)\n",
    "**What makes it special**: Has real-time access to X/Twitter data, known for a more conversational and sometimes humorous tone.\n",
    "\n",
    "**Where to get started**:\n",
    "- Website: https://x.ai (currently limited availability)\n",
    "- API access is expanding gradually\n",
    "- Check their developer platform for updates\n",
    "\n",
    "**Best for**: Projects involving social media data, conversational applications\n",
    "\n",
    "---\n",
    "\n",
    "3. **Kimi** (Moonshot AI - China)\n",
    "**What makes it special**: Exceptional long context window (can handle very long documents), strong multilingual capabilities.\n",
    "\n",
    "**Where to get started**:\n",
    "- Website: https://platform.moonshot.cn\n",
    "- Primarily Chinese interface, but supports English\n",
    "- Create account and navigate to API section\n",
    "\n",
    "**Best for**: Processing long documents, multilingual projects\n",
    "\n",
    "---\n",
    "\n",
    "4. **Cohere**\n",
    "**What makes it special**: Enterprise-focused with strong text embedding and classification capabilities, excellent documentation for developers.\n",
    "\n",
    "**Where to get started**:\n",
    "- Website: https://cohere.com\n",
    "- Click \"Get Started\" or \"Sign Up\"\n",
    "- Dashboard â†’ API Keys\n",
    "- Generous free trial tier for learning\n",
    "\n",
    "**Best for**: Text classification, semantic search, embeddings\n",
    "\n",
    "---\n",
    "\n",
    "#### Popular Open Source LLMs to Explore\n",
    "\n",
    "5. **Mistral** (France)\n",
    "**What makes it special**: High-quality European alternative, various model sizes, strong performance-to-cost ratio.\n",
    "\n",
    "**Where to get started**:\n",
    "- Website: https://console.mistral.ai\n",
    "- Create account\n",
    "- API Keys section\n",
    "- Also offers open-source models you can download\n",
    "\n",
    "**Best for**: European data residency needs, cost-effective experimentation\n",
    "\n",
    "---\n",
    "\n",
    "6. **Meta Llama Models**\n",
    "**What makes it special**: One of the most popular open-source model families, constantly improving, large community support.\n",
    "\n",
    "**How to access**:\n",
    "- **Through APIs**: Many providers host Llama (Together AI, Replicate, Groq)\n",
    "- **Together AI**: https://together.ai - Easy API access\n",
    "- **Replicate**: https://replicate.com - Pay-per-use\n",
    "- **Groq**: https://groq.com - Ultra-fast inference\n",
    "- **Run locally**: Download from Hugging Face (requires powerful hardware)\n",
    "\n",
    "**Best for**: Learning about open-source models, community projects\n",
    "\n",
    "---\n",
    "\n",
    "7. **Hugging Face** (Platform)\n",
    "**What makes it special**: Not a single model, but a platform hosting thousands of open-source models. Think of it as the GitHub of AI models.\n",
    "\n",
    "**Where to get started**:\n",
    "- Website: https://huggingface.co\n",
    "- Create free account\n",
    "- Settings â†’ Access Tokens\n",
    "- Access thousands of models through their API\n",
    "\n",
    "**Best for**: Experimenting with many different models, learning about model varieties\n",
    "\n",
    "---\n",
    "\n",
    "#### Quick Comparison Overview\n",
    "\n",
    "**DeepSeek** is a closed-source model with very low cost, excellent for coding and math. It's highly recommended for beginners looking for great value.\n",
    "\n",
    "**Grok** is a closed-source model with medium pricing that excels at real-time data access. However, it currently has limited availability, so it may not be the best starting point for beginners.\n",
    "\n",
    "**Kimi** is a closed-source model with medium pricing, exceptional at handling long context. The primarily Chinese interface might present a learning curve for some students.\n",
    "\n",
    "**Cohere** is a closed-source model that offers a generous free tier and excellent documentation. It specializes in embeddings and is very beginner-friendly.\n",
    "\n",
    "**Mistral** is an open-source model with low cost and easy-to-use APIs. It's a great European alternative and recommended for beginners.\n",
    "\n",
    "**Llama** (Meta) is an open-source model that's either free or low-cost depending on how you access it. With massive community support and widespread popularity, it's excellent for beginners wanting to explore open-source options.\n",
    "\n",
    "**Hugging Face** is a platform (not a single model) with varying costs depending on which model you use. It's highly educational and perfect for beginners who want to explore the variety of available models.\n",
    "\n",
    "---\n",
    "\n",
    "#### Tips for Experimenting with Multiple LLMs\n",
    "\n",
    "**Start with free tiers**: Most services offer free credits or trials - take advantage of these for learning.\n",
    "\n",
    "**Use environment variables**: Store all your API keys in your `.env` file:\n",
    "```\n",
    "OPENAI_API_KEY=your_key_here\n",
    "ANTHROPIC_API_KEY=your_key_here\n",
    "DEEPSEEK_API_KEY=your_key_here\n",
    "MISTRAL_API_KEY=your_key_here\n",
    "```\n",
    "\n",
    "**Compare outputs**: Run the same prompt through different models to see how they differ in responses, speed, and cost.\n",
    "\n",
    "**Set spending limits**: Always configure budget alerts on platforms that support them.\n",
    "\n",
    "**Read the documentation**: Each LLM has different capabilities - check their docs to understand what they do best.\n",
    "\n",
    "**Join communities**: Many of these models have Discord servers or forums where you can learn from other users.\n",
    "\n",
    "---\n",
    "\n",
    "#### Why Experiment with Different Models?\n",
    "\n",
    "**Learn flexibility**: In real-world projects, you'll often need to choose the right model for specific tasks.\n",
    "\n",
    "**Cost optimization**: Some models are much cheaper for certain tasks.\n",
    "\n",
    "**Understand trade-offs**: You'll learn about the balance between speed vs. quality, and cost vs. capability.\n",
    "\n",
    "**Avoid vendor lock-in**: Don't depend on just one provider - diversify your skills.\n",
    "\n",
    "**Expand your skillset**: Each API has slight differences - learning multiple makes you more versatile as a developer.\n",
    "\n",
    "\n",
    "Remember: you don't need to sign up for everything at once. Start with 2-3 models and expand as you get more comfortable with LangChain. Each new model you learn adds another tool to your AI development toolkit!\n",
    "\n",
    "Happy experimenting! ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56598bb-0334-4309-9372-7885684084ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
