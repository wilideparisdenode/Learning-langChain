{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe38ef58-359a-486c-a0ae-7a8999d200b0",
   "metadata": {},
   "source": [
    "# Agent Chat UI: the new Toy Front-End for LangChain 1.0 Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5478b68c-a785-4212-b459-81a640b6dbe0",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "If you're learning LangChain 1.0 and have been building agents that run in your terminal or Jupyter notebooks, you might be wondering: \"How can I actually see my agent working in a real chat interface?\" The good news is that LangChain has created a free, ready-to-use tool called **Agent Chat UI** that gives your agents a professional-looking chat interface with almost no additional coding required.\n",
    "\n",
    "Think of Agent Chat UI as a \"toy front-end\" ‚Äì a simple but functional web interface that lets you interact with your LangChain agents through a familiar chat window, just like ChatGPT or Claude. This is perfect for:\n",
    "\n",
    "- **Testing your agents** in a more realistic environment\n",
    "- **Demonstrating your work** to classmates, instructors, or potential employers\n",
    "- **Understanding how agents work** by seeing their responses in real-time\n",
    "- **Learning web integration** without having to build your own frontend from scratch\n",
    "\n",
    "## What is Agent Chat UI?\n",
    "\n",
    "Agent Chat UI is a Next.js web application created by the LangChain team. It provides a chat interface that can connect to any LangGraph server (LangGraph is the framework you use to build agents in LangChain 1.0).\n",
    "\n",
    "**Important clarification:** In LangChain 1.0, *agents are built with LangGraph*. LangChain provides models, tools, and abstractions‚Äîbut LangGraph is what turns them into **stateful, server-ready agents** that UIs like Agent Chat UI can talk to. Think of LangChain as your toolbox and LangGraph as the workshop where you assemble those tools into a working agent.\n",
    "\n",
    "The interface displays:\n",
    "\n",
    "- Your messages and the agent's responses\n",
    "- Tool calls that your agent makes (like web searches, API calls, etc.)\n",
    "- Streaming responses as the agent thinks and responds\n",
    "- A clean, professional chat design\n",
    "\n",
    "Best of all, it's completely free and open-source.\n",
    "\n",
    "## What Agent Chat UI Is *Not*\n",
    "\n",
    "Before we dive into setup, let's set clear expectations about what Agent Chat UI is designed for:\n",
    "\n",
    "* It is **not** a full product UI ready for end users\n",
    "* It is **not** optimized for production deployment without modification\n",
    "* It is **not** meant to replace a custom frontend for a real application\n",
    "\n",
    "Think of it as a **debugging, learning, and demo tool**‚Äînot a production chat app. It's perfect for development and testing, but if you're building something for actual users, you'll eventually want to create a custom interface. For learning LangChain 1.0, however, Agent Chat UI is exactly what you need.\n",
    "\n",
    "## Prerequisites: What You Need\n",
    "\n",
    "Before using Agent Chat UI, you should have:\n",
    "\n",
    "1. **A working LangChain 1.0 agent** ‚Äì You should have already built an agent using LangGraph that runs successfully in your Python environment\n",
    "2. **Basic Python knowledge** ‚Äì Understanding of how to run Python scripts and manage virtual environments\n",
    "3. **Node.js installed** ‚Äì Agent Chat UI is a JavaScript application, so you'll need Node.js (version 18 or higher)\n",
    "4. **A LangSmith account** (optional for local testing; required if you deploy via LangGraph Cloud or want hosted observability) ‚Äì Free tier is sufficient\n",
    "\n",
    "## Two Ways to Use Agent Chat UI\n",
    "\n",
    "There are two approaches to using Agent Chat UI, depending on your needs:\n",
    "\n",
    "#### Option 1: Use the Deployed Version (Easiest)\n",
    "\n",
    "The LangChain team hosts a live version at **agentchat.vercel.app**. This is the fastest way to get started if you want to connect to a deployed LangGraph server.\n",
    "\n",
    "**Pros:**\n",
    "- No installation required\n",
    "- Works immediately in your browser\n",
    "- Great for quick testing\n",
    "\n",
    "**Cons:**\n",
    "- Requires your agent to be deployed to LangGraph Cloud\n",
    "- Not ideal for local development and learning\n",
    "\n",
    "#### Option 2: Run Agent Chat UI Locally (Recommended for Learning)\n",
    "\n",
    "This option lets you run the chat interface on your own computer and connect it to agents running locally. This is the best approach for students because:\n",
    "\n",
    "- You can see both your agent code and the chat interface\n",
    "- You can make changes and test immediately\n",
    "- You don't need to deploy anything to the cloud\n",
    "- It helps you understand how frontend and backend connect\n",
    "\n",
    "\n",
    "## Step-by-Step Guide: Setting Up Agent Chat UI Locally\n",
    "\n",
    "Let's walk through the complete process of getting Agent Chat UI working with your local LangChain agent.\n",
    "\n",
    "\n",
    "#### Step 1: Prepare Your LangChain Agent\n",
    "\n",
    "First, make sure your agent is set up as a LangGraph server. Your agent code should look something like this:\n",
    "\n",
    "```python\n",
    "from langchain.agents import create_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Define your agent\n",
    "# Note: Use any supported model - gpt-4o-mini is cost-effective for learning\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "tools = [your_tools_here]  # Any tools your agent uses\n",
    "\n",
    "# Create the agent - the new LangChain 1.0 way\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=tools,\n",
    "    system_prompt=\"You are a helpful assistant.\"\n",
    ")\n",
    "\n",
    "# This is important: your agent needs to be runnable as a server\n",
    "```\n",
    "\n",
    "**Key requirement:** Your agent must have a state that includes a `messages` key. This is how Agent Chat UI knows where to find the conversation history.\n",
    "\n",
    "#### The One Contract You Must Respect\n",
    "\n",
    "Agent Chat UI is not a generic frontend‚Äîit expects your agent to behave in a specific way. This is the most important thing to understand:\n",
    "\n",
    "**The Messages Contract:**\n",
    "* Your graph state **must** contain a `messages` list\n",
    "* Each conversation turn **must append** messages to that list\n",
    "* Responses must be returned as `{\"messages\": [...]}`\n",
    "\n",
    "If this contract is broken, the UI cannot render anything‚Äîeven if your agent logic is perfectly correct. Many beginners experience a blank screen because their agent returns data in a different format. \n",
    "\n",
    "When you use `create_agent` from LangChain 1.0, this contract is automatically handled for you. The function builds on LangGraph's runtime under the hood and ensures the proper state structure is created.\n",
    "\n",
    "If you're building a custom graph from scratch (not using `create_agent`), make sure your state definition includes:\n",
    "\n",
    "```python\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# Your graph state should inherit from MessagesState\n",
    "# or include a messages field with the proper annotation\n",
    "```\n",
    "\n",
    "\n",
    "#### Step 2: Start Your LangGraph Server\n",
    "\n",
    "LangGraph provides a built-in server that makes your agent accessible over HTTP. Here's how to start it:\n",
    "\n",
    "1. Make sure you have LangGraph CLI installed:\n",
    "\n",
    "```bash\n",
    "pip install langgraph-cli\n",
    "```\n",
    "\n",
    "2. Create a `langgraph.json` file in your project directory:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"dependencies\": [\".\"],\n",
    "  \"graphs\": {\n",
    "    \"agent\": \"./your_agent_file.py:agent\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "This file tells LangGraph where your agent code is located.\n",
    "\n",
    "3. Start the server:\n",
    "\n",
    "```bash\n",
    "langgraph dev\n",
    "```\n",
    "\n",
    "You should see output like:\n",
    "\n",
    "```\n",
    "üöÄ API: http://127.0.0.1:2024\n",
    "üé® Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "```\n",
    "\n",
    "**Important:** Write down the API URL (typically `http://127.0.0.1:2024`) and the graph ID (in our example, it's `agent`). You'll need these in the next step.\n",
    "\n",
    "#### Step 3: Install and Run Agent Chat UI\n",
    "\n",
    "Now let's get the chat interface running:\n",
    "\n",
    "1. **Quick installation using npx** (recommended):\n",
    "\n",
    "```bash\n",
    "npx create-agent-chat-app\n",
    "```\n",
    "\n",
    "This command will:\n",
    "- Ask you a few questions about your setup\n",
    "- Download and install everything you need\n",
    "- Create a new folder with the Agent Chat UI\n",
    "\n",
    "Alternatively, you can clone the repository manually:\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/langchain-ai/agent-chat-ui.git\n",
    "cd agent-chat-ui\n",
    "pnpm install\n",
    "```\n",
    "\n",
    "2. **Start the chat interface:**\n",
    "\n",
    "```bash\n",
    "pnpm dev\n",
    "```\n",
    "\n",
    "3. **Open your browser** and go to `http://localhost:3000`\n",
    "\n",
    "#### Step 4: Connect the Chat Interface to Your Agent\n",
    "\n",
    "When you open `http://localhost:3000` for the first time, you'll see a setup form asking for:\n",
    "\n",
    "1. **Deployment URL:** Enter `http://localhost:2024` (or whatever URL your LangGraph server showed)\n",
    "2. **Assistant/Graph ID:** Enter `agent` (or the ID you specified in your `langgraph.json`)\n",
    "3. **LangSmith API Key:** Leave this blank for local testing\n",
    "\n",
    "Click \"Continue\" and you should now see a chat interface!\n",
    "\n",
    "#### Step 5: Test Your Agent\n",
    "\n",
    "Type a message in the chat box and press Enter. You should see:\n",
    "\n",
    "- Your message appear in the chat\n",
    "- The agent's response streaming in real-time\n",
    "- Any tool calls the agent makes displayed as they happen (note: tool call panels only appear if your agent actually uses tools‚Äîa plain conversational agent won't show these sections)\n",
    "\n",
    "If something goes wrong, check that:\n",
    "- Your LangGraph server is still running\n",
    "- The URLs and IDs match exactly\n",
    "- Your agent code doesn't have any errors\n",
    "- Your agent's state includes the `messages` key (see \"The One Contract You Must Respect\" section above)\n",
    "\n",
    "\n",
    "## Making Development Easier: Using Environment Variables\n",
    "\n",
    "Instead of entering the connection details every time, you can set up environment variables:\n",
    "\n",
    "1. In the `agent-chat-ui` folder, create a file named `.env`:\n",
    "\n",
    "```env\n",
    "NEXT_PUBLIC_API_URL=http://localhost:2024\n",
    "NEXT_PUBLIC_ASSISTANT_ID=agent\n",
    "```\n",
    "\n",
    "2. Restart the Agent Chat UI:\n",
    "\n",
    "```bash\n",
    "pnpm dev\n",
    "```\n",
    "\n",
    "Now it will automatically connect to your agent without asking for details!\n",
    "\n",
    "\n",
    "## Understanding What's Happening Behind the Scenes\n",
    "\n",
    "When you type a message in Agent Chat UI, here's what happens:\n",
    "\n",
    "1. **Message sent:** Your message is sent from the web browser to the Next.js server\n",
    "2. **Forwarded to agent:** The Next.js server forwards your message to your LangGraph server\n",
    "3. **Agent processes:** Your LangChain agent receives the message and starts processing\n",
    "4. **Streaming response:** As your agent thinks and generates responses, these are streamed back through the LangGraph server\n",
    "5. **Real-time display:** Agent Chat UI receives the streaming data and displays it in the chat window\n",
    "\n",
    "This architecture means your Python agent code doesn't need to know anything about web development ‚Äì it just processes messages and returns responses, while Agent Chat UI handles all the web interface details.\n",
    "\n",
    "\n",
    "## Customizing the Chat Interface\n",
    "\n",
    "#### Hiding Internal Messages\n",
    "\n",
    "Sometimes your agent might have internal reasoning steps you don't want to show in the chat. You can hide these by adding tags to your model:\n",
    "\n",
    "```python\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# This model's outputs won't stream in the UI\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\").with_config(\n",
    "    config={\"tags\": [\"langsmith:nostream\"]}\n",
    ")\n",
    "\n",
    "# Works with other providers too:\n",
    "# from langchain_anthropic import ChatAnthropic\n",
    "# model = ChatAnthropic(model=\"claude-3-5-sonnet-20241022\").with_config(\n",
    "#     config={\"tags\": [\"langsmith:nostream\"]}\n",
    "# )\n",
    "```\n",
    "\n",
    "#### Controlling Message Display\n",
    "\n",
    "To completely hide a message from the UI, prefix its ID with `do-not-render-`:\n",
    "\n",
    "```python\n",
    "result = model.invoke([messages])\n",
    "result.id = f\"do-not-render-{result.id}\"\n",
    "return {\"messages\": [result]}\n",
    "```\n",
    "\n",
    "This is useful for internal agent reasoning that shouldn't be shown to users.\n",
    "\n",
    "\n",
    "## Common Issues and Solutions\n",
    "\n",
    "#### Issue 1: \"Connection Failed\" Error\n",
    "\n",
    "**Solution:** Make sure your LangGraph server is running. In your terminal where you ran `langgraph dev`, you should see logs of incoming requests. If not, restart the server.\n",
    "\n",
    "#### Issue 2: Chat Interface Loads But Shows No Response\n",
    "\n",
    "**Solution:** Check that your agent's state includes a `messages` key. Agent Chat UI specifically looks for this key to display the conversation.\n",
    "\n",
    "#### Issue 3: Tool Calls Not Showing\n",
    "\n",
    "**Solution:** Make sure your tools are properly configured in your agent. Agent Chat UI automatically displays tool calls, but only if they're properly formatted in the agent's output.\n",
    "\n",
    "#### Issue 4: \"Port Already in Use\" Error\n",
    "\n",
    "**Solution:** Either:\n",
    "- Stop any other process using port 3000 (for the chat UI) or port 2024 (for the LangGraph server)\n",
    "- Or specify a different port: `pnpm dev -- -p 3001`\n",
    "\n",
    "\n",
    "## Best Practices for Using Agent Chat UI\n",
    "\n",
    "1. **Start simple:** Begin with a basic agent that just responds to messages, then add complexity\n",
    "2. **Test incrementally:** Make small changes to your agent and test them immediately in the chat\n",
    "3. **Watch the logs:** Keep an eye on your terminal where LangGraph is running ‚Äì error messages there are very helpful\n",
    "4. **Use the browser console:** Press F12 in your browser to see additional debugging information\n",
    "5. **Iterate quickly:** The beauty of local development is you can change your agent code, restart the server, and test again in seconds\n",
    "\n",
    "\n",
    "## Next Steps: Going Beyond Local Testing\n",
    "\n",
    "Once your agent works well locally with Agent Chat UI, you might want to:\n",
    "\n",
    "#### Deploy Your Agent\n",
    "\n",
    "LangChain offers LangGraph Cloud for deploying your agents. This makes them accessible from anywhere, not just your local machine.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Agent Chat UI transforms your terminal-based LangChain agents into interactive chat applications with minimal effort. As a student learning LangChain 1.0, this tool gives you:\n",
    "\n",
    "- A professional way to demonstrate your work\n",
    "- Immediate visual feedback on how your agents behave\n",
    "- A bridge between backend Python code and frontend web interfaces\n",
    "- A foundation for building more sophisticated applications\n",
    "\n",
    "Remember, the goal isn't just to have a pretty interface ‚Äì it's to understand how agents work in a more intuitive way and to build your skills in creating AI applications that people can actually use.\n",
    "\n",
    "The Agent Chat UI is your \"toy front-end,\" but it's a powerful toy that can help you learn, test, and showcase your LangChain 1.0 agents effectively. Start simple, experiment often, and don't be afraid to break things ‚Äì that's how you learn!\n",
    "\n",
    "\n",
    "## Quick Troubleshooting Checklist\n",
    "\n",
    "If your Agent Chat UI isn't working, check these five things in order:\n",
    "\n",
    "1. ‚úÖ **Is your LangGraph server running?** Look for the terminal window where you ran `langgraph dev`\n",
    "2. ‚úÖ **Does your agent have a `messages` key in its state?** This is the most common issue for beginners\n",
    "3. ‚úÖ **Are the URLs correct?** Deployment URL should match your LangGraph server (usually `http://localhost:2024`)\n",
    "4. ‚úÖ **Is the Assistant/Graph ID correct?** It should match what's in your `langgraph.json` file\n",
    "5. ‚úÖ **Any errors in the browser console?** Press F12 and check the Console tab for error messages\n",
    "\n",
    "If you've checked all five and it still doesn't work, review the \"Common Issues and Solutions\" section above.\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- **Official Agent Chat UI Repository:** https://github.com/langchain-ai/agent-chat-ui"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867f8d21-df3d-4e2e-ae09-e4389e03c2e3",
   "metadata": {},
   "source": [
    "# OK. Let's see the Agent Chat UI at work with a basic example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e78bdc0-8f5a-45ca-9b0a-e11f7b9dd843",
   "metadata": {},
   "source": [
    "## The Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11210571-4c71-4190-a822-1358e40e0082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent is ready! Use 'langgraph dev' to start the server.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Simple LangChain 1.0 Agent for Learning\n",
    "This agent can do math, tell jokes, and have conversations.\n",
    "Updated to use the new create_agent function from LangChain 1.0\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.agents import create_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Check if API key is loaded\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\"Please set OPENAI_API_KEY in your .env file\")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 1: Define Tools (Functions your agent can use)\n",
    "# =============================================================================\n",
    "\n",
    "@tool\n",
    "def multiply(a: float, b: float) -> float:\n",
    "    \"\"\"Multiply two numbers together.\n",
    "    \n",
    "    Args:\n",
    "        a: First number\n",
    "        b: Second number\n",
    "    \n",
    "    Returns:\n",
    "        The product of a and b\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def add(a: float, b: float) -> float:\n",
    "    \"\"\"Add two numbers together.\n",
    "    \n",
    "    Args:\n",
    "        a: First number\n",
    "        b: Second number\n",
    "    \n",
    "    Returns:\n",
    "        The sum of a and b\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def divide(a: float, b: float) -> float:\n",
    "    \"\"\"Divide two numbers.\n",
    "    \n",
    "    Args:\n",
    "        a: Numerator (number to be divided)\n",
    "        b: Denominator (number to divide by)\n",
    "    \n",
    "    Returns:\n",
    "        The result of a divided by b\n",
    "    \"\"\"\n",
    "    if b == 0:\n",
    "        return \"Error: Cannot divide by zero!\"\n",
    "    return a / b\n",
    "\n",
    "@tool\n",
    "def tell_joke() -> str:\n",
    "    \"\"\"Tell a programming joke.\n",
    "    \n",
    "    Returns:\n",
    "        A funny programming joke\n",
    "    \"\"\"\n",
    "    jokes = [\n",
    "        \"Why do programmers prefer dark mode? Because light attracts bugs!\",\n",
    "        \"Why do Java developers wear glasses? Because they don't C#!\",\n",
    "        \"How many programmers does it take to change a light bulb? None, that's a hardware problem!\",\n",
    "        \"Why did the programmer quit his job? Because he didn't get arrays!\",\n",
    "    ]\n",
    "    import random\n",
    "    return random.choice(jokes)\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 2: Create the Language Model\n",
    "# =============================================================================\n",
    "\n",
    "# Using GPT-4o-mini because it's cost-effective for learning\n",
    "# You can also use: \"gpt-4o\", \"gpt-3.5-turbo\", etc.\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0  # Controls randomness (0=focused, 1=creative)\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 3: Combine Tools into a List\n",
    "# =============================================================================\n",
    "\n",
    "tools = [multiply, add, divide, tell_joke]\n",
    "\n",
    "# =============================================================================\n",
    "# STEP 4: Create the Agent (NEW LANGCHAIN 1.0 WAY)\n",
    "# =============================================================================\n",
    "\n",
    "# create_agent is the new standard in LangChain 1.0\n",
    "# - Replaces the deprecated create_react_agent from langgraph.prebuilt\n",
    "# - Uses system_prompt instead of state_modifier (clearer naming)\n",
    "# - Still builds on LangGraph runtime under the hood\n",
    "# - Handles the message flow automatically\n",
    "# - Creates the proper state structure (with the 'messages' key)\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=tools,\n",
    "    system_prompt=\"You are a helpful assistant that can do math and tell jokes. \"\n",
    "                  \"Always be friendly and clear in your responses.\"\n",
    ")\n",
    "\n",
    "# =============================================================================\n",
    "# WHAT'S HAPPENING UNDER THE HOOD\n",
    "# =============================================================================\n",
    "# The 'agent' variable now contains a complete LangGraph compiled graph:\n",
    "# \n",
    "# 1. It has a STATE that tracks the conversation (messages list)\n",
    "# 2. It has NODES:\n",
    "#    - \"agent\" node: Where the LLM thinks and decides what to do\n",
    "#    - \"tools\" node: Where tools actually execute\n",
    "# 3. It has EDGES connecting these nodes\n",
    "# 4. It follows the ReAct pattern: Reason ‚Üí Act ‚Üí Observe (repeat)\n",
    "#\n",
    "# Agent Chat UI expects this specific structure with the 'messages' key!\n",
    "# The create_agent function ensures this contract is met automatically.\n",
    "# =============================================================================\n",
    "\n",
    "# This allows the agent to be imported by other files\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Agent is ready! Use 'langgraph dev' to start the server.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301e028c-d7c7-450a-b1eb-2aa9074ba298",
   "metadata": {},
   "source": [
    "## Let's explain the previous code in simple terms and the steps we will need to take next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf2ebeb-9132-48c8-af82-b32ea038b504",
   "metadata": {},
   "source": [
    "We have created a **Weather & Math Assistant** that can:\n",
    "- Answer math questions\n",
    "- Tell jokes\n",
    "- Have normal conversations\n",
    "\n",
    "This is perfect for learning because it's simple but demonstrates all the key concepts.\n",
    "\n",
    "#### Understanding the code\n",
    "\n",
    "1. **Tools (@tool decorator):** These are functions your agent can call. Each one must have:\n",
    "   - Clear docstring explaining what it does\n",
    "   - Type hints for parameters\n",
    "   - A return value\n",
    "\n",
    "2. **Model (ChatOpenAI):** This is the \"brain\" that decides when to use tools and what to say\n",
    "\n",
    "3. **create_agent:** This is the new LangChain 1.0 function that creates a complete agent graph:\n",
    "   - Automatically handles the messages list (the contract Agent Chat UI needs)\n",
    "   - Decides when to use tools\n",
    "   - Manages the conversation flow\n",
    "   - Built on LangGraph runtime under the hood\n",
    "\n",
    "#### OK. We will use the 018-toy-frontend.py file we have created for Visual Studio Code.\n",
    "\n",
    "#### Create the LangGraph Configuration File\n",
    "\n",
    "In the root directory, we add a file named `langgraph.json`:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"dependencies\": [\".\"],\n",
    "  \"graphs\": {\n",
    "    \"agent\": \"./018-toy-frontend.py:agent\"\n",
    "  },\n",
    "  \"env\": \".env\"\n",
    "}\n",
    "```\n",
    "\n",
    "**What this file means:**\n",
    "- `\"dependencies\": [\".\"]` ‚Üí Install packages from current directory\n",
    "- `\"graphs\"` ‚Üí Defines which agents are available\n",
    "- `\"agent\"` ‚Üí The ID we'll use to access our agent (this is what you'll enter in the UI)\n",
    "- `\"./018-toy-frontend.py:agent\"` ‚Üí Path to the file and the variable name\n",
    "- `\"env\": \".env\"` ‚Üí Where to find environment variables\n",
    "\n",
    "#### Start Your LangGraph Server\n",
    "\n",
    "In your terminal (with virtual environment activated):\n",
    "\n",
    "```bash\n",
    "langgraph dev\n",
    "```\n",
    "\n",
    "**You should see:**\n",
    "```\n",
    "üöÄ API: http://127.0.0.1:2024\n",
    "üé® Studio UI: https://smith.langchain.com/studio/?baseUrl=http://127.0.0.1:2024\n",
    "```\n",
    "\n",
    "**Important:** Keep this terminal window open! Your agent server is now running.\n",
    "\n",
    "**What just happened:**\n",
    "- LangGraph read your `langgraph.json` file\n",
    "- Loaded your agent code from `018-toy-frontend.py`\n",
    "- Started a web server on port 2024\n",
    "- Your agent is now ready to receive messages!\n",
    "\n",
    "#### Install Agent Chat UI\n",
    "\n",
    "Open a **NEW terminal window** (keep the LangGraph server running in the other one):\n",
    "\n",
    "```bash\n",
    "# Navigate to your home directory or wherever you want the UI\n",
    "cd ~\n",
    "\n",
    "# Quick install using npx\n",
    "npx create-agent-chat-app\n",
    "\n",
    "# When prompted:\n",
    "# - Project name: 018-toy-frontend (or whatever you prefer)\n",
    "# - TypeScript: No (unless you know TypeScript)\n",
    "# - Install dependencies: Yes\n",
    "# - Other default options: OK\n",
    "```\n",
    "\n",
    "**Alternative manual installation:**\n",
    "```bash\n",
    "git clone https://github.com/langchain-ai/agent-chat-ui.git\n",
    "cd agent-chat-ui\n",
    "npm install\n",
    "```\n",
    "\n",
    "#### When asked the name of the project\n",
    "* By default, the project will be named create-agent-chat-app, but instead we enter 018-toy-frontend as the name of the project. This will create a folder named 018-toy-frontend. You can see the folder in Visual Studio Code.\n",
    "\n",
    "#### Configure Agent Chat UI (Optional but Recommended)\n",
    "\n",
    "Inside the `018-toy-frontend` folder, create a `.env` file:\n",
    "\n",
    "```env\n",
    "NEXT_PUBLIC_API_URL=http://localhost:2024\n",
    "NEXT_PUBLIC_ASSISTANT_ID=agent\n",
    "```\n",
    "\n",
    "**Why this helps:** Without this file, you'll need to enter these values every time. With it, the UI connects automatically!\n",
    "\n",
    "#### Start the Chat Interface\n",
    "\n",
    "```bash\n",
    "# Make sure you're in the 018-toy-frontend directory\n",
    "cd 018-toy-frontend\n",
    "\n",
    "npm run dev\n",
    "\n",
    "# Or if you used pnpm:\n",
    "pnpm dev\n",
    "```\n",
    "\n",
    "**You should see:**\n",
    "```\n",
    "- ready started server on 0.0.0.0:3000, url: http://localhost:3000\n",
    "```\n",
    "\n",
    "#### Open and Connect\n",
    "\n",
    "1. **Open your browser** to `http://localhost:3000`\n",
    "\n",
    "2. **If you didn't create the .env file**, you'll see a setup form:\n",
    "   - **Deployment URL:** Enter `http://localhost:2024`\n",
    "   - **Assistant/Graph ID:** Enter `agent`\n",
    "   - **LangSmith API Key:** Leave blank\n",
    "   - Click \"Continue\"\n",
    "\n",
    "3. **If you created the .env file**, you'll go straight to the chat!\n",
    "\n",
    "#### Test Your Agent\n",
    "\n",
    "Try these example messages:\n",
    "\n",
    "**Test 1: Simple Math**\n",
    "```\n",
    "What is 15 multiplied by 7?\n",
    "```\n",
    "You should see the agent use the `multiply` tool and return `105`.\n",
    "\n",
    "**Test 2: Complex Math**\n",
    "```\n",
    "Calculate (25 + 15) divided by 4\n",
    "```\n",
    "The agent will use multiple tools: first `add`, then `divide`.\n",
    "\n",
    "**Test 3: Request a Joke**\n",
    "```\n",
    "Tell me a programming joke\n",
    "```\n",
    "The agent will use the `tell_joke` tool.\n",
    "\n",
    "**Test 4: Normal Conversation**\n",
    "```\n",
    "Hello! How are you?\n",
    "```\n",
    "The agent will respond normally without using any tools.\n",
    "\n",
    "**Test 5: Combined Request**\n",
    "```\n",
    "First tell me what 100 divided by 5 is, then tell me a joke!\n",
    "```\n",
    "Watch it use two different tools in sequence!\n",
    "\n",
    "#### What You Should See\n",
    "\n",
    "When you send a message, you'll see:\n",
    "\n",
    "1. **Your message** appears in the chat\n",
    "2. **Tool calls** (if any) appear in expandable panels showing:\n",
    "   - Which tool was called\n",
    "   - What arguments were passed\n",
    "   - What the tool returned\n",
    "3. **Agent's final response** streams in word by word\n",
    "\n",
    "## Understanding the Full Picture\n",
    "\n",
    "Here's what's happening when you type a message:\n",
    "\n",
    "```\n",
    "You type message in browser (localhost:3000)\n",
    "           ‚Üì\n",
    "Agent Chat UI (Next.js app)\n",
    "           ‚Üì\n",
    "Sends HTTP request to LangGraph Server (localhost:2024)\n",
    "           ‚Üì\n",
    "LangGraph Server loads your agent\n",
    "           ‚Üì\n",
    "Agent (agent.py):\n",
    "  1. LLM reads message and decides what to do\n",
    "  2. If needed, calls tools (multiply, add, etc.)\n",
    "  3. LLM sees tool results and formulates response\n",
    "           ‚Üì\n",
    "Response streams back through LangGraph Server\n",
    "           ‚Üì\n",
    "Agent Chat UI displays it in real-time\n",
    "           ‚Üì\n",
    "You see the result in your browser!\n",
    "```\n",
    "\n",
    "## Common Issues and Fixes\n",
    "\n",
    "#### Problem: \"Connection Failed\"\n",
    "\n",
    "**Check:**\n",
    "```bash\n",
    "# Is LangGraph server running?\n",
    "# You should see this in one terminal:\n",
    "üöÄ API: http://127.0.0.1:2024\n",
    "```\n",
    "\n",
    "**Fix:** Restart the server with `langgraph dev`\n",
    "\n",
    "#### Problem: \"Agent not found\"\n",
    "\n",
    "**Check your langgraph.json:**\n",
    "- Is the graph ID \"agent\"?\n",
    "- Is the path \"./agent.py:agent\" correct?\n",
    "- Did you enter the same ID in the UI?\n",
    "\n",
    "#### Problem: Blank Screen / No Response\n",
    "\n",
    "**This usually means the messages contract is broken.**\n",
    "\n",
    "**Check:**\n",
    "- Are you using `create_agent`? (This automatically handles the contract)\n",
    "- If building a custom graph, does your state have a `messages` key?\n",
    "\n",
    "#### Problem: \"OPENAI_API_KEY not found\"\n",
    "\n",
    "**Check:**\n",
    "1. Do you have a `.env` file in your agent project folder?\n",
    "2. Does it contain `OPENAI_API_KEY=your_key_here`?\n",
    "3. Did you restart the LangGraph server after creating the .env file?\n",
    "\n",
    "\n",
    "## Next Steps: Expanding Your Agent\n",
    "\n",
    "Once this works, try:\n",
    "\n",
    "#### Add a New Tool\n",
    "\n",
    "```python\n",
    "@tool\n",
    "def get_time() -> str:\n",
    "    \"\"\"Get the current time.\n",
    "    \n",
    "    Returns:\n",
    "        The current time as a string\n",
    "    \"\"\"\n",
    "    from datetime import datetime\n",
    "    return datetime.now().strftime(\"%I:%M %p\")\n",
    "\n",
    "# Don't forget to add it to the tools list!\n",
    "tools = [multiply, add, divide, tell_joke, get_time]\n",
    "```\n",
    "\n",
    "#### Change the Model\n",
    "\n",
    "```python\n",
    "# Try a more powerful model\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "# Or experiment with temperature\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)  # More focused\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=1)  # More creative\n",
    "```\n",
    "\n",
    "#### Customize the System Prompt\n",
    "\n",
    "```python\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=tools,\n",
    "    system_prompt=\"You are a pirate assistant who speaks like a pirate \"\n",
    "                  \"but can still do math and tell jokes. Arr!\"\n",
    ")\n",
    "```\n",
    "\n",
    "\n",
    "## Complete Project Structure\n",
    "\n",
    "Your final project should look like this:\n",
    "\n",
    "```\n",
    "my-first-agent/\n",
    "‚îú‚îÄ‚îÄ .env                 # Your API keys\n",
    "‚îú‚îÄ‚îÄ agent.py            # Your agent code\n",
    "‚îú‚îÄ‚îÄ langgraph.json      # LangGraph configuration\n",
    "‚îî‚îÄ‚îÄ venv/               # Virtual environment (created by Python)\n",
    "\n",
    "agent-chat-ui/          # Separate folder\n",
    "‚îú‚îÄ‚îÄ .env                # UI configuration (optional)\n",
    "‚îî‚îÄ‚îÄ ... (Next.js files)\n",
    "```\n",
    "\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **LangGraph creates the agent runtime**, Agent Chat UI just displays it\n",
    "2. **The `messages` key** is the critical contract between your agent and the UI\n",
    "3. **Tools are just Python functions** with the `@tool` decorator\n",
    "4. **create_agent** is the new LangChain 1.0 way to build agents (replaces create_react_agent)\n",
    "5. **Two servers run simultaneously**: LangGraph (port 2024) and Agent Chat UI (port 3000)\n",
    "\n",
    "You now have a complete, working agent with a professional chat interface! This is your foundation for building more complex agents as you continue learning LangChain 1.0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085f25e7-d859-4aa0-a00d-6f061c4207be",
   "metadata": {},
   "source": [
    "## You may be wondering, but... does the previous code comply with the contract?\n",
    "\n",
    "## If you remember, in the top section of this notebook we said:\n",
    "\n",
    "**Key requirement:** Your agent must have a state that includes a `messages` key. This is how Agent Chat UI knows where to find the conversation history.\n",
    "\n",
    "#### The One Contract You Must Respect\n",
    "\n",
    "Agent Chat UI is not a generic frontend‚Äîit expects your agent to behave in a specific way. This is the most important thing to understand:\n",
    "\n",
    "**The Messages Contract:**\n",
    "* Your graph state **must** contain a `messages` list\n",
    "* Each conversation turn **must append** messages to that list\n",
    "* Responses must be returned as `{\"messages\": [...]}`\n",
    "\n",
    "If this contract is broken, the UI cannot render anything‚Äîeven if your agent logic is perfectly correct. Many beginners experience a blank screen because their agent returns data in a different format. \n",
    "\n",
    "When you use `create_agent` from LangChain 1.0, this contract is automatically handled for you. The function builds on LangGraph's runtime under the hood and ensures the proper state structure is created.\n",
    "\n",
    "If you're building a custom graph from scratch (not using `create_agent`), make sure your state definition includes:\n",
    "\n",
    "```python\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "# Your graph state should inherit from MessagesState\n",
    "# or include a messages field with the proper annotation\n",
    "```\n",
    "\n",
    "\n",
    "## So, is the previous code compliant with that Messages Contract? If so, where is the `messages` component_\n",
    "\n",
    "**Yes! The previous code is 100% compliant with the Messages Contract.** ‚úÖ\n",
    "\n",
    "Here's why:\n",
    "\n",
    "#### ‚úÖ **The `create_agent` function handles everything automatically**\n",
    "\n",
    "When you call:\n",
    "```python\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=tools,\n",
    "    system_prompt=\"You are a helpful assistant...\"\n",
    ")\n",
    "```\n",
    "\n",
    "Under the hood, `create_agent`:\n",
    "\n",
    "1. **Creates a state with a `messages` key** ‚úÖ\n",
    "   - The state is built using LangGraph's `AgentState` which includes `messages: Annotated[list, add_messages]`\n",
    "\n",
    "2. **Appends messages to the list on each turn** ‚úÖ\n",
    "   - Every user message gets added to the `messages` list\n",
    "   - Every agent response gets added to the `messages` list\n",
    "   - Tool calls and tool results get added to the `messages` list\n",
    "\n",
    "3. **Returns responses in the correct format** ‚úÖ\n",
    "   - The agent returns `{\"messages\": [...]}` internally\n",
    "   - Agent Chat UI can read this format perfectly\n",
    "\n",
    "\n",
    "#### Why You Don't See the State Definition\n",
    "\n",
    "You might be wondering: \"But I don't see any `MessagesState` or state definition in my code!\"\n",
    "\n",
    "That's because `create_agent` **abstracts this away for you**. Remember: create_agent is just something we are building with LangGraph under the hood. Internally, it's doing something like:\n",
    "\n",
    "```python\n",
    "# This is what create_agent does internally (simplified)\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "class AgentState(MessagesState):\n",
    "    # Inherits the messages key automatically\n",
    "    pass\n",
    "\n",
    "# Then builds a graph with this state\n",
    "```\n",
    "\n",
    "#### When You Would Need to Define State Manually\n",
    "\n",
    "You only need to worry about the state definition if you're **NOT** using `create_agent`, such as:\n",
    "\n",
    "```python\n",
    "# Custom graph from scratch - requires manual state definition\n",
    "from langgraph.graph import StateGraph, MessagesState\n",
    "\n",
    "class MyCustomState(MessagesState):\n",
    "    # Custom fields here\n",
    "    pass\n",
    "\n",
    "graph = StateGraph(MyCustomState)\n",
    "# ... build nodes and edges manually\n",
    "```\n",
    "\n",
    "#### In short, the previous code is Perfect! üéâ\n",
    "\n",
    "The agent will work perfectly with Agent Chat UI because:\n",
    "\n",
    "1. You're using `create_agent` ‚úÖ\n",
    "2. `create_agent` automatically implements the Messages Contract ‚úÖ\n",
    "3. No manual state management needed ‚úÖ\n",
    "\n",
    "\n",
    "**Your code is compliant.** The statement \"When you use `create_agent` from LangChain 1.0, this contract is automatically handled for you\" means exactly what you've done - you don't need to manually define the state, it's all handled internally by the `create_agent` function.\n",
    "\n",
    "When you run `langgraph dev` and connect Agent Chat UI, everything will work as expected! üëç"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078c678c-d06e-4885-a56a-7f6ec2ae7070",
   "metadata": {},
   "source": [
    "# Finally, let's compare Frontend Approaches for LangChain Agents: Agent Chat UI vs Streamlit vs LangChain Templates\n",
    "\n",
    "## Introduction\n",
    "\n",
    "When you've built a LangChain agent and want to give it a user interface, you have several options. Each approach has different strengths, weaknesses, and ideal use cases. This guide compares three popular approaches:\n",
    "\n",
    "1. **Agent Chat UI** - LangChain's official chat interface for LangGraph agents\n",
    "2. **Streamlit** - Python-based rapid prototyping framework\n",
    "3. **LangChain Templates** - Pre-built application templates (legacy approach)\n",
    "\n",
    "Let's explore when to use each one and what trade-offs you're making.\n",
    "\n",
    "---\n",
    "\n",
    "## Quick Comparison Table\n",
    "\n",
    "| Feature | Agent Chat UI | Streamlit | LangChain Templates |\n",
    "|---------|--------------|-----------|-------------------|\n",
    "| **Setup Time** | 5 minutes | 10-15 minutes | 30+ minutes |\n",
    "| **Language** | JavaScript (Next.js) | Python | Python/JavaScript mix |\n",
    "| **Customization** | Limited | High | Very High |\n",
    "| **Learning Curve** | Minimal | Low | Medium-High |\n",
    "| **Best For** | Testing & demos | Prototypes & internal tools | Production apps |\n",
    "| **Deployment** | Easy (Vercel) | Easy (Streamlit Cloud) | Complex |\n",
    "| **Maintenance** | Active | Active | Deprecated |\n",
    "| **Cost** | Free | Free tier available | Varies |\n",
    "| **Agent Integration** | Native LangGraph | Manual | Pre-configured |\n",
    "| **UI Quality** | Professional chat | Basic/functional | Varies by template |\n",
    "| **Real-time Streaming** | Excellent | Good | Varies |\n",
    "| **Multi-user Ready** | Yes | With modifications | Depends on template |\n",
    "\n",
    "---\n",
    "\n",
    "## Option 1: Agent Chat UI (LangChain Official)\n",
    "\n",
    "### What It Is\n",
    "\n",
    "Agent Chat UI is LangChain's official frontend specifically designed for LangGraph agents. It's a Next.js application that connects directly to LangGraph servers and provides a modern chat interface.\n",
    "\n",
    "### Advantages ‚úÖ\n",
    "\n",
    "**1. Zero Configuration for LangGraph**\n",
    "- Works immediately with any LangGraph agent that has a `messages` state\n",
    "- No code changes needed to your agent\n",
    "- Automatic tool call visualization\n",
    "- Native streaming support\n",
    "\n",
    "**2. Professional User Experience**\n",
    "- Modern, ChatGPT-like interface\n",
    "- Real-time message streaming\n",
    "- Tool execution visualization\n",
    "- Clean, responsive design\n",
    "\n",
    "**3. Minimal Learning Curve**\n",
    "- Don't need to learn frontend development\n",
    "- No UI code to write or maintain\n",
    "- Focus stays on your agent logic\n",
    "\n",
    "**4. Official Support**\n",
    "- Maintained by the LangChain team\n",
    "- Updates with new LangGraph features\n",
    "- Well-documented and reliable\n",
    "\n",
    "**5. Easy Deployment**\n",
    "- One-click deploy to Vercel\n",
    "- Can connect to deployed LangGraph agents\n",
    "- Free hosting options\n",
    "\n",
    "### Disadvantages ‚ùå\n",
    "\n",
    "**1. Limited Customization**\n",
    "- Fixed chat interface layout\n",
    "- Can't easily add custom UI elements\n",
    "- Branding options are limited\n",
    "- Difficult to add non-chat features (dashboards, forms, etc.)\n",
    "\n",
    "**2. Requires LangGraph Architecture**\n",
    "- Only works with LangGraph agents\n",
    "- Must follow the `messages` state contract\n",
    "- Not suitable for non-agent applications\n",
    "- Requires running a LangGraph server\n",
    "\n",
    "**3. JavaScript Knowledge for Deep Changes**\n",
    "- Built with Next.js/React\n",
    "- Meaningful modifications require frontend skills\n",
    "- Python developers may find this uncomfortable\n",
    "\n",
    "**4. Separation of Concerns**\n",
    "- Agent code and UI are separate projects\n",
    "- More complex project structure for beginners\n",
    "- Need to manage two running processes (server + UI)\n",
    "\n",
    "### Best Use Cases\n",
    "\n",
    "‚úÖ **Perfect for:**\n",
    "- Quick demos of LangGraph agents\n",
    "- Learning and development\n",
    "- Internal testing tools\n",
    "- Showcasing agent capabilities\n",
    "- When you want a professional look fast\n",
    "\n",
    "‚ùå **Not ideal for:**\n",
    "- Custom user experiences\n",
    "- Non-agent applications\n",
    "- Complex multi-page applications\n",
    "- When you need deep integration with existing systems\n",
    "\n",
    "### Code Example\n",
    "\n",
    "Minimal setup - no UI code needed:\n",
    "\n",
    "```python\n",
    "# Your agent (agent.py)\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "agent = create_react_agent(model, tools=[...])\n",
    "\n",
    "# langgraph.json\n",
    "{\n",
    "  \"graphs\": {\n",
    "    \"agent\": \"./agent.py:agent\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "Then just run:\n",
    "```bash\n",
    "langgraph dev  # Start your agent\n",
    "pnpm dev       # Start Agent Chat UI in another terminal\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Option 2: Streamlit\n",
    "\n",
    "### What It Is\n",
    "\n",
    "Streamlit is a Python framework for building web applications quickly. It's extremely popular in the data science and ML community for creating interactive interfaces without frontend knowledge.\n",
    "\n",
    "### Advantages ‚úÖ\n",
    "\n",
    "**1. Pure Python**\n",
    "- Write your entire app in Python\n",
    "- No JavaScript required\n",
    "- Comfortable for Python developers\n",
    "- Single codebase for agent + UI\n",
    "\n",
    "**2. Rapid Development**\n",
    "- Extremely fast to prototype\n",
    "- Simple, intuitive API\n",
    "- Live reloading during development\n",
    "- Rich widget library (sliders, buttons, inputs, etc.)\n",
    "\n",
    "**3. Flexibility**\n",
    "- Not limited to chat interfaces\n",
    "- Can build dashboards, forms, visualizations\n",
    "- Easy to add charts and data displays\n",
    "- Mix multiple interaction patterns\n",
    "\n",
    "**4. Great for Data Display**\n",
    "- Excellent for showing dataframes\n",
    "- Built-in chart support (Plotly, Matplotlib, etc.)\n",
    "- Easy file uploads/downloads\n",
    "- Natural fit for data-heavy applications\n",
    "\n",
    "**5. Large Ecosystem**\n",
    "- Huge community\n",
    "- Many examples and tutorials\n",
    "- Third-party component library\n",
    "- Active development\n",
    "\n",
    "**6. Easy Deployment**\n",
    "- Streamlit Cloud (free tier)\n",
    "- Simple configuration\n",
    "- Git-based deployment\n",
    "\n",
    "### Disadvantages ‚ùå\n",
    "\n",
    "**1. Not Built for Chat**\n",
    "- Chat interface requires custom implementation\n",
    "- State management can be tricky\n",
    "- No native streaming visualization\n",
    "- Refresh/reload behavior can be awkward\n",
    "\n",
    "**2. Performance Limitations**\n",
    "- Entire script reruns on each interaction\n",
    "- Can be slow with complex apps\n",
    "- Memory usage grows with session length\n",
    "- Not ideal for high-traffic production\n",
    "\n",
    "**3. Limited Professional Polish**\n",
    "- UI looks \"homemade\"\n",
    "- Customizing appearance is difficult\n",
    "- Limited control over layout\n",
    "- CSS customization is hacky\n",
    "\n",
    "**4. Session Management Challenges**\n",
    "- State persistence requires `st.session_state`\n",
    "- Easy to create bugs with state\n",
    "- Multi-user scenarios need careful handling\n",
    "- Long conversations can cause memory issues\n",
    "\n",
    "**5. Integration Complexity**\n",
    "- Need to manually integrate LangChain\n",
    "- Streaming requires custom implementation\n",
    "- Tool visualization is your responsibility\n",
    "- More code to maintain\n",
    "\n",
    "### Best Use Cases\n",
    "\n",
    "‚úÖ **Perfect for:**\n",
    "- Rapid prototyping\n",
    "- Internal tools and dashboards\n",
    "- Data exploration interfaces\n",
    "- When you need custom layouts (forms, tabs, sidebars)\n",
    "- Python-only teams\n",
    "- Applications that are more than just chat\n",
    "\n",
    "‚ùå **Not ideal for:**\n",
    "- Production-grade chat applications\n",
    "- High-traffic public-facing apps\n",
    "- When you need professional polish\n",
    "- Real-time collaboration features\n",
    "- Applications requiring complex state management\n",
    "\n",
    "### Code Example\n",
    "\n",
    "Basic Streamlit chat with LangChain:\n",
    "\n",
    "```python\n",
    "import streamlit as st\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, AIMessage\n",
    "\n",
    "st.title(\"My LangChain Agent\")\n",
    "\n",
    "# Initialize session state\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "# Initialize agent\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Display chat history\n",
    "for message in st.session_state.messages:\n",
    "    with st.chat_message(message[\"role\"]):\n",
    "        st.write(message[\"content\"])\n",
    "\n",
    "# Chat input\n",
    "if prompt := st.chat_input(\"What would you like to know?\"):\n",
    "    # Add user message\n",
    "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.write(prompt)\n",
    "    \n",
    "    # Get agent response\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        response = model.invoke([HumanMessage(content=prompt)])\n",
    "        st.write(response.content)\n",
    "        st.session_state.messages.append(\n",
    "            {\"role\": \"assistant\", \"content\": response.content}\n",
    "        )\n",
    "```\n",
    "\n",
    "**Note:** This is simplified. Real implementations need:\n",
    "- Proper agent integration\n",
    "- Streaming support\n",
    "- Tool call visualization\n",
    "- Error handling\n",
    "- Better state management\n",
    "\n",
    "---\n",
    "\n",
    "## Option 3: LangChain Templates (Legacy)\n",
    "\n",
    "### What They Were\n",
    "\n",
    "LangChain Templates were pre-built application templates that came with both backend and frontend code. They provided starting points for various use cases (RAG chatbots, SQL agents, research assistants, etc.).\n",
    "\n",
    "### Current Status: Deprecated ‚ö†Ô∏è\n",
    "\n",
    "**Important:** LangChain Templates are no longer actively maintained. The LangChain team has shifted focus to:\n",
    "- LangGraph for agent building\n",
    "- Agent Chat UI for frontends\n",
    "- LangServe for deployment\n",
    "\n",
    "However, they're still worth understanding for context.\n",
    "\n",
    "### Advantages ‚úÖ (Historical)\n",
    "\n",
    "**1. Complete Starting Point**\n",
    "- Backend and frontend included\n",
    "- Pre-configured deployment\n",
    "- Example data and prompts\n",
    "- Best practices built-in\n",
    "\n",
    "**2. Production-Ready Structure**\n",
    "- Proper separation of concerns\n",
    "- Database integration examples\n",
    "- Authentication patterns\n",
    "- API structure\n",
    "\n",
    "**3. Multiple Tech Stacks**\n",
    "- Various frontend frameworks (React, Next.js, etc.)\n",
    "- Different backend patterns\n",
    "- Deployment configurations\n",
    "\n",
    "**4. Use Case Specific**\n",
    "- Templates for specific scenarios\n",
    "- Domain knowledge included\n",
    "- Optimized patterns for each use case\n",
    "\n",
    "### Disadvantages ‚ùå\n",
    "\n",
    "**1. Deprecated and Unmaintained**\n",
    "- No updates to new LangChain versions\n",
    "- Breaking changes not addressed\n",
    "- Community support declining\n",
    "- Documentation outdated\n",
    "\n",
    "**2. High Complexity**\n",
    "- Full-stack setup required\n",
    "- Multiple technologies to learn\n",
    "- Complex project structure\n",
    "- Difficult for beginners\n",
    "\n",
    "**3. Over-Engineering for Simple Needs**\n",
    "- Too much infrastructure for learning\n",
    "- Deployment complexity\n",
    "- More code to understand and maintain\n",
    "\n",
    "**4. Limited Flexibility**\n",
    "- Templates were opinionated\n",
    "- Changing tech stack was difficult\n",
    "- Migration to new patterns required significant work\n",
    "\n",
    "### Best Use Cases\n",
    "\n",
    "‚úÖ **Still useful for:**\n",
    "- Learning full-stack patterns (study the code)\n",
    "- Understanding production architectures\n",
    "- Inspiration for custom builds\n",
    "- Historical context\n",
    "\n",
    "‚ùå **Not recommended for:**\n",
    "- New projects (use Agent Chat UI or Streamlit instead)\n",
    "- Learning current LangChain best practices\n",
    "- Production applications\n",
    "- Beginners\n",
    "\n",
    "---\n",
    "\n",
    "## Decision Framework: Which Should You Choose?\n",
    "\n",
    "### Choose **Agent Chat UI** if:\n",
    "\n",
    "- ‚úÖ You're building with LangGraph\n",
    "- ‚úÖ You want a professional chat interface\n",
    "- ‚úÖ You're learning or demoing agents\n",
    "- ‚úÖ You don't want to write UI code\n",
    "- ‚úÖ You need something working in 5 minutes\n",
    "- ‚úÖ Real-time streaming is important\n",
    "- ‚úÖ You're okay with limited customization\n",
    "\n",
    "**Example scenarios:**\n",
    "- \"I built a research agent and want to show it to my class\"\n",
    "- \"I need to test my agent's conversational abilities\"\n",
    "- \"I want to demo my agent to a potential client\"\n",
    "\n",
    "---\n",
    "\n",
    "### Choose **Streamlit** if:\n",
    "\n",
    "- ‚úÖ You want to stay in Python\n",
    "- ‚úÖ You need custom layouts (not just chat)\n",
    "- ‚úÖ You're building internal tools\n",
    "- ‚úÖ You need forms, dashboards, or data viz\n",
    "- ‚úÖ You want rapid iteration\n",
    "- ‚úÖ You're comfortable with more DIY approach\n",
    "- ‚úÖ Professional polish isn't critical\n",
    "\n",
    "**Example scenarios:**\n",
    "- \"I need a dashboard showing agent performance metrics\"\n",
    "- \"I want users to upload files and configure settings\"\n",
    "- \"I'm building an internal tool for my data science team\"\n",
    "- \"I need to prototype multiple interaction patterns quickly\"\n",
    "\n",
    "---\n",
    "\n",
    "### Avoid **LangChain Templates**:\n",
    "\n",
    "- ‚ùå Starting new projects\n",
    "- ‚ùå Learning current best practices\n",
    "- ‚ùå Production deployments\n",
    "\n",
    "**Alternative:**\n",
    "- Study them for architectural patterns\n",
    "- Then build fresh with Agent Chat UI or Streamlit\n",
    "\n",
    "---\n",
    "\n",
    "## Hybrid Approaches\n",
    "\n",
    "You don't have to choose just one! Here are smart combinations:\n",
    "\n",
    "### 1. Agent Chat UI + Streamlit Dashboard\n",
    "\n",
    "**Use Agent Chat UI for:**\n",
    "- Main chat interaction\n",
    "- Quick demos\n",
    "- User-facing conversations\n",
    "\n",
    "**Use Streamlit for:**\n",
    "- Admin dashboard\n",
    "- Analytics and monitoring\n",
    "- Configuration management\n",
    "- Data exploration\n",
    "\n",
    "**Example:** Chat with users via Agent Chat UI, while monitoring conversations and agent performance in a Streamlit dashboard.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Development Path\n",
    "\n",
    "**Phase 1 - Learning (Week 1-2):**\n",
    "- Use Agent Chat UI\n",
    "- Focus on agent logic\n",
    "- Quick iteration\n",
    "\n",
    "**Phase 2 - Prototyping (Week 3-4):**\n",
    "- Try Streamlit for custom features\n",
    "- Build what Agent Chat UI can't do\n",
    "- Test with real users\n",
    "\n",
    "**Phase 3 - Production (Month 2+):**\n",
    "- Build custom frontend if needed\n",
    "- Use Agent Chat UI patterns as reference\n",
    "- Deploy with proper architecture\n",
    "\n",
    "---\n",
    "\n",
    "## Real-World Scenarios\n",
    "\n",
    "### Scenario 1: University Course Project\n",
    "\n",
    "**Requirement:** Build and demo a LangChain agent in 2 weeks\n",
    "\n",
    "**Best choice:** Agent Chat UI\n",
    "- **Why:** Minimal time on UI means more time learning agents\n",
    "- **Time saved:** ~20 hours not building frontend\n",
    "- **Result:** Professional demo without frontend distraction\n",
    "\n",
    "---\n",
    "\n",
    "### Scenario 2: Internal Company Tool\n",
    "\n",
    "**Requirement:** RAG chatbot for 50 employees with document upload\n",
    "\n",
    "**Best choice:** Streamlit\n",
    "- **Why:** Need file upload + chat + admin controls\n",
    "- **Deployment:** Easy with Streamlit Cloud\n",
    "- **Python team:** No frontend hiring needed\n",
    "- **Result:** Functional tool in 1 week\n",
    "\n",
    "---\n",
    "\n",
    "### Scenario 3: Customer-Facing Product\n",
    "\n",
    "**Requirement:** Polished chatbot for thousands of users\n",
    "\n",
    "**Best choice:** Neither (build custom)\n",
    "- **Why:** Need full control, branding, scaling\n",
    "- **Use Agent Chat UI for:** Development and testing\n",
    "- **Use Streamlit for:** Internal monitoring dashboard\n",
    "- **Production:** Custom Next.js/React app\n",
    "- **Result:** Professional product with proper infrastructure\n",
    "\n",
    "---\n",
    "\n",
    "### Scenario 4: Research Demo\n",
    "\n",
    "**Requirement:** Show agent capabilities at conference\n",
    "\n",
    "**Best choice:** Agent Chat UI\n",
    "- **Why:** Professional look, zero UI code, reliable\n",
    "- **Setup time:** 10 minutes\n",
    "- **Result:** Focus on research, not web development\n",
    "\n",
    "---\n",
    "\n",
    "## Performance Comparison\n",
    "\n",
    "### Response Time\n",
    "\n",
    "**Agent Chat UI:**\n",
    "- ‚ö° **Excellent** - Native streaming, minimal overhead\n",
    "- Real-time message display\n",
    "- Efficient WebSocket communication\n",
    "\n",
    "**Streamlit:**\n",
    "- ‚ö†Ô∏è **Good** - Can stream but requires custom implementation\n",
    "- Script reruns add latency\n",
    "- More overhead per interaction\n",
    "\n",
    "**LangChain Templates:**\n",
    "- ‚úÖ **Varies** - Depends on implementation\n",
    "- Generally good if properly built\n",
    "\n",
    "### Scalability\n",
    "\n",
    "**Agent Chat UI:**\n",
    "- ‚úÖ **Good** - Vercel scales automatically\n",
    "- LangGraph server handles agent load\n",
    "- Stateless frontend scales easily\n",
    "\n",
    "**Streamlit:**\n",
    "- ‚ö†Ô∏è **Limited** - Not built for high traffic\n",
    "- Each user = separate Python process\n",
    "- Memory-intensive for long sessions\n",
    "- Free tier: very limited\n",
    "\n",
    "**LangChain Templates:**\n",
    "- ‚úÖ **Potentially excellent** - If using proper architecture\n",
    "- But requires DevOps expertise\n",
    "\n",
    "### Cost at Scale\n",
    "\n",
    "**Agent Chat UI (1000 daily users):**\n",
    "- Frontend: Free on Vercel (or ~$20/month)\n",
    "- LangGraph: Pay for LangGraph Cloud\n",
    "- Total: Moderate\n",
    "\n",
    "**Streamlit (1000 daily users):**\n",
    "- Free tier: Won't support this\n",
    "- Paid tier: $250-500/month\n",
    "- Self-host: Cheaper but needs DevOps\n",
    "- Total: Moderate to High\n",
    "\n",
    "---\n",
    "\n",
    "## Migration Paths\n",
    "\n",
    "### From Agent Chat UI ‚Üí Custom Frontend\n",
    "\n",
    "**When you outgrow Agent Chat UI:**\n",
    "\n",
    "1. **Keep using it for development**\n",
    "   - Continue testing with Agent Chat UI\n",
    "   - Developers work in familiar environment\n",
    "\n",
    "2. **Study the Agent Chat UI code**\n",
    "   - Learn their LangGraph integration patterns\n",
    "   - Understand streaming implementation\n",
    "   - Copy good patterns\n",
    "\n",
    "3. **Build custom frontend**\n",
    "   - Use same LangGraph server\n",
    "   - API remains unchanged\n",
    "   - Just replace the UI\n",
    "\n",
    "**Key insight:** Agent Chat UI teaches you the patterns you'll use in production.\n",
    "\n",
    "---\n",
    "\n",
    "### From Streamlit ‚Üí Production\n",
    "\n",
    "**When you need to scale Streamlit:**\n",
    "\n",
    "1. **Extract agent logic**\n",
    "   - Separate agent code from UI code\n",
    "   - Move to LangGraph server\n",
    "   - API-based architecture\n",
    "\n",
    "2. **Keep Streamlit for internal tools**\n",
    "   - Admin dashboards\n",
    "   - Monitoring interfaces\n",
    "   - Configuration panels\n",
    "\n",
    "3. **Build custom public-facing UI**\n",
    "   - React/Next.js for users\n",
    "   - Connect to same backend\n",
    "   - Streamlit stays for internal use\n",
    "\n",
    "---\n",
    "\n",
    "## Final Recommendations\n",
    "\n",
    "### For Students and Learners:\n",
    "**Start with Agent Chat UI**\n",
    "- Lowest barrier to entry\n",
    "- Focus on learning agents, not frontends\n",
    "- Professional results immediately\n",
    "\n",
    "### For Prototyping:\n",
    "**Use Streamlit**\n",
    "- Rapid iteration\n",
    "- Stay in Python\n",
    "- Easy to add custom features\n",
    "\n",
    "### For Production:\n",
    "**Start with Agent Chat UI, then:**\n",
    "- If it meets needs ‚Üí Deploy it\n",
    "- If you need customization ‚Üí Build custom frontend\n",
    "- Use LangGraph server either way\n",
    "\n",
    "### Never Start With:\n",
    "**LangChain Templates**\n",
    "- They're deprecated\n",
    "- Too complex for learning\n",
    "- Better alternatives exist\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion: The Modern Approach\n",
    "\n",
    "The LangChain ecosystem has evolved. The current best practice is:\n",
    "\n",
    "1. **Build your agent with LangGraph**\n",
    "   - Proper separation of concerns\n",
    "   - Server-ready architecture\n",
    "   - Tool integration\n",
    "\n",
    "2. **Use Agent Chat UI for development and testing**\n",
    "   - Fast iteration\n",
    "   - Professional demos\n",
    "   - May be sufficient for production\n",
    "\n",
    "3. **Use Streamlit for custom prototypes**\n",
    "   - When Agent Chat UI is too limiting\n",
    "   - Internal tools\n",
    "   - Data-heavy applications\n",
    "\n",
    "4. **Build custom frontends only when necessary**\n",
    "   - High-traffic public applications\n",
    "   - Complex user experiences\n",
    "   - Specific branding requirements\n",
    "\n",
    "The key insight: **Agent Chat UI changed the game**. Before it existed, you had to choose between:\n",
    "- Clunky Streamlit chat interfaces\n",
    "- Complex full-stack templates\n",
    "- Building everything from scratch\n",
    "\n",
    "Now, you get a production-quality chat interface in 5 minutes, letting you focus on what matters: building great agents.\n",
    "\n",
    "Start simple, iterate based on real needs, and graduate to complexity only when the benefits justify the costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8ab159-8f4b-4ead-9a51-7ae0a5ba455a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
