{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17232844-31a4-4e65-863d-14858ce98d6a",
   "metadata": {},
   "source": [
    "# A LangChain 1.0 RAG Agent that can talk with a PDF Document... properly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429a5380-fcd7-4ff5-9583-a681a9c1bf0c",
   "metadata": {},
   "source": [
    "## What is RAG (Retrieval-Augmented Generation)?\n",
    "\n",
    "**RAG** combines two powerful techniques:\n",
    "1. **Retrieval**: Finding relevant information using semantic search (like we did in `020-pdf-agent.ipynb`)\n",
    "2. **Generation**: Using an LLM to read that information and generate a coherent, natural language answer\n",
    "\n",
    "**Why is this code an example of a RAG app?**\n",
    "- It **retrieves** relevant document chunks using semantic search (via the tool)\n",
    "- It **augments** the agent's knowledge with that retrieved context\n",
    "- It **generates** a natural language answer by reading and understanding the retrieved text\n",
    "\n",
    "This is different from just semantic search, which only gives you raw chunks without interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73323d14-ca9b-47af-bc34-438f7013210b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fb59ffd-d928-4d71-874c-614c520259f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"gen-ai-in-2026.pdf\")\n",
    "\n",
    "data = loader.load()\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "\n",
    "ids = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5476a514-2c85-4de5-8d84-7e37ab52e92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to Gartner, by 2026, more than 80% of enterprises will use generative AI APIs or deploy generative AI-enabled applications in production environments.\n"
     ]
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def search_handbook(query: str) -> str:\n",
    "    \"\"\"Search the handbook for information\"\"\"\n",
    "    results = vector_store.similarity_search(query)\n",
    "    return results[0].page_content\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=[search_handbook],\n",
    "    system_prompt=\"You are a helpful agent that can search the pdf file for information.\"\n",
    "    )\n",
    "\n",
    "from langchain.messages import HumanMessage\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"According to Gartner, what percentage of enterprises will use Generative AI APis or deploy generative AI-enabled applications in production environments in 2026?\")]}\n",
    ")\n",
    "\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c83087-7926-4fc9-8817-b4dc3b1f6f32",
   "metadata": {},
   "source": [
    "## Let's explain the previous code in simple terms\n",
    "\n",
    "#### Step 1: Preparing the Data (Same as Before)\n",
    "\n",
    "This part is identical to `020-pdf-agent.ipynb` - we're preparing our knowledge base:\n",
    "\n",
    "```python\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"gen-ai-in-2026.pdf\")\n",
    "```\n",
    "**Load the PDF file** - Points to the document we want to query.\n",
    "\n",
    "```python\n",
    "data = loader.load()\n",
    "```\n",
    "**Extract all pages** - Converts the PDF into Document objects.\n",
    "\n",
    "```python\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "```\n",
    "**Configure the text splitter** - Will break the document into 1000-character chunks with 200-character overlap.\n",
    "\n",
    "```python\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "```\n",
    "**Split the documents** - Creates smaller, searchable chunks.\n",
    "\n",
    "```python\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "```\n",
    "**Create embeddings model** - This will convert text to numerical vectors that capture semantic meaning.\n",
    "\n",
    "```python\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "```\n",
    "**Create vector database** - A specialized database for storing and searching vector embeddings.\n",
    "\n",
    "```python\n",
    "ids = vector_store.add_documents(documents=all_splits)\n",
    "```\n",
    "**Store all chunks** - Each chunk is converted to a vector and stored for later retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5tcbl6f7at",
   "metadata": {},
   "source": [
    "### Step 2: Creating the RAG Agent (The Magic Part!)\n",
    "\n",
    "This is where RAG happens - we give an AI agent the ability to search the document and generate intelligent answers.\n",
    "\n",
    "---\n",
    "\n",
    "#### Line-by-Line Explanation\n",
    "\n",
    "```python\n",
    "from langchain.tools import tool\n",
    "```\n",
    "**Import the tool decorator** - This allows us to create \"tools\" that the agent can use. Tools are functions the agent can call when needed.\n",
    "\n",
    "```python\n",
    "@tool\n",
    "def search_handbook(query: str) -> str:\n",
    "    \"\"\"Search the handbook for information\"\"\"\n",
    "    results = vector_store.similarity_search(query)\n",
    "    return results[0].page_content\n",
    "```\n",
    "**Create a search tool**:\n",
    "- `@tool` decorator: Converts this function into a tool the agent can use\n",
    "- The **docstring** (`\"\"\"Search the handbook for information\"\"\"`) is CRITICAL - the agent reads this to understand what the tool does\n",
    "- `query: str`: The search query (the agent will generate this automatically based on the user's question)\n",
    "- `vector_store.similarity_search(query)`: Performs semantic search to find relevant chunks\n",
    "- `results[0].page_content`: Returns just the text content of the most relevant chunk\n",
    "- **Why this works**: The agent can call this function whenever it needs information from the PDF\n",
    "\n",
    "```python\n",
    "from langchain.agents import create_agent\n",
    "```\n",
    "**Import the agent creator** - This is LangChain 1.0's primary way to build agents.\n",
    "\n",
    "```python\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=[search_handbook],\n",
    "    system_prompt=\"You are a helpful agent that can search the pdf file for information.\"\n",
    ")\n",
    "```\n",
    "**Create the RAG agent**:\n",
    "- `model=\"gpt-4o-mini\"`: The LLM that will power the agent's reasoning and text generation\n",
    "- `tools=[search_handbook]`: Gives the agent access to our search tool\n",
    "- `system_prompt`: Instructions that tell the agent its purpose and capabilities\n",
    "- **What the agent can do**: \n",
    "  - Decide when to search the PDF (it won't search for \"Hello\" or simple questions)\n",
    "  - Generate appropriate search queries\n",
    "  - Read the retrieved content\n",
    "  - Formulate natural language answers\n",
    "  - Handle follow-up questions\n",
    "\n",
    "```python\n",
    "from langchain.messages import HumanMessage\n",
    "```\n",
    "**Import message types** - Agents work with structured messages.\n",
    "\n",
    "```python\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"According to Gartner, what percentage of enterprises will use Generative AI APis or deploy generative AI-enabled applications in production environments in 2026?\")]}\n",
    ")\n",
    "```\n",
    "**Send a question to the agent**:\n",
    "- `HumanMessage`: Represents a message from the user\n",
    "- `agent.invoke()`: Runs the agent with the conversation\n",
    "- **What happens internally**:\n",
    "  1. Agent reads the question\n",
    "  2. Agent decides it needs to search the PDF\n",
    "  3. Agent generates a good search query: `\"Gartner percentage enterprises Generative AI APIs 2026\"`\n",
    "  4. Agent calls the `search_handbook` tool\n",
    "  5. Agent receives the retrieved chunk\n",
    "  6. Agent reads and understands the chunk\n",
    "  7. Agent extracts the answer and formulates a response\n",
    "\n",
    "```python\n",
    "print(response[\"messages\"][-1].content)\n",
    "```\n",
    "**Print the final answer**:\n",
    "- `response[\"messages\"]`: Contains the full conversation (user question, tool calls, tool results, agent's answer)\n",
    "- `[-1]`: Gets the last message (the agent's final answer)\n",
    "- `.content`: Gets just the text of that message\n",
    "\n",
    "**Output**: `\"According to Gartner, by 2026, more than 80% of enterprises will use generative AI APIs or deploy generative AI-enabled applications in production environments.\"`\n",
    "\n",
    "---\n",
    "\n",
    "#### How the Agent Makes Decisions\n",
    "\n",
    "The agent uses a **ReAct pattern** (Reasoning + Acting):\n",
    "\n",
    "1. **Reasoning**: \"The user is asking about a Gartner statistic. I need to search the document.\"\n",
    "2. **Acting**: Calls `search_handbook(\"Gartner percentage enterprises Generative AI APIs 2026\")`\n",
    "3. **Observing**: Reads the retrieved chunk\n",
    "4. **Reasoning**: \"I found the answer in the text: 'more than 80% of enterprises will use generative AI APIs'\"\n",
    "5. **Acting**: Generates the final answer in natural language\n",
    "\n",
    "The agent can:\n",
    "- Skip searches for simple questions it can answer directly\n",
    "- Generate multiple search queries if needed\n",
    "- Refine searches if the first result isn't good enough\n",
    "- Combine information from multiple chunks (if configured to do so)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23c29c5f-29f1-418d-92ec-9668836cb36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='According to Gartner, what percentage of enterprises will use Generative AI APis or deploy generative AI-enabled applications in production environments in 2026?', additional_kwargs={}, response_metadata={}, id='d9c5196d-baa1-46ab-917b-68abb3ad2f0c'),\n",
      " AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 88, 'total_tokens': 116, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_c4585b5b9c', 'id': 'chatcmpl-CxtLaahfUsKCIW8U4xrbZveUVrGe8', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019bbc44-27b6-7e13-a73c-8693a26a390a-0', tool_calls=[{'name': 'search_handbook', 'args': {'query': 'Gartner percentage of enterprises using Generative AI APIs in 2026'}, 'id': 'call_Hv0otZgO0tAfCO8dZDhCRjvp', 'type': 'tool_call'}], usage_metadata={'input_tokens': 88, 'output_tokens': 28, 'total_tokens': 116, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      " ToolMessage(content='Generative AI in 2026:\\nTransforming Business and\\n Professional Value\\nAs we progress through 2026, Generative AI has reached a critical inflection point. After years\\nof experimentation and pilot programs, businesses are now demanding concrete returns on\\ntheir AI investments. This year marks the transition from proof-of-concept to production-scale\\ndeployment, with organizations shifting their focus from \"what\\'s possible\" to \"what\\'s\\nprofitable.\"\\nThe 2026 AI Landscape: From Hype to Reality\\nThe generative AI market has experienced explosive growth, with global investment tripling\\nfrom 2024 to 2025, reaching approximately $37 billion. Gartner research indicates that by\\n2026, more than 80% of enterprises will use generative AI APIs or deploy generative\\nAI-enabled applications in production environments—a staggering increase from just 5% in\\n2023.\\nHowever, this growth comes with a sobering reality check. MIT research revealed a 95%', name='search_handbook', id='11076fc6-51fc-4bda-9534-bf11bad14e8d', tool_call_id='call_Hv0otZgO0tAfCO8dZDhCRjvp'),\n",
      " AIMessage(content='According to Gartner, by 2026, more than 80% of enterprises will use generative AI APIs or deploy generative AI-enabled applications in production environments.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 325, 'total_tokens': 359, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_c4585b5b9c', 'id': 'chatcmpl-CxtLboQQEZ847TrwCJjThvDdSZkKB', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019bbc44-2d28-7201-9b64-2ba7d67ca804-0', usage_metadata={'input_tokens': 325, 'output_tokens': 34, 'total_tokens': 359, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(response['messages'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jret3uwdakk",
   "metadata": {},
   "source": [
    "### Understanding the Message Flow\n",
    "\n",
    "The `pprint(response['messages'])` output shows the complete conversation between components:\n",
    "\n",
    "1. **HumanMessage**: Your original question\n",
    "2. **AIMessage #1**: The agent deciding to use the tool (contains `tool_calls`)\n",
    "3. **ToolMessage**: The result from `search_handbook` (the retrieved chunk)\n",
    "4. **AIMessage #2**: The agent's final answer after reading the tool result\n",
    "\n",
    "This transparency is valuable for debugging and understanding how the agent works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781be28c-31d6-47b3-807b-846ca34ed660",
   "metadata": {},
   "source": [
    "## RAG vs Semantic Search: Why RAG Gives Better Responses\n",
    "\n",
    "### Comparing the Two Approaches\n",
    "\n",
    "| Aspect | **Semantic Search** (020-pdf-agent.ipynb) | **RAG Agent** (021-rag-agent.ipynb) |\n",
    "|--------|------------------------------------------|-------------------------------------|\n",
    "| **What you get** | Raw document chunks with metadata | Natural language answers |\n",
    "| **LLM involved?** | No - just vector similarity | Yes - agent reads and understands |\n",
    "| **Output format** | Technical Document object | Human-friendly text |\n",
    "| **Answer extraction** | Manual - you read the chunk | Automatic - agent extracts the answer |\n",
    "| **Multiple chunks** | Only shows one (unless you loop) | Agent can synthesize information from context |\n",
    "| **Follow-up questions** | No memory or context | Agent can handle conversational flow |\n",
    "| **Decision making** | You decide when to search | Agent decides when retrieval is needed |\n",
    "| **User experience** | Poor - requires technical knowledge | Excellent - like talking to an expert |\n",
    "\n",
    "---\n",
    "\n",
    "### Example Comparison\n",
    "\n",
    "#### Semantic Search Output (020-pdf-agent.ipynb):\n",
    "```\n",
    "page_content='Generative AI in 2026:\\nTransforming Business and\\n Professional Value\\nAs we progress through 2026, Generative AI has reached a critical inflection point...'\n",
    "metadata={'producer': 'ReportLab PDF Library', 'page': 0, 'page_label': '1', 'start_index': 0}\n",
    "```\n",
    "**Problems**:\n",
    "- You have to manually read the chunk to find \"80%\"\n",
    "- Includes irrelevant metadata\n",
    "- Shows more text than needed\n",
    "- Not conversational or user-friendly\n",
    "\n",
    "#### RAG Agent Output (021-rag-agent.ipynb):\n",
    "```\n",
    "According to Gartner, by 2026, more than 80% of enterprises will use generative AI APIs \n",
    "or deploy generative AI-enabled applications in production environments.\n",
    "```\n",
    "**Benefits**:\n",
    "- Direct, clear answer\n",
    "- Extracted exactly what was asked\n",
    "- Professional, natural language\n",
    "- Ready to present to users\n",
    "\n",
    "---\n",
    "\n",
    "### Why RAG Gives Better Responses: The Key Differences\n",
    "\n",
    "#### 1. **Intelligence Layer**\n",
    "- **Semantic Search**: Dumb retrieval - finds similar text but doesn't understand what you need\n",
    "- **RAG**: Smart retrieval + comprehension - understands your question, finds relevant info, AND interprets it\n",
    "\n",
    "#### 2. **Answer vs Data**\n",
    "- **Semantic Search**: Returns raw data chunks (like giving someone a whole page from an encyclopedia)\n",
    "- **RAG**: Returns precise answers (like having an expert read the page and tell you exactly what you need)\n",
    "\n",
    "#### 3. **Contextual Understanding**\n",
    "- **Semantic Search**: No understanding of what information is relevant in the chunk\n",
    "- **RAG**: LLM reads the chunk, understands it, and extracts only the relevant information\n",
    "\n",
    "#### 4. **Multi-step Reasoning**\n",
    "- **Semantic Search**: One search, one result, done\n",
    "- **RAG Agent**: Can chain multiple searches, reason about results, and synthesize information\n",
    "\n",
    "#### 5. **Handling Complexity**\n",
    "Example question: *\"Compare what Gartner and MIT said about AI adoption\"*\n",
    "- **Semantic Search**: Would return one chunk (either Gartner OR MIT stats)\n",
    "- **RAG Agent**: Could search for Gartner stats, then search for MIT stats, then compare them\n",
    "\n",
    "#### 6. **User Experience**\n",
    "- **Semantic Search**: Requires user to be technical, read through chunks, find answers\n",
    "- **RAG Agent**: Works like ChatGPT - natural conversation, clean answers\n",
    "\n",
    "---\n",
    "\n",
    "### The Power of Agentic RAG\n",
    "\n",
    "This implementation uses **Agentic RAG**, which means:\n",
    "\n",
    "1. **Autonomous Decision-Making**: The agent decides WHEN to search (not every query needs retrieval)\n",
    "   - \"Hello\" → No search needed\n",
    "   - \"What's 2+2?\" → No search needed  \n",
    "   - \"What did Gartner say?\" → Search needed\n",
    "\n",
    "2. **Dynamic Query Generation**: The agent creates better search queries than you might\n",
    "   - Your question: \"According to Gartner, what percentage...\"\n",
    "   - Agent's search: \"Gartner percentage enterprises Generative AI APIs 2026\"\n",
    "   - Result: More focused retrieval\n",
    "\n",
    "3. **Multi-turn Interactions**: The agent can have conversations\n",
    "   - User: \"What did Gartner say about AI in 2026?\"\n",
    "   - Agent: *searches and answers*\n",
    "   - User: \"What about MIT?\"\n",
    "   - Agent: *searches again with new context*\n",
    "\n",
    "4. **Tool Integration**: Agents can use multiple tools\n",
    "   - Search tool (what we have)\n",
    "   - Could add: web search, calculator, database queries, etc.\n",
    "\n",
    "---\n",
    "\n",
    "### Real-World Impact\n",
    "\n",
    "**Why RAG matters in production**:\n",
    "- Research shows RAG can improve answer accuracy by up to **70%**\n",
    "- Users get ChatGPT-quality responses from your private documents\n",
    "- No need to fine-tune expensive models on your data\n",
    "- Documents can be updated without retraining\n",
    "- Scales to millions of documents efficiently\n",
    "\n",
    "**Use cases**:\n",
    "- Customer support bots (search company knowledge base)\n",
    "- Legal document analysis (find relevant case law)\n",
    "- Medical literature review (find research papers)\n",
    "- Enterprise documentation (internal wikis, handbooks)\n",
    "- Educational tutors (textbook Q&A)\n",
    "\n",
    "---\n",
    "\n",
    "### Key Takeaway\n",
    "\n",
    "**Semantic Search** is like having a library card catalog - it tells you which books might have your answer, but you still have to read them.\n",
    "\n",
    "**RAG** is like having a research librarian - they find the relevant books, read them for you, and give you a clear, direct answer to your question.\n",
    "\n",
    "**Agentic RAG** is like having a smart assistant - they decide when to use the library, what to search for, and can even combine information from multiple sources autonomously.\n",
    "\n",
    "---\n",
    "\n",
    "### Evolution Path\n",
    "\n",
    "```\n",
    "Simple Keyword Search → Semantic Search → RAG → Agentic RAG → Multi-Agent RAG\n",
    "     (1990s)              (2020s)        (2023)    (2024-2026)      (Future)\n",
    "```\n",
    "\n",
    "We're currently in the **Agentic RAG era**, where agents make intelligent decisions about retrieval and reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1d37b1-f8a8-4c58-96f4-a4bb0dc807a5",
   "metadata": {},
   "source": [
    "## How to run this code from Visual Studio Code\n",
    "* Open Terminal.\n",
    "* Make sure you are in the project folder.\n",
    "* Make sure you have the poetry env activated.\n",
    "* Enter and run the following command:\n",
    "    * `python 021-rag-agent.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fc9f77-e716-4c57-ac6a-e3f957861944",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
