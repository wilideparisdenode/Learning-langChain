{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3baecfc5-acf9-46ff-bcbf-e5a22d980ddb",
   "metadata": {},
   "source": [
    "# Creating a real Agent\n",
    "* Unlike the previous one, this Agent does have agentic behavior.\n",
    "* This is the code the LangChain Team provides in the LangChain Documentation.\n",
    "* Do not get overwhelmed by the following code. We will explain it briefly below, and in the following lessons we will study each of this components and more in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ded5fc2c-6e10-46ce-8519-ce84f265fb1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17b857b5-a45f-4bd6-a572-04e46a75250d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response keys: dict_keys(['messages', 'structured_response'])\n",
      "Last message: content='Returning structured response: ResponseFormat(punny_response=\"Looks like Florida is having a bright day! It\\'s always sunny in the Sunshine State!\", weather_conditions=\\'sunny\\')' name='ResponseFormat' id='0a44462a-d80f-4d9b-8fc8-b3d9939db61b' tool_call_id='call_rQT4FINdG7AwupUxSXwGoDXT'\n",
      "ResponseFormat(punny_response=\"Looks like Florida is having a bright day! It's always sunny in the Sunshine State!\", weather_conditions='sunny')\n",
      "ResponseFormat(punny_response=\"You're welcome! I'm always here to help you weather the storm!\", weather_conditions=None)\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents.structured_output import ToolStrategy\n",
    "\n",
    "\n",
    "# Define system prompt\n",
    "SYSTEM_PROMPT = \"\"\"You are an expert weather forecaster, who speaks in puns.\n",
    "\n",
    "You have access to two tools:\n",
    "\n",
    "- get_weather_for_location: use this to get the weather for a specific location\n",
    "- get_user_location: use this to get the user's location\n",
    "\n",
    "If a user asks you for the weather, make sure you know the location. If you can tell from the question that they mean wherever they are, use the get_user_location tool to find their location.\"\"\"\n",
    "\n",
    "# Define context schema\n",
    "@dataclass\n",
    "class Context:\n",
    "    \"\"\"Custom runtime context schema.\"\"\"\n",
    "    user_id: str\n",
    "\n",
    "# Define tools\n",
    "@tool\n",
    "def get_weather_for_location(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "@tool\n",
    "def get_user_location(runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Retrieve user information based on user ID.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    return \"Florida\" if user_id == \"1\" else \"SF\"\n",
    "\n",
    "# Configure model\n",
    "model = init_chat_model(\n",
    "    \"gpt-4o-mini\",\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "# Define response format\n",
    "@dataclass\n",
    "class ResponseFormat:\n",
    "    \"\"\"Response schema for the agent.\"\"\"\n",
    "    # A punny response (always required)\n",
    "    punny_response: str\n",
    "    # Any interesting information about the weather if available\n",
    "    weather_conditions: str | None = None\n",
    "\n",
    "# Set up memory\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "# Create agent\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    tools=[get_user_location, get_weather_for_location],\n",
    "    context_schema=Context,\n",
    "    response_format=ToolStrategy(ResponseFormat),\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "\n",
    "# Run agent\n",
    "# `thread_id` is a unique identifier for a given conversation.\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather outside?\"}]},\n",
    "    config=config,\n",
    "    context=Context(user_id=\"1\")\n",
    ")\n",
    "\n",
    "# See what's actually in the response\n",
    "print(\"Response keys:\", response.keys())\n",
    "print(\"Last message:\", response['messages'][-1])\n",
    "\n",
    "print(response['structured_response'])\n",
    "# ResponseFormat(\n",
    "#     punny_response=\"Florida is still having a 'sun-derful' day! The sunshine is playing 'ray-dio' hits all day long! I'd say it's the perfect weather for some 'solar-bration'! If you were hoping for rain, I'm afraid that idea is all 'washed up' - the forecast remains 'clear-ly' brilliant!\",\n",
    "#     weather_conditions=\"It's always sunny in Florida!\"\n",
    "# )\n",
    "\n",
    "\n",
    "# Note that we can continue the conversation using the same `thread_id`.\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"thank you!\"}]},\n",
    "    config=config,\n",
    "    context=Context(user_id=\"1\")\n",
    ")\n",
    "\n",
    "print(response['structured_response'])\n",
    "# ResponseFormat(\n",
    "#     punny_response=\"You're 'thund-erfully' welcome! It's always a 'breeze' to help you stay 'current' with the weather. I'm just 'cloud'-ing around waiting to 'shower' you with more forecasts whenever you need them. Have a 'sun-sational' day in the Florida sunshine!\",\n",
    "#     weather_conditions=None\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d89a637-769f-430f-8110-eb0437ffee8b",
   "metadata": {},
   "source": [
    "## Let's explain in simple terms the previous code included in the LangChain 1.0 Quickstart Guide\n",
    "* Do not get overwhelmed, we use this just as a quick demo of a real agent. We will explain the components of an Agent in detail in the following lessons. \n",
    "\n",
    "#### Step 1: Import Required Modules\n",
    "\n",
    "```python\n",
    "from dataclasses import dataclass\n",
    "```\n",
    "**What it does:** Imports Python's `dataclass` decorator, which makes it easy to create simple classes that just store data.\n",
    "\n",
    "\n",
    "```python\n",
    "from langchain.agents import create_agent\n",
    "```\n",
    "**What it does:** Imports the main function to create your AI agent.\n",
    "\n",
    "\n",
    "```python\n",
    "from langchain.chat_models import init_chat_model\n",
    "```\n",
    "**What it does:** Imports the function to initialize your AI model (Claude in this case).\n",
    "\n",
    "\n",
    "```python\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "```\n",
    "**What it does:** \n",
    "- `tool` - A decorator that turns regular Python functions into tools the AI can use\n",
    "- `ToolRuntime` - Allows tools to access runtime information (like user context)\n",
    "\n",
    "\n",
    "```python\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "```\n",
    "**What it does:** Imports the memory system so your agent can remember previous conversations.\n",
    "\n",
    "\n",
    "```python\n",
    "from langchain.agents.structured_output import ToolStrategy\n",
    "```\n",
    "**What it does:** Imports a helper to make sure the agent returns responses in a specific format you define.\n",
    "\n",
    "\n",
    "#### Step 2: Define the System Prompt\n",
    "\n",
    "```python\n",
    "SYSTEM_PROMPT = \"\"\"You are an expert weather forecaster, who speaks in puns.\n",
    "\n",
    "If you can tell from the question that they mean wherever they are, use the get_user_location tool to find their location.\"\"\"\n",
    "```\n",
    "\n",
    "**What it does:** This is the \"personality\" and instructions for your AI agent.\n",
    "- Tells the AI to act like a weather forecaster\n",
    "- Tells it to use puns (for fun!)\n",
    "- Gives instructions on when to use the location tool\n",
    "\n",
    "**Think of it as:** The job description for your AI employee.\n",
    "\n",
    "\n",
    "#### Step 3: Define the Context Schema\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class Context:\n",
    "    \"\"\"Custom runtime context schema.\"\"\"\n",
    "    user_id: str\n",
    "```\n",
    "\n",
    "**What it does:** Creates a simple data container that holds user information.\n",
    "- `user_id` is a string that identifies which user is talking to the agent\n",
    "- This allows the agent to personalize responses based on who's asking\n",
    "\n",
    "**Example:** If `user_id = \"1\"`, the agent knows this is user #1.\n",
    "\n",
    "\n",
    "#### Step 4: Define Tools (Functions the AI Can Use)\n",
    "\n",
    "```python\n",
    "@tool\n",
    "def get_weather_for_location(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "```\n",
    "\n",
    "**Line-by-line:**\n",
    "- `@tool` - Marks this function as a tool the AI can call\n",
    "- `def get_weather_for_location(city: str) -> str:` - Defines a toy function that takes a city name and returns text\n",
    "- `\"\"\"Get weather for a given city.\"\"\"` - Documentation the AI reads to understand what this tool does\n",
    "- `return f\"It's always sunny in {city}!\"` - **This is just a toy function that returns a fake weather report (in a real app, this would call a weather API)**\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "@tool\n",
    "def get_user_location(runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Retrieve user information based on user ID.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    return \"Florida\" if user_id == \"1\" else \"SF\"\n",
    "```\n",
    "\n",
    "**Line-by-line:**\n",
    "- `@tool` - Marks this as another tool\n",
    "- `runtime: ToolRuntime[Context]` - This special parameter gives the function access to the user's context\n",
    "- `user_id = runtime.context.user_id` - Extracts the user ID from the context\n",
    "- `return \"Florida\" if user_id == \"1\" else \"SF\"` - Returns location based on user:\n",
    "  - If user ID is \"1\", return \"Florida\"\n",
    "  - Otherwise, return \"SF\" (San Francisco)\n",
    "  - **This is just a toy function. In a real app, this would be a function to get the user location**.\n",
    "\n",
    "**Why this matters:** The AI can figure out where the user is without them saying it!\n",
    "\n",
    "\n",
    "#### Step 5: Configure the AI Model\n",
    "\n",
    "```python\n",
    "model = init_chat_model(\n",
    "    \"gpt-4o-mini\",\n",
    "    temperature=0.0\n",
    ")\n",
    "```\n",
    "\n",
    "**Line-by-line:**\n",
    "- `model =` - Creates a variable to store your AI model\n",
    "- `init_chat_model()` - Initializes the chat model\n",
    "- `\"gpt-4o-mini\"` - Specifies which model to use (gpt-4o-mini)\n",
    "- `temperature=0.0` - Controls randomness:\n",
    "  - `0.0` = very consistent, predictable responses\n",
    "\n",
    "\n",
    "#### Step 6: Define the Response Format (the Structured Output)\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class ResponseFormat:\n",
    "    \"\"\"Response schema for the agent.\"\"\"\n",
    "    # A punny response (always required)\n",
    "    punny_response: str\n",
    "    # Any interesting information about the weather if available\n",
    "    weather_conditions: str | None = None\n",
    "```\n",
    "\n",
    "**What it does:** Defines exactly how the agent should structure its responses.\n",
    "\n",
    "**Line-by-line:**\n",
    "- `punny_response: str` - A text field for the punny response (required)\n",
    "- `weather_conditions: str | None = None` - An optional field for weather info\n",
    "  - `str | None` means it can be text or nothing\n",
    "  - `= None` makes it optional\n",
    "\n",
    "**Example output:**\n",
    "```python\n",
    "ResponseFormat(\n",
    "    punny_response=\"Florida is having a sun-derful day!\",\n",
    "    weather_conditions=\"It's always sunny in Florida!\"\n",
    ")\n",
    "```\n",
    "\n",
    "\n",
    "#### Step 7: Set Up Short-Term Memory (Conversation Memory)\n",
    "\n",
    "```python\n",
    "checkpointer = InMemorySaver()\n",
    "```\n",
    "\n",
    "**What it does:** Creates a memory system that saves conversation history.\n",
    "- Allows the agent to remember what was said earlier\n",
    "- Stored in memory (RAM) - resets when your program stops\n",
    "\n",
    "**Why it matters:** Without this, the agent would forget everything between messages!\n",
    "\n",
    "\n",
    "#### Step 8: Create the Agent\n",
    "\n",
    "```python\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    tools=[get_user_location, get_weather_for_location],\n",
    "    context_schema=Context,\n",
    "    response_format=ToolStrategy(ResponseFormat),\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "```\n",
    "\n",
    "This is where everything comes together.\n",
    "\n",
    "**Line-by-line:**\n",
    "- `model=model` - Uses the Claude model you configured\n",
    "- `system_prompt=SYSTEM_PROMPT` - Gives the agent its instructions and personality\n",
    "- `tools=[...]` - Provides the list of tools the agent can use\n",
    "- `context_schema=Context` - Tells the agent what user information it has access to\n",
    "- `response_format=ToolStrategy(ResponseFormat)` - Ensures responses follow your defined structure\n",
    "- `checkpointer=checkpointer` - Enables conversation memory\n",
    "\n",
    "\n",
    "#### Step 9: Run the Agent with Conversation ID (for Short-Term Memory) and Custom Context (in this case, some user information to remember)\n",
    "\n",
    "```python\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "```\n",
    "**What it does:** Creates a configuration that identifies this conversation thread.\n",
    "- `thread_id` acts like a \"conversation ID\"\n",
    "- All messages with the same thread_id are part of the same conversation\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather outside?\"}]},\n",
    "    config=config,\n",
    "    context=Context(user_id=\"1\")\n",
    ")\n",
    "```\n",
    "\n",
    "**Line-by-line:**\n",
    "- `agent.invoke()` - Sends a message to the agent and gets a response\n",
    "- `{\"messages\": [...]}` - The conversation format:\n",
    "  - `\"role\": \"user\"` - This message is from the user\n",
    "  - `\"content\": \"...\"` - The actual question\n",
    "- `config=config` - Uses the thread_id we defined\n",
    "- `context=Context(user_id=\"1\")` - Tells the agent this is user #1\n",
    "\n",
    "\n",
    "**What happens behind the scenes:**\n",
    "1. Agent reads the question\n",
    "2. Realizes it needs to know the user's location\n",
    "3. Calls `get_user_location()` tool (returns \"Florida\" for user 1)\n",
    "4. Calls `get_weather_for_location(\"Florida\")` tool\n",
    "5. Generates a punny response with the weather info\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "print(response['structured_response'])\n",
    "```\n",
    "**What it does:** Prints the structured response in the format you defined.\n",
    "\n",
    "**Example output:**\n",
    "```python\n",
    "ResponseFormat(\n",
    "    punny_response=\"Florida is having a 'sun-derful' day! The sunshine is playing 'ray-dio' hits all day long!\",\n",
    "    weather_conditions=\"It's always sunny in Florida!\"\n",
    ")\n",
    "```\n",
    "\n",
    "\n",
    "#### Key Concepts Summary\n",
    "\n",
    "1. **Tools** = Functions the AI can call when needed\n",
    "2. **System Prompt** = Instructions that guide the AI's behavior\n",
    "3. **Context** = User-specific information the AI can access\n",
    "4. **Response Format** = The structure of the AI's answers\n",
    "5. **Memory** = Allows the AI to remember previous messages\n",
    "6. **Thread ID** = Identifies a specific conversation\n",
    "\n",
    "\n",
    "#### Try It Yourself\n",
    "\n",
    "You can continue the conversation:\n",
    "\n",
    "```python\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Why is it almost always sunny in Florida?\"}]},\n",
    "    config=config,\n",
    "    context=Context(user_id=\"1\")\n",
    ")\n",
    "\n",
    "print(response['structured_response'])\n",
    "```\n",
    "\n",
    "The agent will remember the previous conversation and respond accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb57ca9-2bd5-4198-ae01-03b78d729294",
   "metadata": {},
   "source": [
    "## How to run this code from Visual Studio Code\n",
    "* Open Terminal.\n",
    "* Make sure you are in the project folder.\n",
    "* Make sure you have the poetry env activated.\n",
    "* Enter and run the following command:\n",
    "    * `python 003-creating-a-real-agent.py` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee94440-1fa9-4a24-abf5-cceda970aa84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
