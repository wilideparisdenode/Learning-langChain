{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c1112cf-b313-4b97-acf0-1281e6f31295",
   "metadata": {},
   "source": [
    "# Middleware in LangChain 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8be9b78-0886-4d32-862b-86ff330b6152",
   "metadata": {},
   "source": [
    "## What is Middleware and why it is important in LangChain 1.0?\n",
    "#### What Middleware Actually Is\n",
    "Explained in simple terms, Middleware is just any built-in or custom function that we insert in the middle of the agentic process.\n",
    "\n",
    "Middleware is a new abstraction introduced in LangChain 1.0 that provides fine-grained control over the core agent loop of models and tools. It offers three key hooks:\n",
    "- `before_model`: runs before model calls\n",
    "- `after_model`: runs after model calls  \n",
    "- `modify_model_request`: allows modification of tools, prompts, messages, model settings, etc. for that specific request\n",
    "\n",
    "Middleware is specifically designed to solve the \"context engineering\" problem by giving developers control over what goes into the model and when, addressing limitations where tuning became unwieldy for non-trivial use cases.\n",
    "\n",
    "Middleware provides a way to more tightly control and modify what happens inside the agent execution process.\n",
    "\n",
    "If you do not have middleware, the agent execution process is just a black box for you: you enter input and you get output, but you cannot fine tune the execution process.\n",
    "\n",
    "Middleware is useful for the following:\n",
    "* Tracking agent behavior with logging, analytics, and debugging.\n",
    "* Transforming prompts, tool selection, and output formatting.\n",
    "* Adding retries, fallbacks, and early termination logic.\n",
    "* Applying rate limits, guardrails, and PII detection.\n",
    "\n",
    "#### Important note\n",
    "* Middleware can give you the false impression that you can fully customize agents with LangChain 1.0. This is not true. Middleware gives you a higher degree of control of your LangChain Agents, but if you want fully customizable agents, remember that you will need to use LangGraph (or advanced CrewAI) instead or LangChain. For more info about this, see our \"2026 Bootcamp: Understand and Build Professional AI Agents\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e17d4eb-e970-47bd-bff4-a8aa79c7104e",
   "metadata": {},
   "source": [
    "## OK, that is not still very clear. Let's try again: What is Middleware?\n",
    "\n",
    "Think of middleware as a \"filter\" or \"checkpoint\" that sits between the user's request and the AI model. Every time the agent is about to make a decision or call a tool, the middleware can:\n",
    "\n",
    "1. **Inspect** what's happening\n",
    "2. **Modify** the request (change the prompt, tools available, or even the model)\n",
    "3. **Make decisions** about what should happen next\n",
    "\n",
    "It's similar to security checkpoints at an airport—they don't change your destination, but they can check your credentials and decide what you're allowed to bring with you.\n",
    "\n",
    "## How Middleware Works: The Agent Loop\n",
    "\n",
    "To understand middleware, you first need to understand the basic **agent loop**:\n",
    "\n",
    "```\n",
    "1. User sends a message\n",
    "2. Agent receives the message\n",
    "3. Agent calls the AI model (like GPT-4 or Claude)\n",
    "4. Model decides to either:\n",
    "   - Use a tool (like searching the web or querying a database)\n",
    "   - Respond to the user\n",
    "5. If it uses a tool, go back to step 3\n",
    "6. Finally, respond to the user\n",
    "```\n",
    "\n",
    "Middleware can intercept and modify this loop at specific points:\n",
    "\n",
    "- **before_model**: Runs before calling the AI model (Step 3)\n",
    "- **after_model**: Runs after the model responds (Step 4)\n",
    "- **wrap_model_call**: Wraps the entire model call (Steps 3-4)\n",
    "- **wrap_tool_call**: Wraps individual tool executions\n",
    "\n",
    "## Two Types of Middleware: Decorators vs. Classes\n",
    "\n",
    "LangChain 1.0 offers two ways to create middleware, depending on your needs:\n",
    "\n",
    "#### 1. Decorator-Style Middleware (Simple, Quick)\n",
    "\n",
    "Best for single-purpose modifications. You use Python decorators like `@dynamic_prompt` or `@wrap_model_call`:\n",
    "\n",
    "```python\n",
    "from langchain.agents.middleware import dynamic_prompt\n",
    "\n",
    "@dynamic_prompt\n",
    "def custom_prompt(request):\n",
    "    # This function runs before every model call\n",
    "    # and can return a modified prompt\n",
    "    return \"You are a helpful assistant.\"\n",
    "```\n",
    "\n",
    "#### 2. Class-Based Middleware (Powerful, Reusable)\n",
    "\n",
    "Best for complex logic or when you need multiple hooks working together:\n",
    "\n",
    "```python\n",
    "from langchain.agents.middleware import AgentMiddleware\n",
    "\n",
    "class MyCustomMiddleware(AgentMiddleware):\n",
    "    def before_model(self, state, runtime):\n",
    "        # Runs before model calls\n",
    "        pass\n",
    "    \n",
    "    def after_model(self, state, runtime):\n",
    "        # Runs after model responses\n",
    "        pass\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b667d050-297c-4af9-a34c-a4ac002fdb25",
   "metadata": {},
   "source": [
    "## How can we create middleware? Is there Built-in middleware already built for us by the LangChain team?\n",
    "* In most cases, we will use Built-In middleware built for us by the LangChain team. See the available built-in middleware in the [documentation](https://docs.langchain.com/oss/python/langchain/middleware/built-in).\n",
    "* Sometimes we will want to create custom middleware. In order to do this, we will use hooks that run at specific points in the agent execution flow. See how to do this in the [documentation](https://docs.langchain.com/oss/python/langchain/middleware/custom)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7885fab-7748-4af4-84a7-c9d1f523b12c",
   "metadata": {},
   "source": [
    "## How do we use Middleware in LangChain 1.0?\n",
    "* In LangChain 1.0, we add middleware by passing it in the `create_agent` function.\n",
    "* For example, see how we use middleware to automatically summarize conversation history when approaching token limits, preserving recent messages while compressing older context:\n",
    "\n",
    "```python\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[your_weather_tool, your_calculator_tool],\n",
    "    middleware=[\n",
    "        SummarizationMiddleware(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            trigger=(\"tokens\", 4000),\n",
    "            keep=(\"messages\", 20),\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "```\n",
    "\n",
    "* **We will see more detailed examples of Middleware in the next lessons**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0eb0ed8-74b5-42d9-960a-2830b02231fe",
   "metadata": {},
   "source": [
    "## Is Middleware replacing Chains or LCEL?\n",
    "**It is not accurate to say that Middleware replaces chains and LCEL in LangChain 1.0**. They serve fundamentally different purposes: \n",
    "* Middleware is primarily about customizing the agent runtime loop,\n",
    "* Chains and LCEL are about pipeline composition.\n",
    "\n",
    "\n",
    "#### What Happened to Chains and LCEL. Are all of them legacy now?\n",
    "This requires an important clarification: **not all chains are legacy**. Let us break this down:\n",
    "\n",
    "\n",
    "#### What's Actually Legacy vs. What's Current\n",
    "\n",
    "**Legacy chains** (moved to `langchain-classic`):\n",
    "- Class-based chains like `LLMChain`, `ConversationalRetrievalChain`, `RetrievalQA`\n",
    "- LLMChain was deprecated in LangChain 0.1.17 with the recommendation to use RunnableSequence, e.g., `prompt | llm` instead\n",
    "\n",
    "**Still current and recommended**:\n",
    "- **LCEL chains** (using the pipe operator: `prompt | llm | parser`)\n",
    "- LCEL takes a declarative approach to building new Runnables, with the pipe operator creating RunnableSequence compositions that are still the recommended way to build chains.\n",
    "\n",
    "\n",
    "#### What Replaced What\n",
    "\n",
    "**For simple composition tasks**: LCEL chains (`prompt | llm | parser`) are still the answer - nothing replaced them because they're not deprecated.\n",
    "\n",
    "**For agent workflows**: `create_agent` is the standard way to build agents in LangChain 1.0, providing a simpler interface than langgraph.prebuilt.create_react_agent while offering greater customization potential by using middleware.\n",
    "\n",
    "\n",
    "#### The Real Shift\n",
    "\n",
    "**LangChain 1.0 focuses on three things**: \n",
    "* the new create_agent abstraction (fastest way to build an agent),\n",
    "* built on LangGraph runtime for reliable agents,\n",
    "* and prebuilt and user-defined middleware for step-by-step control.\n",
    "\n",
    "**In short**: \n",
    "* Legacy **Chain classes** → moved to `langchain-classic`.\n",
    "* **LCEL chains** → still current and recommended. \n",
    "* **Agent abstractions** → replaced by `create_agent` with middleware.\n",
    "\n",
    "\n",
    "#### The Key Distinction\n",
    "- **Middleware**: Specifically for **agent execution** (the model + tools loop), enabling human-in-the-loop, summarization, PII redaction, etc.\n",
    "\n",
    "- **LCEL/Chains**: For **general composition** of runnables - still the way to build sequences like `prompt | llm | parser`\n",
    "\n",
    "The core LangChain 1.0 focuses on the `create_agent` abstraction with middleware for customization, but LCEL remains the underlying composition mechanism. They're complementary tools serving different architectural needs, not replacements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053782c1-1901-4190-b12c-743da70aab6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
