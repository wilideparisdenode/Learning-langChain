{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dc4c108-1255-4ac2-9b31-cd20c7a5de02",
   "metadata": {},
   "source": [
    "# MCP en LangChain 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761e744b-cdd4-48a0-b1f1-663d49dd0606",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ¿Qué es MCP?\n",
    "* Model Context Protocol (MCP) es un protocolo abierto que estandariza cómo podemos conectar herramientas externas a nuestras aplicaciones LLM y Agentes (como ya sabéis, los Agentes son simplemente un tipo de aplicación LLM)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbd3bf4-d6c6-4616-9e8d-4d3946b781d8",
   "metadata": {},
   "source": [
    "## ¿Cómo pueden los Agentes usar MCP en LangChain 1.0?\n",
    "* Los agentes de LangChain pueden usar herramientas definidas en servidores MCP utilizando la librería [langchain-mcp-adapters](https://github.com/langchain-ai/langchain-mcp-adapters).\n",
    "* Podéis encontrar herramientas MCP disponibles en muchas fuentes como [este sitio web](https://mcp.so/server/time/modelcontextprotocol).\n",
    "\n",
    "#### Cómo usar herramientas externas con MCP: lo básico\n",
    "* Primero, necesitamos instalar el paquete langchain-mcp-adapters:\n",
    "`pip install langchain-mcp-adapters`\n",
    "\n",
    "* Después, utilizaremos `MultiServerMCPClient`, un módulo que para cada invocación de herramienta crea una nueva sesión MCP, ejecuta la herramienta y luego limpia:\n",
    "\n",
    "```python\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient  \n",
    "from langchain.agents import create_agent\n",
    "\n",
    "\n",
    "client = MultiServerMCPClient(  \n",
    "    {\n",
    "        \"math\": {\n",
    "            \"transport\": \"stdio\",  # Comunicación por subproceso local\n",
    "            \"command\": \"python\",\n",
    "            # Ruta absoluta a tu archivo math_server.py\n",
    "            \"args\": [\"/path/to/math_server.py\"],\n",
    "        },\n",
    "        \"weather\": {\n",
    "            \"transport\": \"http\",  # Servidor remoto basado en HTTP\n",
    "            # Asegúrate de iniciar tu servidor de clima en el puerto 8000\n",
    "            \"url\": \"http://localhost:8000/mcp\",\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "tools = await client.get_tools()  \n",
    "\n",
    "agent = create_agent(\n",
    "    \"gpt-4o-mini\",\n",
    "    tools  \n",
    ")\n",
    "\n",
    "math_response = await agent.ainvoke(\n",
    "    {\"messages\": [{\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"what's (3 + 5) x 12?\"}]}\n",
    ")\n",
    "\n",
    "weather_response = await agent.ainvoke(\n",
    "    {\"messages\": [{\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"what is the weather in nyc?\"}]}\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75504bbd-6d4b-41f5-81b6-3320b3e6368d",
   "metadata": {},
   "source": [
    "## Veámoslo en un ejemplo básico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccf1b30-d296-46e3-99fb-f5a4bb33c4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f764c1cb-e921-41c1-ab2f-10ece6ca9d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.messages import HumanMessage\n",
    "from pprint import pprint\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"time\": {\n",
    "            \"transport\": \"stdio\",\n",
    "            # las siguientes líneas están copiadas del sitio web del proveedor de MCP\n",
    "            # ver https://mcp.so/server/time/modelcontextprotocol\n",
    "            \"command\": \"uvx\",\n",
    "            \"args\": [\n",
    "                \"mcp-server-time\",\n",
    "                \"--local-timezone=America/New_York\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "tools = await client.get_tools()\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=tools,\n",
    ")\n",
    "\n",
    "question = HumanMessage(content=\"What time is it in Madrid?\")\n",
    "\n",
    "response = await agent.ainvoke(\n",
    "    {\"messages\": [question]}\n",
    ")\n",
    "\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3dc796-a7a1-4781-bc68-1cef8e839c60",
   "metadata": {},
   "source": [
    "## OK. Expliquemos el código anterior en términos sencillos\n",
    "\n",
    "#### Importaciones (líneas 1-3)\n",
    "\n",
    "```python\n",
    "from langchain.agents import create_agent\n",
    "```\n",
    "**Qué hace:** Importa una función que te permite crear un agente de IA.\n",
    "**En simple:** Un agente es como un asistente inteligente que puede usar herramientas para resolver problemas. Esta función es la \"fábrica\" que construye ese asistente.\n",
    "\n",
    "```python\n",
    "from langchain.messages import HumanMessage\n",
    "```\n",
    "**Qué hace:** Importa una clase para crear mensajes de usuario.\n",
    "**En simple:** Cuando quieres \"hablar\" con el agente, necesitas empaquetar tu pregunta en un formato especial. `HumanMessage` es ese empaquetado.\n",
    "\n",
    "```python\n",
    "from pprint import pprint\n",
    "```\n",
    "**Qué hace:** Importa una función para imprimir datos de forma bonita.\n",
    "**En simple:** Aunque en este código no se usa, `pprint` ayuda a ver resultados complejos de forma más legible. (Nota: el código usa `print` normal al final, no `pprint`).\n",
    "\n",
    "\n",
    "#### Conexión al servidor MCP (líneas 4-18)\n",
    "\n",
    "```python\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "```\n",
    "**Qué hace:** Importa un cliente para conectarse a servidores MCP.\n",
    "**En simple:** MCP (Model Context Protocol) es un estándar que permite que tu agente use herramientas externas. Este cliente es el \"puente\" que conecta tu agente con esas herramientas.\n",
    "\n",
    "```python\n",
    "client = MultiServerMCPClient(\n",
    "```\n",
    "**Qué hace:** Crea una instancia del cliente MCP.\n",
    "**En simple:** Estás creando tu conexión a los servidores de herramientas. \"Multi\" significa que puedes conectarte a varios servidores a la vez.\n",
    "\n",
    "```python\n",
    "    {\n",
    "        \"time\": {\n",
    "```\n",
    "**Qué hace:** Define un servidor llamado \"time\" (tiempo).\n",
    "**En simple:** Le estás diciendo al cliente: \"Conéctate a un servidor que se llama 'time' y que tiene herramientas relacionadas con fechas y horas\".\n",
    "\n",
    "```python\n",
    "            \"transport\": \"stdio\",\n",
    "```\n",
    "**Qué hace:** Define cómo se comunica con el servidor.\n",
    "**En simple:** \"stdio\" significa \"Standard Input/Output\" (entrada/salida estándar). Es como decir \"voy a hablar con este servidor usando mensajes de texto simples por la terminal\".\n",
    "\n",
    "```python\n",
    "            \"command\": \"uvx\",\n",
    "```\n",
    "**Qué hace:** Especifica el comando para ejecutar el servidor.\n",
    "**En simple:** `uvx` es una herramienta de Python que ejecuta aplicaciones. Es como decir \"usa uvx para arrancar el servidor\".\n",
    "\n",
    "```python\n",
    "            \"args\": [\n",
    "                \"mcp-server-time\",\n",
    "                \"--local-timezone=America/New_York\"\n",
    "            ]\n",
    "```\n",
    "**Qué hace:** Proporciona los argumentos (parámetros) para el comando.\n",
    "**En simple:** Le dice a `uvx` que ejecute `mcp-server-time` (el servidor de tiempo) configurado para la zona horaria de Nueva York. Es como decir: \"ejecuta este programa con esta configuración específica\".\n",
    "\n",
    "\n",
    "#### Obtención de herramientas (línea 19)\n",
    "\n",
    "```python\n",
    "tools = await client.get_tools()\n",
    "```\n",
    "**Qué hace:** Obtiene todas las herramientas disponibles del servidor MCP.\n",
    "**En simple:** El cliente pregunta al servidor: \"¿Qué herramientas tienes disponibles?\" y las guarda en la variable `tools`. El `await` significa que el programa espera a recibir la respuesta antes de continuar (porque es una operación asíncrona).\n",
    "\n",
    "\n",
    "#### Creación del agente (líneas 20-23)\n",
    "\n",
    "```python\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=tools,\n",
    ")\n",
    "```\n",
    "**Qué hace:** Crea el agente con un modelo de IA y las herramientas MCP.\n",
    "**En simple:** Aquí construyes tu asistente inteligente. Le dices:\n",
    "- \"Usa el cerebro GPT-4o-mini\" (el modelo de IA de OpenAI)\n",
    "- \"Estas son las herramientas que puedes usar\" (las que obtuviste del servidor MCP)\n",
    "\n",
    "El agente ahora sabe cómo pensar (GPT-4o-mini) y qué herramientas tiene disponibles.\n",
    "\n",
    "\n",
    "#### Pregunta y ejecución (líneas 24-28)\n",
    "\n",
    "```python\n",
    "question = HumanMessage(content=\"What time is it in Madrid?\")\n",
    "```\n",
    "**Qué hace:** Crea un mensaje con la pregunta del usuario.\n",
    "**En simple:** Empaquetas tu pregunta \"¿Qué hora es en Madrid?\" en el formato que el agente entiende.\n",
    "\n",
    "```python\n",
    "response = await agent.ainvoke(\n",
    "    {\"messages\": [question]}\n",
    ")\n",
    "```\n",
    "**Qué hace:** Envía la pregunta al agente y espera su respuesta.\n",
    "**En simple:** Le dices al agente: \"Aquí está mi pregunta, resuélvela\". El agente:\n",
    "1. Lee la pregunta\n",
    "2. Decide si necesita usar alguna herramienta\n",
    "3. Usa el servidor MCP para obtener la hora\n",
    "4. Te devuelve la respuesta\n",
    "\n",
    "El `await` significa que esperas a que termine todo este proceso.\n",
    "\n",
    "\n",
    "#### Mostrar resultado (línea 29)\n",
    "\n",
    "```python\n",
    "print(response['messages'][-1].content)\n",
    "```\n",
    "**Qué hace:** Imprime el último mensaje de la conversación.\n",
    "**En simple:** \n",
    "- `response['messages']` es una lista con todos los mensajes de la conversación\n",
    "- `[-1]` toma el último mensaje (la respuesta final del agente)\n",
    "- `.content` extrae el texto de ese mensaje\n",
    "- `print()` lo muestra en pantalla\n",
    "\n",
    "\n",
    "#### Resumen general\n",
    "\n",
    "Este código hace lo siguiente en orden:\n",
    "\n",
    "1. **Configura la conexión** a un servidor MCP que tiene herramientas de tiempo/fecha\n",
    "2. **Obtiene las herramientas** disponibles de ese servidor\n",
    "3. **Crea un agente** inteligente que sabe usar esas herramientas\n",
    "4. **Hace una pregunta**: \"¿Qué hora es en Madrid?\"\n",
    "5. **El agente razona**: \"Necesito usar la herramienta de tiempo para responder esto\"\n",
    "6. **Muestra la respuesta** que el agente obtuvo\n",
    "\n",
    "Es un buen ejemplo de cómo los agentes de LangChain pueden usar herramientas externas (MCP) para responder preguntas que requieren información en tiempo real."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e300f2-ad00-4a15-9c1d-c9b0573daec7",
   "metadata": {},
   "source": [
    "#### Si utilizáis pprint para ver la respuesta detallada, veréis que efectivamente estamos usando la herramienta externa a través de MCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42005ebc-06c5-4d7d-a740-464c54d45514",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed9dd24-b3e7-45bb-bf94-8e8974c4bdbf",
   "metadata": {},
   "source": [
    "## Cómo ejecutar este código desde Visual Studio Code\n",
    "* Abrid el Terminal.\n",
    "* Aseguraos de estar en la carpeta del proyecto.\n",
    "* Aseguraos de tener el entorno de poetry activado.\n",
    "* Introducid y ejecutad el siguiente comando:\n",
    "    * `python 008-mcp.py`\n",
    " \n",
    "#### Nota importante sobre un pequeño cambio en el archivo .py\n",
    "\n",
    "Los notebooks de Jupyter manejan el código asíncrono de manera diferente a los scripts de Python normales.\n",
    "\n",
    "**En notebooks de Jupyter:**\n",
    "- Jupyter (específicamente IPython) tiene un bucle de eventos integrado que siempre está en ejecución\n",
    "- Esto os permite usar `await` directamente en el nivel superior de las celdas sin necesidad de envolverlo en una función `async def`\n",
    "- Jupyter maneja automáticamente la ejecución asíncrona por vosotros\n",
    "\n",
    "**En scripts de Python normales (terminal):**\n",
    "- No hay un bucle de eventos ejecutándose por defecto\n",
    "- Debéis crear explícitamente un bucle de eventos usando `asyncio.run()`\n",
    "- Todas las sentencias `await` deben estar dentro de funciones `async def`\n",
    "\n",
    "**Ejemplo:**\n",
    "\n",
    "```python\n",
    "# ✅ Funciona en notebook de Jupyter\n",
    "tools = await client.get_tools()\n",
    "\n",
    "# ✅ Funciona en terminal/script\n",
    "async def main():\n",
    "    tools = await client.get_tools()\n",
    "    \n",
    "asyncio.run(main())\n",
    "```\n",
    "\n",
    "Esta es una de las características convenientes de Jupyter para trabajar con código asíncrono - facilita la experimentación. Pero cuando movéis ese código a un archivo `.py` para ejecutarlo desde el terminal, necesitáis añadir el envoltorio de la función async y `asyncio.run()`.\n",
    "\n",
    "¡Este es un \"problema común\" típico cuando se hace la transición de código desde notebooks de Jupyter a scripts de Python!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400a2715-e132-4343-9b2f-d86eb2342db3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
