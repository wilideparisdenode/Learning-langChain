{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c33c242e-61a9-4e54-bf60-47cbef343d6f",
   "metadata": {},
   "source": [
    "# Una aplicación LangChain 1.0 que puede conversar con un documento PDF\n",
    "* Como verás, esto aún no es un agente. Lo convertiremos en un agente en el próximo ejercicio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33780ffa-5163-4b6f-8409-bdb8b7409110",
   "metadata": {},
   "source": [
    "## ¿Qué es la Búsqueda Semántica?\n",
    "\n",
    "**La búsqueda semántica** es una técnica de búsqueda que comprende el **significado** (semántica) de tu consulta en lugar de simplemente buscar palabras clave exactas. En lugar de buscar coincidencias exactas de palabras, encuentra contenido que es conceptualmente similar a tu pregunta.\n",
    "\n",
    "**¿Por qué este código es un ejemplo de búsqueda semántica?**\n",
    "- La búsqueda tradicional por palabras clave buscaría palabras exactas como \"Gartner\" o \"porcentaje\"\n",
    "- La búsqueda semántica convierte tanto tu pregunta COMO los fragmentos del documento en vectores numéricos (embeddings)\n",
    "- Luego encuentra los fragmentos cuyos vectores están más cerca en el espacio matemático del vector de tu pregunta\n",
    "- Esto significa que puede encontrar respuestas relevantes incluso si la redacción exacta es diferente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a427d97e-1671-4baa-ad23-04d2306b6f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ed0e93-b531-48d7-97ad-81e390156add",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"gen-ai-in-2026.pdf\")\n",
    "\n",
    "data = loader.load()\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "\n",
    "ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "results = vector_store.similarity_search(\n",
    "    \"According to Gartner, what percentage of enterprises will use Generative AI APis or deploy generative AI-enabled applications in production environments in 2026?\"\n",
    ")\n",
    "\n",
    "print(results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29c881b-1e43-4560-b7d4-4c418370ef64",
   "metadata": {},
   "source": [
    "## Explicación del código anterior en términos sencillos\n",
    "\n",
    "```python\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "```\n",
    "**Importa el cargador de PDF** - Esta es una herramienta que puede leer archivos PDF y convertirlos en un formato con el que LangChain puede trabajar.\n",
    "\n",
    "```python\n",
    "loader = PyPDFLoader(\"gen-ai-in-2026.pdf\")\n",
    "```\n",
    "**Crea un objeto cargador** para el archivo PDF específico. Piensa en esto como apuntar a tu documento.\n",
    "\n",
    "```python\n",
    "data = loader.load()\n",
    "```\n",
    "**Carga el PDF** y lo convierte en objetos Document. Cada página se convierte en un documento con `page_content` (el texto) y `metadata` (información sobre la página).\n",
    "\n",
    "```python\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "```\n",
    "**Importa el divisor de texto** - Los PDFs suelen ser demasiado largos para procesarlos de una vez, así que necesitamos dividirlos en trozos más pequeños.\n",
    "\n",
    "```python\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "```\n",
    "**Configura cómo dividir el texto**:\n",
    "- `chunk_size=1000`: Cada trozo tendrá aproximadamente 1000 caracteres de longitud\n",
    "- `chunk_overlap=200`: Los trozos se solapan 200 caracteres para evitar cortar frases de forma incómoda\n",
    "- `add_start_index=True`: Recuerda de dónde vino cada trozo en el documento original\n",
    "\n",
    "```python\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "```\n",
    "**Realiza realmente la división** - Toma el PDF completo y lo divide en trozos más pequeños y manejables.\n",
    "\n",
    "```python\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "```\n",
    "**Importa el modelo de embeddings** - Esto convertirá el texto en vectores numéricos.\n",
    "\n",
    "```python\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "```\n",
    "**Crea un objeto de embeddings** usando el modelo text-embedding-3-large de OpenAI. Este modelo está especializado en comprender el significado del texto y convertirlo en números.\n",
    "\n",
    "```python\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "```\n",
    "**Importa la base de datos vectorial** - Esta es una base de datos especial diseñada para almacenar y buscar vectores de manera eficiente.\n",
    "\n",
    "```python\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "```\n",
    "**Crea una base de datos vectorial** que utilizará nuestro modelo de embeddings. \"InMemory\" significa que almacena todo en RAM (rápido pero temporal).\n",
    "\n",
    "```python\n",
    "ids = vector_store.add_documents(documents=all_splits)\n",
    "```\n",
    "**Añade todos los fragmentos del documento a la base de datos** - Cada fragmento se convierte en un vector y se almacena. Los `ids` son identificadores únicos para cada fragmento almacenado.\n",
    "\n",
    "```python\n",
    "results = vector_store.similarity_search(\n",
    "    \"According to Gartner, what percentage of enterprises will use Generative AI APis or deploy generative AI-enabled applications in production environments in 2026?\"\n",
    ")\n",
    "```\n",
    "**Realiza la búsqueda semántica**:\n",
    "1. Convierte tu pregunta en un vector\n",
    "2. Lo compara con todos los vectores de fragmentos almacenados\n",
    "3. Devuelve los fragmentos más similares (por defecto, 4 fragmentos)\n",
    "4. La \"similitud\" se mide por lo cerca que están los vectores en el espacio matemático\n",
    "\n",
    "```python\n",
    "print(results[0])\n",
    "```\n",
    "**Imprime el primer resultado (el más similar)** - Esto muestra el fragmento de texto que es semánticamente más similar a tu pregunta.\n",
    "\n",
    "\n",
    "#### ¿Por qué los resultados no son muy buenos?\n",
    "\n",
    "Cuando ejecutas `print(results[0])`, obtienes **un fragmento de documento en bruto**, no una respuesta real. Los problemas son:\n",
    "\n",
    "1. **Sin extracción de respuesta**: Solo estás viendo el texto recuperado, pero no hay ninguna IA leyéndolo y respondiendo a tu pregunta\n",
    "2. **Formato en bruto**: La salida incluye metadatos y el fragmento completo, lo que dificulta su lectura\n",
    "3. **Sin síntesis de contexto**: Si la respuesta requiere información de múltiples fragmentos, solo ves uno\n",
    "4. **Sin razonamiento**: No hay ningún LLM para interpretar el contenido recuperado y formular una respuesta adecuada\n",
    "\n",
    "\n",
    "## Cómo mejoraremos los resultados en el próximo ejercicio con RAG\n",
    "\n",
    "Este código demuestra **búsqueda semántica** (encontrar información relevante por significado), pero para obtener buenas respuestas, necesitas **RAG** (Retrieval-Augmented Generation) que combina:\n",
    "1. **Recuperación**: Encontrar fragmentos relevantes (lo que tenemos)\n",
    "2. **Generación**: Usar un LLM para leer esos fragmentos y generar una respuesta coherente (lo que nos falta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7721df-dfb3-48f0-9a25-2d32d2dc10fb",
   "metadata": {},
   "source": [
    "## Cómo ejecutar este código desde Visual Studio Code\n",
    "* Abre el Terminal.\n",
    "* Asegúrate de estar en la carpeta del proyecto.\n",
    "* Asegúrate de tener activado el entorno poetry.\n",
    "* Introduce y ejecuta el siguiente comando:\n",
    "    * `python 020-pdf-agent.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a57d87-7870-4a79-b9ba-1739f8cc3621",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
