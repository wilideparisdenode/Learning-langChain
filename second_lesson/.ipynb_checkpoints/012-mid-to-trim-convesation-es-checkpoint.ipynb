{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b674f186-f0a4-434a-995b-65f34e0339c2",
   "metadata": {},
   "source": [
    "# Uso de middleware personalizado para recortar una conversación larga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a5f410-2203-4fac-8956-716dbb3bc649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d6a912-8635-48b5-a640-d1053314e9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.messages import HumanMessage, AIMessage\n",
    "from typing import Any\n",
    "from langchain.agents import AgentState\n",
    "from langchain.messages import RemoveMessage\n",
    "from langgraph.runtime import Runtime\n",
    "from langchain.agents.middleware import before_agent\n",
    "from langchain.messages import ToolMessage\n",
    "\n",
    "@before_agent\n",
    "def trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "    \"\"\"Eliminar todos los mensajes de herramientas del estado\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    tool_messages = [m for m in messages if isinstance(m, ToolMessage)]\n",
    "    \n",
    "    return {\"messages\": [RemoveMessage(id=m.id) for m in tool_messages]}\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    checkpointer=InMemorySaver(),\n",
    "    middleware=[trim_messages],\n",
    ")\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [\n",
    "        HumanMessage(content=\"Mi dispositivo no se enciende. ¿Qué debería hacer?\"),\n",
    "        ToolMessage(content=\"blorp-x7 iniciando ping de diagnóstico…\", tool_call_id=\"1\"),\n",
    "        AIMessage(content=\"¿El dispositivo está conectado y encendido?\"),\n",
    "        HumanMessage(content=\"Sí, está conectado y encendido.\"),\n",
    "        ToolMessage(content=\"temp=42C voltage=2.9v … greeble completado.\", tool_call_id=\"2\"),\n",
    "        AIMessage(content=\"¿El dispositivo muestra alguna luz o indicador?\"),\n",
    "        HumanMessage(content=\"¿Cuál es la temperatura del dispositivo?\")\n",
    "        ]},\n",
    "    {\"configurable\": {\"thread_id\": \"2\"}}\n",
    ")\n",
    "\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96bec48-5260-4e4d-b50a-0cd20f8f8f9a",
   "metadata": {},
   "source": [
    "#### Si imprimimos la respuesta detallada con pprint, veremos que los mensajes de herramientas se han recortado de la conversación (memoria a corto plazo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0faa47-243c-4ef8-9db2-52b1368212a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a02ab1f-ae5d-4eea-8623-6f82fe38df77",
   "metadata": {},
   "source": [
    "## Vamos a explicar el código anterior en términos sencillos\n",
    "A continuación se muestra lo que hace este código **en lenguaje sencillo**, **línea por línea**.\n",
    "\n",
    "#### La idea principal en una frase\n",
    "\n",
    "Estás creando un agente, y estás añadiendo un **\"filtro\" de middleware** que **elimina las entradas ToolMessage** de la conversación **antes de que se ejecute el agente**, para que el agente vea un historial de chat \"más limpio / más corto\". (Los hooks de middleware como `before_agent` están pensados exactamente para este tipo de edición de estado.)\n",
    "\n",
    "---\n",
    "\n",
    "#### Importaciones\n",
    "\n",
    "```py\n",
    "from langchain.agents import create_agent\n",
    "```\n",
    "\n",
    "* Importa `create_agent`, una función auxiliar que construye un **agente LLM** listo para ejecutarse.\n",
    "\n",
    "```py\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "```\n",
    "\n",
    "* Importa un **checkpointer** que puede guardar el estado del agente (como mensajes) **en RAM** (no en disco). Útil para conversaciones de múltiples turnos.\n",
    "\n",
    "```py\n",
    "from langchain.messages import HumanMessage, AIMessage\n",
    "```\n",
    "\n",
    "* Objetos de mensaje:\n",
    "\n",
    "  * `HumanMessage`: algo que dijo el usuario\n",
    "  * `AIMessage`: algo que dijo el modelo/agente\n",
    "\n",
    "```py\n",
    "from typing import Any\n",
    "```\n",
    "\n",
    "* Ayudante de tipado de Python (`Any` significa \"podría ser cualquier tipo\").\n",
    "\n",
    "```py\n",
    "from langchain.agents import AgentState\n",
    "```\n",
    "\n",
    "* `AgentState` es el \"tipo de diccionario de estado\" que el agente usa internamente (incluye `\"messages\"`, más otros campos internos).\n",
    "\n",
    "```py\n",
    "from langchain.messages import RemoveMessage\n",
    "```\n",
    "\n",
    "* Un \"mensaje de instrucción\" especial que le dice a LangGraph/LangChain: **eliminar un mensaje con este ID** del estado.\n",
    "\n",
    "```py\n",
    "from langgraph.runtime import Runtime\n",
    "```\n",
    "\n",
    "* `Runtime` es contexto de ejecución adicional que se pasa a los hooks de middleware (piensa: metadatos sobre la ejecución actual).\n",
    "\n",
    "```py\n",
    "from langchain.agents.middleware import before_agent\n",
    "```\n",
    "\n",
    "* Importa el decorador de middleware que se ejecuta **una vez, justo antes de que el agente comience**.\n",
    "\n",
    "```py\n",
    "from langchain.messages import ToolMessage\n",
    "```\n",
    "\n",
    "* Un `ToolMessage` representa la salida de una llamada a herramienta (logs de diagnóstico, resultados de base de datos, etc.).\n",
    "\n",
    "---\n",
    "\n",
    "#### La función middleware (el \"recortador\")\n",
    "\n",
    "```py\n",
    "@before_agent\n",
    "def trim_messages(state: AgentState, runtime: Runtime) -> dict[str, Any] | None:\n",
    "```\n",
    "\n",
    "* `@before_agent` registra esta función como middleware que se ejecuta **antes de que se ejecute el agente**. \n",
    "* La función recibe:\n",
    "\n",
    "  * `state`: el estado actual del agente (incluye los mensajes de la conversación)\n",
    "  * `runtime`: información sobre esta ejecución (no se usa aquí, pero está disponible)\n",
    "* Devuelve:\n",
    "\n",
    "  * un diccionario de actualizaciones para aplicar al estado (devuelves actualizaciones), o\n",
    "  * `None` (que significa \"no cambiar nada\").\n",
    "\n",
    "```py\n",
    "    \"\"\"Eliminar todos los mensajes de herramientas del estado\"\"\"\n",
    "```\n",
    "\n",
    "* Un docstring que explica la intención: eliminar las salidas de herramientas del estado.\n",
    "\n",
    "```py\n",
    "    messages = state[\"messages\"]\n",
    "```\n",
    "\n",
    "* Extrae la lista del historial de mensajes del estado del agente.\n",
    "\n",
    "```py\n",
    "    tool_messages = [m for m in messages if isinstance(m, ToolMessage)]\n",
    "```\n",
    "\n",
    "* Escanea la lista de mensajes y recopila **solo** los mensajes que son salidas de herramientas.\n",
    "\n",
    "```py\n",
    "    return {\"messages\": [RemoveMessage(id=m.id) for m in tool_messages]}\n",
    "```\n",
    "\n",
    "* Devuelve una **actualización de estado** que le dice al sistema:\n",
    "\n",
    "  * \"Para el campo `messages`, aplica estas eliminaciones.\"\n",
    "* Para cada mensaje de herramienta encontrado, creas una instrucción `RemoveMessage(id=...)` para eliminarlo.\n",
    "\n",
    "**Efecto:** cuando el agente comience, comenzará con una lista de mensajes donde cada `ToolMessage` ha sido eliminado.\n",
    "\n",
    "####  Sutileza importante\n",
    "\n",
    "Dado que usamos **`before_agent`**, esto se ejecuta **una vez por invocación** (una \"ejecución del agente\").\n",
    "Si necesitases recortar **antes de cada llamada al modelo dentro del bucle del agente**, LangChain también proporciona middleware `before_model` (comúnmente usado para recortar mensajes).\n",
    "\n",
    "---\n",
    "\n",
    "#### Creación del agente\n",
    "\n",
    "```py\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    checkpointer=InMemorySaver(),\n",
    "    middleware=[trim_messages],\n",
    ")\n",
    "```\n",
    "\n",
    "* `model=\"gpt-4o-mini\"`: elige el modelo de chat que usará el agente.\n",
    "* `checkpointer=InMemorySaver()`:\n",
    "\n",
    "  * habilita guardar/cargar el estado del agente entre ejecuciones (en memoria).\n",
    "* `middleware=[trim_messages]`:\n",
    "\n",
    "  * adjunta tu middleware para que se ejecute en el punto de enganche. Los agentes de LangChain admiten una lista de middleware como esta.\n",
    "\n",
    "---\n",
    "\n",
    "#### Invocación del agente con una conversación larga\n",
    "\n",
    "```py\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [\n",
    "        HumanMessage(content=\"Mi dispositivo no se enciende. ¿Qué debería hacer?\"),\n",
    "        ToolMessage(content=\"blorp-x7 iniciando ping de diagnóstico…\", tool_call_id=\"1\"),\n",
    "        AIMessage(content=\"¿El dispositivo está conectado y encendido?\"),\n",
    "        HumanMessage(content=\"Sí, está conectado y encendido.\"),\n",
    "        ToolMessage(content=\"temp=42C voltage=2.9v … greeble completado.\", tool_call_id=\"2\"),\n",
    "        AIMessage(content=\"¿El dispositivo muestra alguna luz o indicador?\"),\n",
    "        HumanMessage(content=\"¿Cuál es la temperatura del dispositivo?\")\n",
    "        ]},\n",
    "    {\"configurable\": {\"thread_id\": \"2\"}}\n",
    ")\n",
    "```\n",
    "\n",
    "#### Primer argumento: el estado de entrada\n",
    "\n",
    "* Pasas un estado inicial con `\"messages\": [...]`.\n",
    "* La lista incluye:\n",
    "\n",
    "  * Mensajes humanos (usuario)\n",
    "  * Mensajes IA (asistente)\n",
    "  * Mensajes de herramientas (salida de herramienta)\n",
    "\n",
    "#### Lo que hace tu middleware aquí\n",
    "\n",
    "Antes de que el agente comience, se ejecuta `trim_messages` y **elimina las dos entradas `ToolMessage(...)`**. Así que el agente verá efectivamente algo como:\n",
    "\n",
    "1. Usuario: \"Mi dispositivo no se enciende…\"\n",
    "2. IA: \"¿Está conectado…\"\n",
    "3. Usuario: \"Sí…\"\n",
    "4. IA: \"¿Alguna luz…\"\n",
    "5. Usuario: \"¿Cuál es la temperatura…?\"\n",
    "\n",
    "Eso hace el contexto más corto y elimina logs de herramientas ruidosos.\n",
    "\n",
    "#### Segundo argumento: configuración con `thread_id`\n",
    "\n",
    "```py\n",
    "{\"configurable\": {\"thread_id\": \"2\"}}\n",
    "```\n",
    "\n",
    "* Como estás usando un checkpointer, LangGraph usa un **thread** para almacenar el \"estado acumulado\" entre ejecuciones.\n",
    "* `thread_id=\"2\"` dice: \"Guarda/carga el estado bajo el thread 2.\"\n",
    "\n",
    "---\n",
    "\n",
    "#### Imprimir el último mensaje del asistente\n",
    "\n",
    "```py\n",
    "print(response[\"messages\"][-1].content)\n",
    "```\n",
    "\n",
    "* `response` es un diccionario tipo estado que incluye `\"messages\"`.\n",
    "* `[-1]` significa \"último mensaje\".\n",
    "* `.content` imprime el texto de ese último mensaje (la última respuesta del agente).\n",
    "\n",
    "---\n",
    "\n",
    "#### Modelo mental rápido (para principiantes)\n",
    "\n",
    "* **AgentState** = una mochila que contiene `\"messages\"` y otros campos internos.\n",
    "* **Middleware** = un punto de control donde puedes abrir la mochila y quitar/añadir cosas.\n",
    "* `before_agent` = \"haz esta limpieza una vez antes de que comience la ejecución.\"\n",
    "* `RemoveMessage` = una instrucción de eliminación que elimina IDs de mensajes específicos.\n",
    "* `InMemorySaver + thread_id` = \"recuerda la mochila para la próxima vez bajo este ID de conversación.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15780b3a-4c61-423a-9d97-94960b15a216",
   "metadata": {},
   "source": [
    "## Cómo ejecutar este código desde Visual Studio Code\n",
    "* Abre el Terminal.\n",
    "* Asegúrate de estar en la carpeta del proyecto.\n",
    "* Asegúrate de tener el entorno de poetry activado.\n",
    "* Introduce y ejecuta el siguiente comando:\n",
    "    * `python 012-mid-to-trim-convesation.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ea3883-1855-4d59-825f-2a5ee9215967",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
