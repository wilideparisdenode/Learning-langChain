{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "759a720e-cdd5-4282-b3d2-49b168e7ae10",
   "metadata": {},
   "source": [
    "# Using Built-in Middleware to summarize a Long Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c21ba124-1780-4b49-9cde-93a07d254d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8c49363-f610-4bff-a966-304023427487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, John F. Kennedy had several dogs during his presidency. One of the most famous was a Welsh Terrier named Pushinka, which was a gift from Soviet Premier Nikita Khrushchev. The Kennedy family also had other pets, including a German Shepherd named Charlie. The presence of these dogs added to the family atmosphere in the White House.\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    checkpointer=InMemorySaver(),\n",
    "    middleware=[\n",
    "        SummarizationMiddleware(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            trigger=(\"tokens\", 100),\n",
    "            keep=(\"messages\", 1)\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "from langchain.messages import HumanMessage, AIMessage\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [\n",
    "        HumanMessage(content=\"Are you ready to play the JFK QA game?\"),\n",
    "        AIMessage(content=\"Sure!\"),\n",
    "        HumanMessage(content=\"Who was the favorite sister or JFK?\"),\n",
    "        AIMessage(content=\"Her sister Kick.\"),\n",
    "        HumanMessage(content=\"Correct! Who was his favorite brother?\"),\n",
    "        AIMessage(content=\"Hmmm, that is difficult. I would say Ted. He loved Bobby very much, but Bobby was very different from him.\"),\n",
    "        HumanMessage(content=\"Correct! What was the main source of pain of JFK on a daily basis?\"),\n",
    "        AIMessage(content=\"Back pain.\"),\n",
    "        HumanMessage(content=\"Correct again! Did JFK have dogs?\"),\n",
    "        ]},\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}}\n",
    ")\n",
    "\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238794cd-d053-4d67-9888-66dbfbbbc6b4",
   "metadata": {},
   "source": [
    "#### OK. Let's use pptrint to see the detailed response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "856cabf5-f9e2-4eba-9025-523c8af1d0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content=\"Here is a summary of the conversation to date:\\n\\nThe user engaged in a question-and-answer game about John F. Kennedy (JFK). Key points discussed include:\\n- JFK's favorite sister was Kick.\\n- His favorite brother was Ted, though he also had a strong bond with Bobby.\\n- JFK experienced daily pain primarily from back issues.\", additional_kwargs={}, response_metadata={}, id='147008bd-7867-4c9a-a9f0-983a87624f7b'),\n",
      "              HumanMessage(content='Correct again! Did JFK have dogs?', additional_kwargs={}, response_metadata={}, id='d06fba71-939e-4807-8780-7640c3d5cead'),\n",
      "              AIMessage(content='Yes, John F. Kennedy had several dogs during his presidency. One of the most famous was a Welsh Terrier named Pushinka, which was a gift from Soviet Premier Nikita Khrushchev. The Kennedy family also had other pets, including a German Shepherd named Charlie. The presence of these dogs added to the family atmosphere in the White House.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 70, 'prompt_tokens': 87, 'total_tokens': 157, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_29330a9688', 'id': 'chatcmpl-CuDlWNJ5WVpiJtk1jAuBIdaucN3NF', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b881f-658e-7ab0-9877-fe957ecba59e-0', usage_metadata={'input_tokens': 87, 'output_tokens': 70, 'total_tokens': 157, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7c6ed3-1808-48d1-9714-886cf1976a12",
   "metadata": {},
   "source": [
    "#### As you can see, the response includes a summary of the conversation to date. Let's print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73baef13-0be0-4684-b956-59a6621e42e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a summary of the conversation to date:\n",
      "\n",
      "The user engaged in a question-and-answer game about John F. Kennedy (JFK). Key points discussed include:\n",
      "- JFK's favorite sister was Kick.\n",
      "- His favorite brother was Ted, though he also had a strong bond with Bobby.\n",
      "- JFK experienced daily pain primarily from back issues.\n"
     ]
    }
   ],
   "source": [
    "print(response[\"messages\"][0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d204ca-e8b7-468e-bf76-e116537afddf",
   "metadata": {},
   "source": [
    "## OK. Let's now explain the previous code in simple terms\n",
    "\n",
    "Below is the same code, explained **in simple terms, line-by-line**, plus a clear explanation of **what `SummarizationMiddleware` does**.\n",
    "\n",
    "---\n",
    "\n",
    "#### What this program is doing (big picture)\n",
    "\n",
    "You’re creating a chat **agent** (a smart assistant loop) that:\n",
    "\n",
    "1. Uses an LLM (`gpt-4o-mini`)\n",
    "2. **Remembers the conversation** using a “checkpointer” (memory storage)\n",
    "3. Uses **SummarizationMiddleware** to *auto-summarize older chat history* when it gets too long\n",
    "4. Runs the agent on a list of chat messages and prints the agent’s latest reply\n",
    "\n",
    "Middleware overview: it’s a way to “intercept/control” what happens inside the agent loop.\n",
    "\n",
    "---\n",
    "\n",
    "#### Imports\n",
    "\n",
    "```python\n",
    "from langchain.agents import create_agent\n",
    "```\n",
    "\n",
    "* Imports `create_agent`, a helper that builds an agent for you (an agent = model + tools + memory + loop behavior).\n",
    "\n",
    "```python\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "```\n",
    "\n",
    "* Imports an **in-memory checkpointer**.\n",
    "* A *checkpointer* stores the agent’s state so the agent can resume a conversation later (per thread). For quick demos/prototyping, LangChain recommends `InMemorySaver`.\n",
    "\n",
    "```python\n",
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "```\n",
    "\n",
    "* Imports the middleware that will **summarize conversation history automatically** when some threshold is reached.\n",
    "\n",
    "---\n",
    "\n",
    "#### Create the agent\n",
    "\n",
    "```python\n",
    "agent = create_agent(\n",
    "```\n",
    "\n",
    "* Start building an agent object.\n",
    "\n",
    "```python\n",
    "    model=\"gpt-4o-mini\",\n",
    "```\n",
    "\n",
    "* Sets the main model the agent will use to respond.\n",
    "\n",
    "```python\n",
    "    checkpointer=InMemorySaver(),\n",
    "```\n",
    "\n",
    "* Adds “short-term memory persistence” using an in-memory store.\n",
    "* This lets the agent keep a conversation history **per thread id**, so multiple conversations don’t mix.\n",
    "\n",
    "```python\n",
    "    middleware=[\n",
    "```\n",
    "\n",
    "* Adds middleware components (think: “plugins” that run at certain points inside the agent loop).\n",
    "\n",
    "```python\n",
    "        SummarizationMiddleware(\n",
    "```\n",
    "\n",
    "* Turns on auto-summarization of older messages.\n",
    "\n",
    "```python\n",
    "            model=\"gpt-4o-mini\",\n",
    "```\n",
    "\n",
    "* The model used **to write the summary**.\n",
    "* (You can use the same or a cheaper/faster model than the main one.)\n",
    "\n",
    "```python\n",
    "            trigger=(\"tokens\", 100),\n",
    "```\n",
    "\n",
    "* **When to summarize.**\n",
    "* `(\"tokens\", 100)` means: *if the conversation context is about to exceed ~100 tokens (according to the token counter), summarize older content.*\n",
    "* **Important beginner note:** 100 tokens is *tiny* (like a few short messages), so this will summarize very aggressively.\n",
    "\n",
    "```python\n",
    "            keep=(\"messages\", 1)\n",
    "```\n",
    "\n",
    "* **How much recent chat to keep “as-is”** after summarizing.\n",
    "* `(\"messages\", 1)` means: keep only the most recent **1 message** unchanged; older stuff gets compressed into a summary.\n",
    "\n",
    "```python\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "```\n",
    "\n",
    "* Finishes building the agent.\n",
    "\n",
    "---\n",
    "\n",
    "#### Create message objects\n",
    "\n",
    "```python\n",
    "from langchain.messages import HumanMessage, AIMessage\n",
    "```\n",
    "\n",
    "* Imports message types.\n",
    "* `HumanMessage` = user text, `AIMessage` = assistant text.\n",
    "\n",
    "---\n",
    "\n",
    "#### Invoke (run) the agent with a conversation\n",
    "\n",
    "```python\n",
    "response = agent.invoke(\n",
    "```\n",
    "\n",
    "* Runs the agent once and returns a response object (which includes messages/state updates).\n",
    "\n",
    "```python\n",
    "    {\"messages\": [\n",
    "```\n",
    "\n",
    "* The input is a dictionary with a `messages` list.\n",
    "* You’re giving the agent a conversation “so far”.\n",
    "\n",
    "```python\n",
    "        HumanMessage(content=\"Are you ready to play the JFK QA game?\"),\n",
    "        AIMessage(content=\"Sure!\"),\n",
    "        HumanMessage(content=\"Who was the favorite sister or JFK?\"),\n",
    "        AIMessage(content=\"Her sister Kick.\"),\n",
    "        HumanMessage(content=\"Correct! Who was his favorite brother?\"),\n",
    "        AIMessage(content=\"Hmmm, that is difficult. I would say Ted. He loved Bobby very much, but Bobby was very different from him.\"),\n",
    "        HumanMessage(content=\"Correct! What was the main source of pain of JFK on a daily basis?\"),\n",
    "        AIMessage(content=\"Back pain.\"),\n",
    "        HumanMessage(content=\"Correct again! Did JFK have dogs?\"),\n",
    "```\n",
    "\n",
    "* This is a back-and-forth conversation.\n",
    "* The last message is a user question: “Did JFK have dogs?”\n",
    "* The agent should answer that last question.\n",
    "\n",
    "```python\n",
    "        ]},\n",
    "```\n",
    "\n",
    "* Ends the messages list and the input dict.\n",
    "\n",
    "```python\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "```\n",
    "\n",
    "* This is the **config** for the run.\n",
    "* `thread_id=\"1\"` tells the checkpointer: “store/retrieve memory for conversation thread #1”.\n",
    "* This is how you keep separate chat sessions.\n",
    "\n",
    "```python\n",
    ")\n",
    "```\n",
    "\n",
    "* Finishes the agent call.\n",
    "\n",
    "---\n",
    "\n",
    "#### Print the agent’s final reply\n",
    "\n",
    "```python\n",
    "print(response[\"messages\"][-1].content)\n",
    "```\n",
    "\n",
    "* `response[\"messages\"]` is the updated message list after the agent answered.\n",
    "* `[-1]` means “the last message”.\n",
    "* `.content` gets the text.\n",
    "* So this prints the agent’s newest answer.\n",
    "\n",
    "---\n",
    "\n",
    "#### What `SummarizationMiddleware` does (simple explanation)\n",
    "\n",
    "`SummarizationMiddleware` is an **automatic chat-history compressor**:\n",
    "\n",
    "* It **monitors how big your message history is** (by tokens, message count, or fraction of context).\n",
    "* When the **trigger threshold** is hit (your code: 100 tokens), it:\n",
    "\n",
    "  1. Takes the *older* part of the conversation\n",
    "  2. Calls a model (your code: `gpt-4o-mini`) to **summarize** that older part\n",
    "  3. Replaces that older part with a **short summary**\n",
    "  4. Keeps some most-recent messages untouched based on `keep` (your code: keep only 1 recent message)\n",
    "\n",
    "A detail from the reference docs: it “maintains context continuity by ensuring **AI/Tool message pairs remain together**” (so it doesn’t break the meaning of tool interactions).\n",
    "\n",
    "#### In the specific settings we used\n",
    "\n",
    "* `trigger=(\"tokens\", 100)` → summarize *very quickly*\n",
    "* `keep=(\"messages\", 1)` → keep almost nothing verbatim, just the latest message(s)\n",
    "* Result: the agent will often see something like:\n",
    "\n",
    "  * **Summary:** “We’re playing a JFK Q&A game. User asked X, assistant answered Y…”\n",
    "  * **Most recent message:** “Correct again! Did JFK have dogs?”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d4ab53-8a2a-4514-aa6a-c1f8531f0b90",
   "metadata": {},
   "source": [
    "## How to run this code from Visual Studio Code\n",
    "* Open Terminal.\n",
    "* Make sure you are in the project folder.\n",
    "* Make sure you have the poetry env activated.\n",
    "* Enter and run the following command:\n",
    "    * `python 011-mid-to-summ-conversation.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf38fea0-d316-4691-b82c-579302b9a4ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
