{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7beac31f-6ff1-4a88-a4af-cc6fffdbb603",
   "metadata": {},
   "source": [
    "# Prompts, Mensajes, Bloques de Contenido y Mensajes Multimodales en LangChain 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08deecad-6c25-4bf8-96a6-c0b4c0d49e07",
   "metadata": {},
   "source": [
    "## Prompts (también conocidos como \"Prompts de Texto\") vs. Mensajes (también conocidos como \"Prompts de Mensaje\") en LangChain 1.0\n",
    "\n",
    "#### Prompts de texto\n",
    "Los prompts de texto son cadenas de caracteres. Se utilizan cuando:\n",
    "* Tienes una única solicitud independiente.\n",
    "* No necesitas historial de conversación.\n",
    "* Quieres una complejidad mínima en el código.\n",
    "\n",
    "```python\n",
    "from langchain.chat_models import init_chat_model\n",
    "model = init_chat_model(\"gpt-4o-mini\")\n",
    "\n",
    "response = model.invoke(\"This is a text prompt\")\n",
    "```\n",
    "\n",
    "#### Prompts de mensaje\n",
    "Los mensajes (también conocidos como \"prompts de mensaje\") se utilizan cuando:\n",
    "* Gestionas conversaciones de múltiples turnos.\n",
    "* Trabajas con contenido multimodal (imágenes, audio, archivos).\n",
    "* Incluyes instrucciones del sistema.\n",
    "\n",
    "```python\n",
    "from langchain.messages import SystemMessage, HumanMessage, AIMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"You are a expert on San Francisco\"),\n",
    "    HumanMessage(\"What is the best coffee shop in the city?\"),\n",
    "]\n",
    "response = model.invoke(messages) # Returns an AIMessage like \"The best coffee shop is Peets\"\n",
    "```\n",
    "\n",
    "Alternativamente, puedes escribir mensajes en formato de diccionario:\n",
    "\n",
    "```python\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a expert on San Francisco\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the best coffee shop in the city?\"}\n",
    "]\n",
    "response = model.invoke(messages) # Returns an AIMessage like \"The best coffee shop is Peets\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390f880b-9e77-4da1-afc4-6bcd519f050a",
   "metadata": {},
   "source": [
    "## ¿Qué son los Mensajes en LangChain 1.0?\n",
    "* Los mensajes son la entrada y salida de los modelos.\n",
    "* Incluyen:\n",
    "    * Rol - Identifica el origen del mensaje, lo que en LC 1.0 se denomina \"tipo de mensaje\":\n",
    "        * Mensaje del sistema: Indica al modelo cómo debe comportarse y proporciona contexto para las interacciones.\n",
    "        * Mensaje humano: Representa la entrada e interacciones del usuario humano con el modelo. Puede contener texto, imágenes, audio, archivos y cualquier otra cantidad de contenido multimodal.\n",
    "        * Mensaje de IA: Respuestas generadas por el modelo. Pueden incluir datos multimodales, llamadas a herramientas y metadatos específicos del proveedor.\n",
    "        * Mensaje de herramienta: Representa las salidas de las llamadas a herramientas.\n",
    "    * Contenido - Representa el contenido real del mensaje (como\n",
    "        * texto,\n",
    "        * imágenes,\n",
    "        * audio,\n",
    "        * documentos, etc.)\n",
    "    * Metadatos - Campos opcionales como\n",
    "        * información de respuesta,\n",
    "        * identificadores de mensaje,\n",
    "        * y uso de tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017b7e75-72da-4f9b-a089-7670a5a6d882",
   "metadata": {},
   "source": [
    "## Ejemplo de HumanMessage con metadatos\n",
    "\n",
    "```python\n",
    "human_msg = HumanMessage(\n",
    "    content=\"Hello!\",\n",
    "    name=\"alice\",  # Optional: identify different users\n",
    "    id=\"msg_123\",  # Optional: unique identifier for tracing\n",
    ")\n",
    "```\n",
    "\n",
    "Para ver qué parámetros de metadatos están permitidos por cada modelo, consulta la página de [integrations](https://reference.langchain.com/python/integrations/) en la documentación de LangChain 1.0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ea5f5e-ea07-4b6b-9cc9-3853523ef347",
   "metadata": {},
   "source": [
    "## Contenido de Mensajes y Bloques de Contenido\n",
    "* Los mensajes tienen un atributo `content` que admite cadenas de caracteres y listas de objetos sin tipo (p. ej., diccionarios).\n",
    "* LangChain 1.0 proporciona **bloques de contenido** para texto, razonamiento, citas, datos multimodales, llamadas a herramientas del lado del servidor y otro contenido de mensaje. Los bloques de contenido en LangChain 1.0 proporcionan una representación estándar para el contenido de mensaje que funciona en todos los modelos.\n",
    "* Los modelos de chat de LangChain aceptan contenido de mensaje en el atributo `content`. Esto puede contener:\n",
    "    * Una cadena de caracteres.\n",
    "    * Una lista de bloques de contenido en formato nativo del proveedor.\n",
    "    * Una lista de bloques de contenido estándar de LangChain.\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "```python\n",
    "from langchain.messages import HumanMessage\n",
    "\n",
    "# Message with a String content\n",
    "human_message = HumanMessage(\"Hello, how are you?\")\n",
    "\n",
    "# Message with a content block in a provider-native format (e.g., OpenAI)\n",
    "human_message = HumanMessage(content=[\n",
    "    {\"type\": \"text\", \n",
    "     \"text\": \"Hello, how are you?\"},\n",
    "    {\"type\": \"image_url\", \n",
    "     \"image_url\": {\"url\": \"https://example.com/image.jpg\"}}\n",
    "])\n",
    "\n",
    "# Message with a list of LangChain 1.0 content blocks\n",
    "human_message = HumanMessage(content_blocks=[\n",
    "    {\"type\": \"text\", \n",
    "     \"text\": \"Hello, how are you?\"},\n",
    "    {\"type\": \"image\", \n",
    "     \"url\": \"https://example.com/image.jpg\"},\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0761af43-a23e-4607-bbb0-79955100a434",
   "metadata": {},
   "source": [
    "## Mensajes multimodales\n",
    "* Algunos modelos pueden aceptar datos multimodales como entrada y generarlos como salida.\n",
    "* Consulta la página de [integrations](https://reference.langchain.com/python/integrations) para ver los formatos admitidos y los límites de tamaño para cada modelo.\n",
    "* A continuación mostramos un ejemplo de mensaje de entrada con datos multimodales:\n",
    "\n",
    "```python\n",
    "# Image input from URL\n",
    "message = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\"type\": \"text\", \n",
    "         \"text\": \"Describe the content of this image.\"},\n",
    "        {\"type\": \"image\", \n",
    "         \"url\": \"https://example.com/path/to/image.jpg\"},\n",
    "    ]\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e192c78f-c8c7-4cc8-a314-3bc28d0b0743",
   "metadata": {},
   "source": [
    "## Cómo ejecutar este código desde Visual Studio Code\n",
    "* Abre el Terminal.\n",
    "* Asegúrate de estar en la carpeta del proyecto.\n",
    "* Asegúrate de tener el entorno poetry activado.\n",
    "* Introduce y ejecuta el siguiente comando:\n",
    "    * `python 004-prompts-messages-blocks-multimodal.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cf72ef-1517-454d-affa-97f539006254",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
