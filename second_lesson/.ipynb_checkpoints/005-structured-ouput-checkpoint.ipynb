{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a89de88-a787-4f8c-bb13-851dd3530c11",
   "metadata": {},
   "source": [
    "# Structured Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9852a293-8b8a-4b78-a148-93572b762090",
   "metadata": {},
   "source": [
    "## Why is good that our LLM Apps and Agents can return their responses in structured output?\n",
    "* Instead of returning responses in natural language, sometimes we will want our LLM Apps to return their responses in structured output likeJSON objects, Pydantic models, or dataclasses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bd3ace-fd00-455b-9465-09170aa6c6cb",
   "metadata": {},
   "source": [
    "## How can we make it happen in LangChain 1.0?\n",
    "* LangChain‚Äôs `create_agent` handles structured output automatically.\n",
    "    * The user sets their desired structured output schema using the `response_format` parameter,\n",
    "    * The schema defining the structured output format supports:\n",
    "        * Pydantic models: BaseModel subclasses with field validation\n",
    "        * Dataclasses: Python dataclasses with type annotations\n",
    "        * TypedDict: Typed dictionary classes\n",
    "        * JSON Schema: Dictionary with JSON schema specification\n",
    "    * and when the model generates the structured data, it‚Äôs captured, validated, and returned in the 'structured_response' key of the agent‚Äôs state.\n",
    "\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "\n",
    "class ContactInfo(BaseModel):\n",
    "    \"\"\"Contact information for a person.\"\"\"\n",
    "    name: str = Field(description=\"The name of the person\")\n",
    "    email: str = Field(description=\"The email address of the person\")\n",
    "    phone: str = Field(description=\"The phone number of the person\")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    response_format=ContactInfo\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\": [{\n",
    "        \"role\": \"user\", \n",
    "        \"content\": \"Extract contact info from: John Doe, john@example.com, (555) 123-4567\"}]\n",
    "})\n",
    "\n",
    "print(result[\"structured_response\"])\n",
    "# ContactInfo(name='John Doe', email='john@example.com', phone='(555) 123-4567')\n",
    "```\n",
    "\n",
    "* LangChain automatically uses ProviderStrategy when you pass a schema and the Model supports native structured output, with is the most frequent case. See the [documentation](https://docs.langchain.com/oss/python/langchain/structured-output) to see other less frequent options."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952fe818-14f4-4924-a28a-5449deb279ba",
   "metadata": {},
   "source": [
    "## Basic Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64a777c8-77ed-4885-b891-fb1a2ea7b699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b8721e0-6c4c-4ad1-b80d-a48001501f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The journalist writed an article called Untangling Dallas: A Short Guide to the JFK Assassination Theories\n",
      "The article was about Lone gunman, conspiracies, and a decades‚Äëlong puzzle\n",
      "This is the body of the article:\n",
      " On November 22, 1963, President John F. Kennedy was assassinated in Dallas, Texas. The event sparked a torrent of theories that have persisted for generations. Here are the top ideas that recur in textbooks, documentaries, and conversations, with a note on what the evidence says today.\n",
      "\n",
      "1) The official story: Lee Harvey Oswald acted alone. The Warren Commission (1964) concluded that Oswald fired three shots from the sixth floor of the Texas School Book Depository, striking Kennedy and Governor Connally. The Commission found no provable conspiracy and handed a simple explanation to a shaken nation. Critics have challenged some ballistic and investigative details, but this remains the governing account in most historical surveys.\n",
      "\n",
      "2) A conspiracy involving multiple shooters. The House Select Committee on Assassinations (HSCA) in 1979 concluded Kennedy was probably killed as a result of a conspiracy, likely with more than one gunman. The committee could not identify all participants or the full scope of the plot, but it has kept alive the possibility of a coordinated effort beyond Oswald alone. The key point: there is no single, universally agreed culprit in this version.\n",
      "\n",
      "3) The grassy knoll second shooter theory. A familiar image in popular culture is a shooter from the grassy knoll near Dealey Plaza. This theory has fed the idea of a hidden conspirator. The HSCA‚Äôs acoustic analysis once suggested a second gunman, but subsequent research questioned the method and its conclusions, leaving the theory as a debated possibility rather than a proven fact.\n",
      "\n",
      "4) CIA, Mafia, and anti‚ÄëCastro exile involvement. A well‚Äëworn variant ties Kennedy‚Äôs aggressive push to roll back CIA covert actions and hardLine stance toward Cuba to retaliation from powerful adversaries, including organized crime figures and anti‚ÄëCastro exiles. Proponents point to a web of Cold War tensions and undisclosed relationships, but definitive, widely accepted evidence is elusive.\n",
      "\n",
      "5) Other political plots (LBJ and foreign powers). Some accounts implicate Lyndon B. Johnson in a political maneuver to assume the presidency, while others invoke foreign players such as Cuba or the Soviet Union. These theories often hinge on motive and secrecy, yet they lack the conclusive documentation that would elevate them above speculative rumor in mainstream scholarship.\n",
      "\n",
      "Current status: After decades of releases, a large portion of government files related to the case has been made public, but some materials remain redacted or unreleased. The historical consensus still gives the strongest weight to the lone gunman explanation for many scholars, while conspiracy theories persist in the public imagination due to gaps in evidence, contradictory testimony, and Cold War paranoia. For anyone seeking the truth, the most reliable approach is to examine primary sources, scholarly analyses, and the evolving texture of declassified documents as they come to light.\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain.messages import HumanMessage\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class ArticleFormat(BaseModel):\n",
    "    title: str\n",
    "    subtitle: str\n",
    "    body: str\n",
    "\n",
    "agent = create_agent(\n",
    "    model='gpt-4o-mini',\n",
    "    system_prompt=\"You are an investigative journalist.\",\n",
    "    response_format=ArticleFormat\n",
    ")\n",
    "\n",
    "question = HumanMessage(content=\"Write a short article explaining briefly the top conspiracy theories about who killed JFK?\")\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [question]}\n",
    ")\n",
    "\n",
    "article = response[\"structured_response\"]\n",
    "article_title = article.title\n",
    "article_subtitle = article.subtitle\n",
    "article_body = article.body\n",
    "\n",
    "print(f\"The journalist wrote an article called {article_title}\")\n",
    "print(f\"The article was about {article_subtitle}\")\n",
    "print(f\"This is the body of the article:\\n {article_body}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05e2356-307c-4a46-b0ec-6dc8bd5e4b80",
   "metadata": {},
   "source": [
    "## Let's explain the previous code in simple terms\n",
    "\n",
    "Below is a **simple, beginner-friendly, line-by-line explanation** of what this LangChain 1.0 code does. We will explain every part in plain language.\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. Importing the tools we need\n",
    "\n",
    "```python\n",
    "from langchain.agents import create_agent\n",
    "```\n",
    "\n",
    "* This imports a helper function called `create_agent`.\n",
    "* An **agent** is an AI helper that can receive instructions and generate responses.\n",
    "* Think of it as ‚Äúcreating an AI worker‚Äù.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "from langchain.messages import HumanMessage\n",
    "```\n",
    "\n",
    "* This imports `HumanMessage`, which represents **something a human says to the AI**.\n",
    "* LangChain uses message objects instead of raw strings to keep conversations structured.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "from pydantic import BaseModel\n",
    "```\n",
    "\n",
    "* This imports `BaseModel` from **Pydantic**.\n",
    "* Pydantic is used to define **structured data** (data with fixed fields).\n",
    "* We‚Äôll use it to tell the AI **exactly what format its answer must have**.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Defining the response structure\n",
    "\n",
    "```python\n",
    "class ArticleFormat(BaseModel):\n",
    "```\n",
    "\n",
    "* This defines a **data model** called `ArticleFormat`.\n",
    "* It describes what a valid AI response should look like.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "    title: str\n",
    "    subtitle: str\n",
    "    body: str\n",
    "```\n",
    "\n",
    "* These are the required fields in the response:\n",
    "\n",
    "  * `title`: a string\n",
    "  * `subtitle`: a string\n",
    "  * `body`: a string\n",
    "* The AI **must** return all three, or the response will fail validation.\n",
    "\n",
    "üëâ In simple terms:\n",
    "\n",
    "> ‚ÄúThe AI must answer in the form of an article with a title, subtitle, and body.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Creating the AI agent\n",
    "\n",
    "```python\n",
    "agent = create_agent(\n",
    "```\n",
    "\n",
    "* This creates the AI agent instance.\n",
    "* From now on, `agent` is your AI journalist.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "    model='gpt-4o-mini',\n",
    "```\n",
    "\n",
    "* This tells LangChain which AI model to use.\n",
    "* `gpt-4o-mini` is a lightweight, fast language model.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "    system_prompt=\"You are an investigative journalist.\",\n",
    "```\n",
    "\n",
    "* This is a **system instruction**.\n",
    "* It sets the AI‚Äôs role and behavior.\n",
    "* The AI will try to answer **like a journalist**, not a chatbot.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "    response_format=ArticleFormat\n",
    ")\n",
    "```\n",
    "\n",
    "* This forces the AI‚Äôs response to match the `ArticleFormat` schema.\n",
    "* LangChain will automatically parse the output into structured data.\n",
    "\n",
    "üëâ This is powerful because:\n",
    "\n",
    "* No guessing\n",
    "* No text parsing\n",
    "* No messy JSON handling\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Creating the user question\n",
    "\n",
    "```python\n",
    "question = HumanMessage(\n",
    "    content=\"Write a short article explaining briefly the top conspiracy theories about who killed JFK?\"\n",
    ")\n",
    "```\n",
    "\n",
    "* This creates a **human message**.\n",
    "* `content` is what the user is asking the AI.\n",
    "* Wrapping it in `HumanMessage` makes it compatible with LangChain‚Äôs message system.\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. Sending the message to the agent\n",
    "\n",
    "```python\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [question]}\n",
    ")\n",
    "```\n",
    "\n",
    "* This sends the message to the AI agent.\n",
    "* `invoke()` runs the agent and waits for the response.\n",
    "* The input is a dictionary containing a list of messages.\n",
    "\n",
    "üëâ Even for one question, LangChain expects a **list of messages**.\n",
    "\n",
    "---\n",
    "\n",
    "#### 6. Extracting the structured response\n",
    "\n",
    "```python\n",
    "article = response[\"structured_response\"]\n",
    "```\n",
    "\n",
    "* The agent‚Äôs output contains a parsed response.\n",
    "* Because we used `response_format=ArticleFormat`, LangChain already converted the AI output into an `ArticleFormat` object.\n",
    "\n",
    "üëâ At this point:\n",
    "\n",
    "* `article` is **not text**\n",
    "* It‚Äôs a Python object with fields: `title`, `subtitle`, and `body`\n",
    "\n",
    "---\n",
    "\n",
    "#### 7. Accessing each article field\n",
    "\n",
    "```python\n",
    "article_title = article.title\n",
    "article_subtitle = article.subtitle\n",
    "article_body = article.body\n",
    "```\n",
    "\n",
    "* These lines extract each part of the article.\n",
    "* This works just like accessing attributes on any Python object.\n",
    "\n",
    "---\n",
    "\n",
    "#### 8. Printing the results\n",
    "\n",
    "```python\n",
    "print(f\"The journalist wrote an article called {article_title}\")\n",
    "```\n",
    "\n",
    "* Prints the article title.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "print(f\"The article was about {article_subtitle}\")\n",
    "```\n",
    "\n",
    "* Prints the subtitle (what the article is about).\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "print(f\"This is the body of the article:\\n {article_body}\")\n",
    "```\n",
    "\n",
    "* Prints the article body.\n",
    "* `\\n` adds a new line before the text.\n",
    "\n",
    "---\n",
    "\n",
    "#### üß† Big picture summary\n",
    "\n",
    "This code:\n",
    "\n",
    "1. Defines a **structured article format**\n",
    "2. Creates an **AI journalist**\n",
    "3. Asks it a question\n",
    "4. Forces the AI to reply in a **clean, predictable structure**\n",
    "5. Extracts and prints each part of the article\n",
    "\n",
    "---\n",
    "\n",
    "#### üöÄ Why this approach is powerful\n",
    "\n",
    "* No messy string parsing\n",
    "* Strong typing and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b40a41-2dcc-430a-9662-1482c2baa3c3",
   "metadata": {},
   "source": [
    "## Main options to structure the output in LangChain\n",
    "* Pydantic and Dataclass are the most frequent ways to set the structure of the output in LangChain. See more detailed information and examples about these and other options in this [LangChain Documentation Page](https://docs.langchain.com/oss/python/langchain/structured-output)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125c0f51-0292-40de-a02d-aa4f7c62ae36",
   "metadata": {},
   "source": [
    "## How to run this code from Visual Studio Code\n",
    "* Open Terminal.\n",
    "* Make sure you are in the project folder.\n",
    "* Make sure you have the poetry env activated.\n",
    "* Enter and run the following command:\n",
    "    * `python 005-structured-output.py` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013528e3-9360-417a-8a04-bd8014560186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
