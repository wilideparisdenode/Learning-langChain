{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3baecfc5-acf9-46ff-bcbf-e5a22d980ddb",
   "metadata": {},
   "source": [
    "# Creando un Agente Real\n",
    "* A diferencia del anterior, este Agente sí tiene comportamiento agéntico.\n",
    "* Este es el código que el equipo de LangChain proporciona en la documentación de LangChain.\n",
    "* No te agobies con el siguiente código. Lo explicaremos brevemente a continuación, y en las siguientes lecciones estudiaremos cada uno de estos componentes y más en detalle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded5fc2c-6e10-46ce-8519-ce84f265fb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b857b5-a45f-4bd6-a572-04e46a75250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents.structured_output import ToolStrategy\n",
    "\n",
    "\n",
    "# Definir el prompt del sistema\n",
    "SYSTEM_PROMPT = \"\"\"Eres un experto pronosticador del tiempo, que habla con juegos de palabras.\n",
    "\n",
    "Tienes acceso a dos herramientas:\n",
    "\n",
    "- get_weather_for_location: úsala para obtener el tiempo de una ubicación específica\n",
    "- get_user_location: úsala para obtener la ubicación del usuario\n",
    "\n",
    "Si un usuario te pregunta por el tiempo, asegúrate de saber la ubicación. Si puedes deducir de la pregunta que se refieren a donde están, usa la herramienta get_user_location para encontrar su ubicación.\"\"\"\n",
    "\n",
    "# Definir el esquema de contexto\n",
    "@dataclass\n",
    "class Context:\n",
    "    \"\"\"Esquema de contexto de ejecución personalizado.\"\"\"\n",
    "    user_id: str\n",
    "\n",
    "# Definir herramientas\n",
    "@tool\n",
    "def get_weather_for_location(city: str) -> str:\n",
    "    \"\"\"Obtener el tiempo para una ciudad dada.\"\"\"\n",
    "    return f\"¡Siempre hace sol en {city}!\"\n",
    "\n",
    "@tool\n",
    "def get_user_location(runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Recuperar información del usuario basada en el ID de usuario.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    return \"Florida\" if user_id == \"1\" else \"SF\"\n",
    "\n",
    "# Configurar modelo\n",
    "model = init_chat_model(\n",
    "    \"gpt-4o-mini\",\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "# Definir formato de respuesta\n",
    "@dataclass\n",
    "class ResponseFormat:\n",
    "    \"\"\"Esquema de respuesta para el agente.\"\"\"\n",
    "    # Una respuesta con juegos de palabras (siempre requerida)\n",
    "    punny_response: str\n",
    "    # Cualquier información interesante sobre el tiempo si está disponible\n",
    "    weather_conditions: str | None = None\n",
    "\n",
    "# Configurar memoria\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "# Crear agente\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    tools=[get_user_location, get_weather_for_location],\n",
    "    context_schema=Context,\n",
    "    response_format=ToolStrategy(ResponseFormat),\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "\n",
    "# Ejecutar agente\n",
    "# `thread_id` es un identificador único para una conversación dada.\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"¿qué tiempo hace fuera?\"}]},\n",
    "    config=config,\n",
    "    context=Context(user_id=\"1\")\n",
    ")\n",
    "\n",
    "# Ver qué hay realmente en la respuesta\n",
    "print(\"Claves de respuesta:\", response.keys())\n",
    "print(\"Último mensaje:\", response['messages'][-1])\n",
    "\n",
    "print(response['structured_response'])\n",
    "# ResponseFormat(\n",
    "#     punny_response=\"Florida is still having a 'sun-derful' day! The sunshine is playing 'ray-dio' hits all day long! I'd say it's the perfect weather for some 'solar-bration'! If you were hoping for rain, I'm afraid that idea is all 'washed up' - the forecast remains 'clear-ly' brilliant!\",\n",
    "#     weather_conditions=\"It's always sunny in Florida!\"\n",
    "# )\n",
    "\n",
    "\n",
    "# Ten en cuenta que podemos continuar la conversación usando el mismo `thread_id`.\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"¡gracias!\"}]},\n",
    "    config=config,\n",
    "    context=Context(user_id=\"1\")\n",
    ")\n",
    "\n",
    "print(response['structured_response'])\n",
    "# ResponseFormat(\n",
    "#     punny_response=\"You're 'thund-erfully' welcome! It's always a 'breeze' to help you stay 'current' with the weather. I'm just 'cloud'-ing around waiting to 'shower' you with more forecasts whenever you need them. Have a 'sun-sational' day in the Florida sunshine!\",\n",
    "#     weather_conditions=None\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d89a637-769f-430f-8110-eb0437ffee8b",
   "metadata": {},
   "source": [
    "## Expliquemos en términos simples el código anterior incluido en la Guía de Inicio Rápido de LangChain 1.0\n",
    "* No te agobies, usamos esto solo como una demostración rápida de un agente real. Explicaremos los componentes de un Agente en detalle en las siguientes lecciones.\n",
    "\n",
    "#### Paso 1: Importar los Módulos Requeridos\n",
    "\n",
    "```python\n",
    "from dataclasses import dataclass\n",
    "```\n",
    "**Qué hace:** Importa el decorador `dataclass` de Python, que facilita la creación de clases simples que solo almacenan datos.\n",
    "\n",
    "\n",
    "```python\n",
    "from langchain.agents import create_agent\n",
    "```\n",
    "**Qué hace:** Importa la función principal para crear tu agente de IA.\n",
    "\n",
    "\n",
    "```python\n",
    "from langchain.chat_models import init_chat_model\n",
    "```\n",
    "**Qué hace:** Importa la función para inicializar tu modelo de IA (Claude en este caso).\n",
    "\n",
    "\n",
    "```python\n",
    "from langchain.tools import tool, ToolRuntime\n",
    "```\n",
    "**Qué hace:**\n",
    "- `tool` - Un decorador que convierte funciones normales de Python en herramientas que la IA puede usar\n",
    "- `ToolRuntime` - Permite a las herramientas acceder a información de ejecución (como el contexto del usuario)\n",
    "\n",
    "\n",
    "```python\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "```\n",
    "**Qué hace:** Importa el sistema de memoria para que tu agente pueda recordar conversaciones previas.\n",
    "\n",
    "\n",
    "```python\n",
    "from langchain.agents.structured_output import ToolStrategy\n",
    "```\n",
    "**Qué hace:** Importa un ayudante para asegurarse de que el agente devuelva respuestas en un formato específico que tú defines.\n",
    "\n",
    "\n",
    "#### Paso 2: Definir el Prompt del Sistema\n",
    "\n",
    "```python\n",
    "SYSTEM_PROMPT = \"\"\"Eres un experto pronosticador del tiempo, que habla con juegos de palabras.\n",
    "\n",
    "Si puedes deducir de la pregunta que se refieren a donde están, usa la herramienta get_user_location para encontrar su ubicación.\"\"\"\n",
    "```\n",
    "\n",
    "**Qué hace:** Esta es la \"personalidad\" e instrucciones para tu agente de IA.\n",
    "- Le dice a la IA que actúe como un pronosticador del tiempo\n",
    "- Le dice que use juegos de palabras (¡por diversión!)\n",
    "- Da instrucciones sobre cuándo usar la herramienta de ubicación\n",
    "\n",
    "**Piénsalo como:** La descripción del puesto de trabajo para tu empleado de IA.\n",
    "\n",
    "\n",
    "#### Paso 3: Definir el Esquema de Contexto\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class Context:\n",
    "    \"\"\"Esquema de contexto de ejecución personalizado.\"\"\"\n",
    "    user_id: str\n",
    "```\n",
    "\n",
    "**Qué hace:** Crea un contenedor de datos simple que almacena información del usuario.\n",
    "- `user_id` es una cadena que identifica qué usuario está hablando con el agente\n",
    "- Esto permite al agente personalizar las respuestas según quién esté preguntando\n",
    "\n",
    "**Ejemplo:** Si `user_id = \"1\"`, el agente sabe que este es el usuario #1.\n",
    "\n",
    "\n",
    "#### Paso 4: Definir Herramientas (Funciones que la IA Puede Usar)\n",
    "\n",
    "```python\n",
    "@tool\n",
    "def get_weather_for_location(city: str) -> str:\n",
    "    \"\"\"Obtener el tiempo para una ciudad dada.\"\"\"\n",
    "    return f\"¡Siempre hace sol en {city}!\"\n",
    "```\n",
    "\n",
    "**Línea por línea:**\n",
    "- `@tool` - Marca esta función como una herramienta que la IA puede llamar\n",
    "- `def get_weather_for_location(city: str) -> str:` - Define una función de juguete que toma el nombre de una ciudad y devuelve texto\n",
    "- `\"\"\"Obtener el tiempo para una ciudad dada.\"\"\"` - Documentación que la IA lee para entender qué hace esta herramienta\n",
    "- `return f\"¡Siempre hace sol en {city}!\"` - **Esta es solo una función de juguete que devuelve un informe meteorológico falso (en una aplicación real, esto llamaría a una API del tiempo)**\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "@tool\n",
    "def get_user_location(runtime: ToolRuntime[Context]) -> str:\n",
    "    \"\"\"Recuperar información del usuario basada en el ID de usuario.\"\"\"\n",
    "    user_id = runtime.context.user_id\n",
    "    return \"Florida\" if user_id == \"1\" else \"SF\"\n",
    "```\n",
    "\n",
    "**Línea por línea:**\n",
    "- `@tool` - Marca esto como otra herramienta\n",
    "- `runtime: ToolRuntime[Context]` - Este parámetro especial da acceso a la función al contexto del usuario\n",
    "- `user_id = runtime.context.user_id` - Extrae el ID de usuario del contexto\n",
    "- `return \"Florida\" if user_id == \"1\" else \"SF\"` - Devuelve la ubicación según el usuario:\n",
    "  - Si el ID de usuario es \"1\", devuelve \"Florida\"\n",
    "  - De lo contrario, devuelve \"SF\" (San Francisco)\n",
    "  - **Esta es solo una función de juguete. En una aplicación real, esta sería una función para obtener la ubicación del usuario**.\n",
    "\n",
    "**Por qué esto importa:** ¡La IA puede averiguar dónde está el usuario sin que lo digan!\n",
    "\n",
    "\n",
    "#### Paso 5: Configurar el Modelo de IA\n",
    "\n",
    "```python\n",
    "model = init_chat_model(\n",
    "    \"gpt-4o-mini\",\n",
    "    temperature=0.0\n",
    ")\n",
    "```\n",
    "\n",
    "**Línea por línea:**\n",
    "- `model =` - Crea una variable para almacenar tu modelo de IA\n",
    "- `init_chat_model()` - Inicializa el modelo de chat\n",
    "- `\"gpt-4o-mini\"` - Especifica qué modelo usar (gpt-4o-mini)\n",
    "- `temperature=0.0` - Controla la aleatoriedad:\n",
    "  - `0.0` = respuestas muy consistentes y predecibles\n",
    "\n",
    "\n",
    "#### Paso 6: Definir el Formato de Respuesta (la Salida Estructurada)\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class ResponseFormat:\n",
    "    \"\"\"Esquema de respuesta para el agente.\"\"\"\n",
    "    # Una respuesta con juegos de palabras (siempre requerida)\n",
    "    punny_response: str\n",
    "    # Cualquier información interesante sobre el tiempo si está disponible\n",
    "    weather_conditions: str | None = None\n",
    "```\n",
    "\n",
    "**Qué hace:** Define exactamente cómo debe estructurar el agente sus respuestas.\n",
    "\n",
    "**Línea por línea:**\n",
    "- `punny_response: str` - Un campo de texto para la respuesta con juegos de palabras (requerido)\n",
    "- `weather_conditions: str | None = None` - Un campo opcional para información meteorológica\n",
    "  - `str | None` significa que puede ser texto o nada\n",
    "  - `= None` lo hace opcional\n",
    "\n",
    "**Ejemplo de salida:**\n",
    "```python\n",
    "ResponseFormat(\n",
    "    punny_response=\"¡Florida está teniendo un día radiante!\",\n",
    "    weather_conditions=\"¡Siempre hace sol en Florida!\"\n",
    ")\n",
    "```\n",
    "\n",
    "\n",
    "#### Paso 7: Configurar la Memoria a Corto Plazo (Memoria de Conversación)\n",
    "\n",
    "```python\n",
    "checkpointer = InMemorySaver()\n",
    "```\n",
    "\n",
    "**Qué hace:** Crea un sistema de memoria que guarda el historial de conversación.\n",
    "- Permite al agente recordar lo que se dijo antes\n",
    "- Almacenado en memoria (RAM) - se reinicia cuando tu programa se detiene\n",
    "\n",
    "**Por qué importa:** ¡Sin esto, el agente olvidaría todo entre mensajes!\n",
    "\n",
    "\n",
    "#### Paso 8: Crear el Agente\n",
    "\n",
    "```python\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=SYSTEM_PROMPT,\n",
    "    tools=[get_user_location, get_weather_for_location],\n",
    "    context_schema=Context,\n",
    "    response_format=ToolStrategy(ResponseFormat),\n",
    "    checkpointer=checkpointer\n",
    ")\n",
    "```\n",
    "\n",
    "Aquí es donde todo se junta.\n",
    "\n",
    "**Línea por línea:**\n",
    "- `model=model` - Usa el modelo Claude que configuraste\n",
    "- `system_prompt=SYSTEM_PROMPT` - Da al agente sus instrucciones y personalidad\n",
    "- `tools=[...]` - Proporciona la lista de herramientas que el agente puede usar\n",
    "- `context_schema=Context` - Dice al agente a qué información de usuario tiene acceso\n",
    "- `response_format=ToolStrategy(ResponseFormat)` - Asegura que las respuestas sigan tu estructura definida\n",
    "- `checkpointer=checkpointer` - Habilita la memoria de conversación\n",
    "\n",
    "\n",
    "#### Paso 9: Ejecutar el Agente con ID de Conversación (para Memoria a Corto Plazo) y Contexto Personalizado (en este caso, información del usuario para recordar)\n",
    "\n",
    "```python\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "```\n",
    "**Qué hace:** Crea una configuración que identifica este hilo de conversación.\n",
    "- `thread_id` actúa como un \"ID de conversación\"\n",
    "- Todos los mensajes con el mismo thread_id son parte de la misma conversación\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"¿qué tiempo hace fuera?\"}]},\n",
    "    config=config,\n",
    "    context=Context(user_id=\"1\")\n",
    ")\n",
    "```\n",
    "\n",
    "**Línea por línea:**\n",
    "- `agent.invoke()` - Envía un mensaje al agente y obtiene una respuesta\n",
    "- `{\"messages\": [...]}` - El formato de conversación:\n",
    "  - `\"role\": \"user\"` - Este mensaje es del usuario\n",
    "  - `\"content\": \"...\"` - La pregunta real\n",
    "- `config=config` - Usa el thread_id que definimos\n",
    "- `context=Context(user_id=\"1\")` - Dice al agente que este es el usuario #1\n",
    "\n",
    "\n",
    "**Qué sucede entre bastidores:**\n",
    "1. El agente lee la pregunta\n",
    "2. Se da cuenta de que necesita saber la ubicación del usuario\n",
    "3. Llama a la herramienta `get_user_location()` (devuelve \"Florida\" para el usuario 1)\n",
    "4. Llama a la herramienta `get_weather_for_location(\"Florida\")`\n",
    "5. Genera una respuesta con juegos de palabras con la información meteorológica\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "print(response['structured_response'])\n",
    "```\n",
    "**Qué hace:** Imprime la respuesta estructurada en el formato que definiste.\n",
    "\n",
    "**Ejemplo de salida:**\n",
    "```python\n",
    "ResponseFormat(\n",
    "    punny_response=\"¡Florida está teniendo un día 'radi-sol-ante'! ¡El sol está tocando éxitos 'ray-dio' todo el día!\",\n",
    "    weather_conditions=\"¡Siempre hace sol en Florida!\"\n",
    ")\n",
    "```\n",
    "\n",
    "\n",
    "#### Resumen de Conceptos Clave\n",
    "\n",
    "1. **Herramientas** = Funciones que la IA puede llamar cuando sea necesario\n",
    "2. **Prompt del Sistema** = Instrucciones que guían el comportamiento de la IA\n",
    "3. **Contexto** = Información específica del usuario a la que la IA puede acceder\n",
    "4. **Formato de Respuesta** = La estructura de las respuestas de la IA\n",
    "5. **Memoria** = Permite a la IA recordar mensajes anteriores\n",
    "6. **Thread ID** = Identifica una conversación específica\n",
    "\n",
    "\n",
    "#### Pruébalo Tú Mismo\n",
    "\n",
    "Puedes continuar la conversación:\n",
    "\n",
    "```python\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"¿Por qué casi siempre hace sol en Florida?\"}]},\n",
    "    config=config,\n",
    "    context=Context(user_id=\"1\")\n",
    ")\n",
    "\n",
    "print(response['structured_response'])\n",
    "```\n",
    "\n",
    "El agente recordará la conversación anterior y responderá en consecuencia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb57ca9-2bd5-4198-ae01-03b78d729294",
   "metadata": {},
   "source": [
    "## Cómo ejecutar este código desde Visual Studio Code\n",
    "* Abre el Terminal.\n",
    "* Asegúrate de estar en la carpeta del proyecto.\n",
    "* Asegúrate de tener el entorno poetry activado.\n",
    "* Introduce y ejecuta el siguiente comando:\n",
    "    * `python 003-creating-a-real-agent.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee94440-1fa9-4a24-abf5-cceda970aa84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
