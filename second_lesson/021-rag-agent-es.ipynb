{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17232844-31a4-4e65-863d-14858ce98d6a",
   "metadata": {},
   "source": [
    "# Un Agente RAG con LangChain 1.0 que puede hablar con un documento PDF... correctamente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429a5380-fcd7-4ff5-9583-a681a9c1bf0c",
   "metadata": {},
   "source": [
    "## ¿Qué es RAG (Generación Aumentada por Recuperación)?\n",
    "\n",
    "**RAG** combina dos técnicas poderosas:\n",
    "1. **Recuperación**: Encontrar información relevante usando búsqueda semántica (como hicimos en `020-pdf-agent.ipynb`)\n",
    "2. **Generación**: Usar un LLM para leer esa información y generar una respuesta coherente en lenguaje natural\n",
    "\n",
    "**¿Por qué este código es un ejemplo de una aplicación RAG?**\n",
    "- **Recupera** fragmentos de documento relevantes usando búsqueda semántica (a través de la herramienta)\n",
    "- **Aumenta** el conocimiento del agente con ese contexto recuperado\n",
    "- **Genera** una respuesta en lenguaje natural leyendo y entendiendo el texto recuperado\n",
    "\n",
    "Esto es diferente de la simple búsqueda semántica, que sólo te da fragmentos en bruto sin interpretación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73323d14-ca9b-47af-bc34-438f7013210b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb59ffd-d928-4d71-874c-614c520259f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"gen-ai-in-2026.pdf\")\n",
    "\n",
    "data = loader.load()\n",
    "\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "\n",
    "ids = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5476a514-2c85-4de5-8d84-7e37ab52e92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def search_handbook(query: str) -> str:\n",
    "    \"\"\"Buscar información en el manual\"\"\"\n",
    "    results = vector_store.similarity_search(query)\n",
    "    return results[0].page_content\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=[search_handbook],\n",
    "    system_prompt=\"Eres un agente útil que puede buscar información en el archivo PDF.\"\n",
    "    )\n",
    "\n",
    "from langchain.messages import HumanMessage\n",
    "\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Según Gartner, ¿qué porcentaje de empresas usarán APIs de IA Generativa o desplegarán aplicaciones habilitadas con IA generativa en entornos de producción en 2026?\")]}\n",
    ")\n",
    "\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c83087-7926-4fc9-8817-b4dc3b1f6f32",
   "metadata": {},
   "source": [
    "## Expliquemos el código anterior en términos simples\n",
    "\n",
    "#### Paso 1: Preparar los Datos (Igual que Antes)\n",
    "\n",
    "Esta parte es idéntica a `020-pdf-agent.ipynb` - estamos preparando nuestra base de conocimiento:\n",
    "\n",
    "```python\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"gen-ai-in-2026.pdf\")\n",
    "```\n",
    "**Cargar el archivo PDF** - Apunta al documento que queremos consultar.\n",
    "\n",
    "```python\n",
    "data = loader.load()\n",
    "```\n",
    "**Extraer todas las páginas** - Convierte el PDF en objetos Document.\n",
    "\n",
    "```python\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")\n",
    "```\n",
    "**Configurar el divisor de texto** - Dividirá el documento en fragmentos de 1000 caracteres con 200 caracteres de solapamiento.\n",
    "\n",
    "```python\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "```\n",
    "**Dividir los documentos** - Crea fragmentos más pequeños y buscables.\n",
    "\n",
    "```python\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "```\n",
    "**Crear modelo de embeddings** - Esto convertirá el texto en vectores numéricos que capturan el significado semántico.\n",
    "\n",
    "```python\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "```\n",
    "**Crear base de datos vectorial** - Una base de datos especializada para almacenar y buscar embeddings vectoriales.\n",
    "\n",
    "```python\n",
    "ids = vector_store.add_documents(documents=all_splits)\n",
    "```\n",
    "**Almacenar todos los fragmentos** - Cada fragmento se convierte en un vector y se almacena para su posterior recuperación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5tcbl6f7at",
   "metadata": {},
   "source": [
    "### Paso 2: Crear el Agente RAG (¡La Parte Mágica!)\n",
    "\n",
    "Aquí es donde ocurre RAG - le damos a un agente de IA la capacidad de buscar en el documento y generar respuestas inteligentes.\n",
    "\n",
    "---\n",
    "\n",
    "#### Explicación Línea por Línea\n",
    "\n",
    "```python\n",
    "from langchain.tools import tool\n",
    "```\n",
    "**Importar el decorador tool** - Esto nos permite crear \"herramientas\" que el agente puede usar. Las herramientas son funciones que el agente puede llamar cuando las necesite.\n",
    "\n",
    "```python\n",
    "@tool\n",
    "def search_handbook(query: str) -> str:\n",
    "    \"\"\"Buscar información en el manual\"\"\"\n",
    "    results = vector_store.similarity_search(query)\n",
    "    return results[0].page_content\n",
    "```\n",
    "**Crear una herramienta de búsqueda**:\n",
    "- Decorador `@tool`: Convierte esta función en una herramienta que el agente puede usar\n",
    "- El **docstring** (`\"\"\"Buscar información en el manual\"\"\"`) es CRÍTICO - el agente lee esto para entender qué hace la herramienta\n",
    "- `query: str`: La consulta de búsqueda (el agente la generará automáticamente basándose en la pregunta del usuario)\n",
    "- `vector_store.similarity_search(query)`: Realiza búsqueda semántica para encontrar fragmentos relevantes\n",
    "- `results[0].page_content`: Devuelve solo el contenido de texto del fragmento más relevante\n",
    "- **Por qué funciona**: El agente puede llamar a esta función siempre que necesite información del PDF\n",
    "\n",
    "```python\n",
    "from langchain.agents import create_agent\n",
    "```\n",
    "**Importar el creador de agentes** - Esta es la forma principal de LangChain 1.0 para construir agentes.\n",
    "\n",
    "```python\n",
    "agent = create_agent(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=[search_handbook],\n",
    "    system_prompt=\"Eres un agente útil que puede buscar información en el archivo PDF.\"\n",
    ")\n",
    "```\n",
    "**Crear el agente RAG**:\n",
    "- `model=\"gpt-4o-mini\"`: El LLM que impulsará el razonamiento del agente y la generación de texto\n",
    "- `tools=[search_handbook]`: Da al agente acceso a nuestra herramienta de búsqueda\n",
    "- `system_prompt`: Instrucciones que le dicen al agente su propósito y capacidades\n",
    "- **Lo que el agente puede hacer**: \n",
    "  - Decidir cuándo buscar en el PDF (no buscará para \"Hola\" o preguntas simples)\n",
    "  - Generar consultas de búsqueda apropiadas\n",
    "  - Leer el contenido recuperado\n",
    "  - Formular respuestas en lenguaje natural\n",
    "  - Gestionar preguntas de seguimiento\n",
    "\n",
    "```python\n",
    "from langchain.messages import HumanMessage\n",
    "```\n",
    "**Importar tipos de mensajes** - Los agentes trabajan con mensajes estructurados.\n",
    "\n",
    "```python\n",
    "response = agent.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"Según Gartner, ¿qué porcentaje de empresas usarán APIs de IA Generativa o desplegarán aplicaciones habilitadas con IA generativa en entornos de producción en 2026?\")]}\n",
    ")\n",
    "```\n",
    "**Enviar una pregunta al agente**:\n",
    "- `HumanMessage`: Representa un mensaje del usuario\n",
    "- `agent.invoke()`: Ejecuta el agente con la conversación\n",
    "- **Lo que ocurre internamente**:\n",
    "  1. El agente lee la pregunta\n",
    "  2. El agente decide que necesita buscar en el PDF\n",
    "  3. El agente genera una buena consulta de búsqueda: `\"Gartner porcentaje empresas APIs IA Generativa 2026\"`\n",
    "  4. El agente llama a la herramienta `search_handbook`\n",
    "  5. El agente recibe el fragmento recuperado\n",
    "  6. El agente lee y entiende el fragmento\n",
    "  7. El agente extrae la respuesta y formula una respuesta\n",
    "\n",
    "```python\n",
    "print(response[\"messages\"][-1].content)\n",
    "```\n",
    "**Imprimir la respuesta final**:\n",
    "- `response[\"messages\"]`: Contiene la conversación completa (pregunta del usuario, llamadas a herramientas, resultados de herramientas, respuesta del agente)\n",
    "- `[-1]`: Obtiene el último mensaje (la respuesta final del agente)\n",
    "- `.content`: Obtiene solo el texto de ese mensaje\n",
    "\n",
    "**Salida**: `\"Según Gartner, para 2026, más del 80% de las empresas usarán APIs de IA generativa o desplegarán aplicaciones habilitadas con IA generativa en entornos de producción.\"`\n",
    "\n",
    "---\n",
    "\n",
    "#### Cómo Toma Decisiones el Agente\n",
    "\n",
    "El agente usa un **patrón ReAct** (Razonamiento + Acción):\n",
    "\n",
    "1. **Razonamiento**: \"El usuario está preguntando por una estadística de Gartner. Necesito buscar en el documento.\"\n",
    "2. **Acción**: Llama a `search_handbook(\"Gartner porcentaje empresas APIs IA Generativa 2026\")`\n",
    "3. **Observación**: Lee el fragmento recuperado\n",
    "4. **Razonamiento**: \"He encontrado la respuesta en el texto: 'más del 80% de las empresas usarán APIs de IA generativa'\"\n",
    "5. **Acción**: Genera la respuesta final en lenguaje natural\n",
    "\n",
    "El agente puede:\n",
    "- Omitir búsquedas para preguntas simples que puede responder directamente\n",
    "- Generar múltiples consultas de búsqueda si es necesario\n",
    "- Refinar búsquedas si el primer resultado no es bueno\n",
    "- Combinar información de múltiples fragmentos (si se configura para hacerlo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c29c5f-29f1-418d-92ec-9668836cb36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(response['messages'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jret3uwdakk",
   "metadata": {},
   "source": [
    "### Entendiendo el Flujo de Mensajes\n",
    "\n",
    "La salida de `pprint(response['messages'])` muestra la conversación completa entre componentes:\n",
    "\n",
    "1. **HumanMessage**: Tu pregunta original\n",
    "2. **AIMessage #1**: El agente decidiendo usar la herramienta (contiene `tool_calls`)\n",
    "3. **ToolMessage**: El resultado de `search_handbook` (el fragmento recuperado)\n",
    "4. **AIMessage #2**: La respuesta final del agente después de leer el resultado de la herramienta\n",
    "\n",
    "Esta transparencia es valiosa para depurar y entender cómo funciona el agente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781be28c-31d6-47b3-807b-846ca34ed660",
   "metadata": {},
   "source": [
    "## RAG vs Búsqueda Semántica: Por Qué RAG Ofrece Mejores Respuestas\n",
    "\n",
    "### Comparando los Dos Enfoques\n",
    "\n",
    "| Aspecto | **Búsqueda Semántica** (020-pdf-agent.ipynb) | **Agente RAG** (021-rag-agent.ipynb) |\n",
    "|---------|----------------------------------------------|--------------------------------------|\n",
    "| **Qué obtienes** | Fragmentos de documento en bruto con metadatos | Respuestas en lenguaje natural |\n",
    "| **¿LLM involucrado?** | No - solo similitud vectorial | Sí - el agente lee y entiende |\n",
    "| **Formato de salida** | Objeto Document técnico | Texto amigable para humanos |\n",
    "| **Extracción de respuestas** | Manual - tú lees el fragmento | Automática - el agente extrae la respuesta |\n",
    "| **Múltiples fragmentos** | Solo muestra uno (a menos que hagas un bucle) | El agente puede sintetizar información del contexto |\n",
    "| **Preguntas de seguimiento** | Sin memoria o contexto | El agente puede gestionar flujo conversacional |\n",
    "| **Toma de decisiones** | Tú decides cuándo buscar | El agente decide cuándo es necesaria la recuperación |\n",
    "| **Experiencia de usuario** | Pobre - requiere conocimiento técnico | Excelente - como hablar con un experto |\n",
    "\n",
    "---\n",
    "\n",
    "### Ejemplo de Comparación\n",
    "\n",
    "#### Salida de Búsqueda Semántica (020-pdf-agent.ipynb):\n",
    "```\n",
    "page_content='Generative AI in 2026:\\nTransforming Business and\\n Professional Value\\nAs we progress through 2026, Generative AI has reached a critical inflection point...'\n",
    "metadata={'producer': 'ReportLab PDF Library', 'page': 0, 'page_label': '1', 'start_index': 0}\n",
    "```\n",
    "**Problemas**:\n",
    "- Tienes que leer manualmente el fragmento para encontrar \"80%\"\n",
    "- Incluye metadatos irrelevantes\n",
    "- Muestra más texto del necesario\n",
    "- No es conversacional ni amigable para el usuario\n",
    "\n",
    "#### Salida del Agente RAG (021-rag-agent.ipynb):\n",
    "```\n",
    "Según Gartner, para 2026, más del 80% de las empresas usarán APIs de IA generativa \n",
    "o desplegarán aplicaciones habilitadas con IA generativa en entornos de producción.\n",
    "```\n",
    "**Beneficios**:\n",
    "- Respuesta directa y clara\n",
    "- Extrae exactamente lo que se preguntó\n",
    "- Lenguaje natural profesional\n",
    "- Listo para presentar a los usuarios\n",
    "\n",
    "---\n",
    "\n",
    "### Por Qué RAG Ofrece Mejores Respuestas: Las Diferencias Clave\n",
    "\n",
    "#### 1. **Capa de Inteligencia**\n",
    "- **Búsqueda Semántica**: Recuperación tonta - encuentra texto similar pero no entiende lo que necesitas\n",
    "- **RAG**: Recuperación inteligente + comprensión - entiende tu pregunta, encuentra información relevante Y la interpreta\n",
    "\n",
    "#### 2. **Respuesta vs Datos**\n",
    "- **Búsqueda Semántica**: Devuelve fragmentos de datos en bruto (como dar a alguien una página entera de una enciclopedia)\n",
    "- **RAG**: Devuelve respuestas precisas (como tener un experto que lee la página y te dice exactamente lo que necesitas)\n",
    "\n",
    "#### 3. **Comprensión Contextual**\n",
    "- **Búsqueda Semántica**: Sin comprensión de qué información es relevante en el fragmento\n",
    "- **RAG**: El LLM lee el fragmento, lo entiende y extrae solo la información relevante\n",
    "\n",
    "#### 4. **Razonamiento en Múltiples Pasos**\n",
    "- **Búsqueda Semántica**: Una búsqueda, un resultado, hecho\n",
    "- **Agente RAG**: Puede encadenar múltiples búsquedas, razonar sobre resultados y sintetizar información\n",
    "\n",
    "#### 5. **Gestión de Complejidad**\n",
    "Pregunta de ejemplo: *\"Compara lo que Gartner y MIT dijeron sobre la adopción de IA\"*\n",
    "- **Búsqueda Semántica**: Devolvería un fragmento (estadísticas de Gartner O MIT)\n",
    "- **Agente RAG**: Podría buscar estadísticas de Gartner, luego buscar estadísticas de MIT, y luego compararlas\n",
    "\n",
    "#### 6. **Experiencia de Usuario**\n",
    "- **Búsqueda Semántica**: Requiere que el usuario sea técnico, lea fragmentos, encuentre respuestas\n",
    "- **Agente RAG**: Funciona como ChatGPT - conversación natural, respuestas limpias\n",
    "\n",
    "---\n",
    "\n",
    "### El Poder del RAG Agéntico\n",
    "\n",
    "Esta implementación usa **RAG Agéntico**, lo que significa:\n",
    "\n",
    "1. **Toma de Decisiones Autónoma**: El agente decide CUÁNDO buscar (no todas las consultas necesitan recuperación)\n",
    "   - \"Hola\" → No se necesita búsqueda\n",
    "   - \"¿Cuánto es 2+2?\" → No se necesita búsqueda  \n",
    "   - \"¿Qué dijo Gartner?\" → Se necesita búsqueda\n",
    "\n",
    "2. **Generación Dinámica de Consultas**: El agente crea mejores consultas de búsqueda de las que podrías hacer\n",
    "   - Tu pregunta: \"Según Gartner, qué porcentaje...\"\n",
    "   - Búsqueda del agente: \"Gartner porcentaje empresas APIs IA Generativa 2026\"\n",
    "   - Resultado: Recuperación más enfocada\n",
    "\n",
    "3. **Interacciones Multi-turno**: El agente puede tener conversaciones\n",
    "   - Usuario: \"¿Qué dijo Gartner sobre IA en 2026?\"\n",
    "   - Agente: *busca y responde*\n",
    "   - Usuario: \"¿Y qué hay de MIT?\"\n",
    "   - Agente: *busca de nuevo con nuevo contexto*\n",
    "\n",
    "4. **Integración de Herramientas**: Los agentes pueden usar múltiples herramientas\n",
    "   - Herramienta de búsqueda (lo que tenemos)\n",
    "   - Podría añadir: búsqueda web, calculadora, consultas a bases de datos, etc.\n",
    "\n",
    "---\n",
    "\n",
    "### Impacto en el Mundo Real\n",
    "\n",
    "**Por qué RAG importa en producción**:\n",
    "- La investigación muestra que RAG puede mejorar la precisión de las respuestas hasta en un **70%**\n",
    "- Los usuarios obtienen respuestas de calidad ChatGPT desde tus documentos privados\n",
    "- No es necesario hacer fine-tuning de modelos costosos con tus datos\n",
    "- Los documentos se pueden actualizar sin reentrenamiento\n",
    "- Escala a millones de documentos eficientemente\n",
    "\n",
    "**Casos de uso**:\n",
    "- Bots de soporte al cliente (buscar en la base de conocimiento de la empresa)\n",
    "- Análisis de documentos legales (encontrar jurisprudencia relevante)\n",
    "- Revisión de literatura médica (encontrar artículos de investigación)\n",
    "- Documentación empresarial (wikis internos, manuales)\n",
    "- Tutores educativos (preguntas y respuestas sobre libros de texto)\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusión Clave\n",
    "\n",
    "**La Búsqueda Semántica** es como tener un catálogo de tarjetas de biblioteca - te dice qué libros podrían tener tu respuesta, pero aún tienes que leerlos.\n",
    "\n",
    "**RAG** es como tener un bibliotecario investigador - encuentra los libros relevantes, los lee por ti y te da una respuesta clara y directa a tu pregunta.\n",
    "\n",
    "**RAG Agéntico** es como tener un asistente inteligente - decide cuándo usar la biblioteca, qué buscar, e incluso puede combinar información de múltiples fuentes de forma autónoma.\n",
    "\n",
    "---\n",
    "\n",
    "### Camino de Evolución\n",
    "\n",
    "```\n",
    "Búsqueda por Palabras Clave → Búsqueda Semántica → RAG → RAG Agéntico → RAG Multi-Agente\n",
    "         (1990s)                    (2020s)         (2023)    (2024-2026)      (Futuro)\n",
    "```\n",
    "\n",
    "Actualmente estamos en la **era del RAG Agéntico**, donde los agentes toman decisiones inteligentes sobre recuperación y razonamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1d37b1-f8a8-4c58-96f4-a4bb0dc807a5",
   "metadata": {},
   "source": [
    "## Cómo ejecutar este código desde Visual Studio Code\n",
    "* Abrir Terminal.\n",
    "* Asegurarse de estar en la carpeta del proyecto.\n",
    "* Asegurarse de tener el entorno poetry activado.\n",
    "* Introducir y ejecutar el siguiente comando:\n",
    "    * `python 021-rag-agent.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fc9f77-e716-4c57-ac6a-e3f957861944",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
